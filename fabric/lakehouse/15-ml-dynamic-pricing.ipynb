{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ML Dynamic Pricing - Phase 2: Elasticity-Based Optimization\n",
        "\n",
        "Combines rule-based pricing with price elasticity modeling for revenue-optimal recommendations.\n",
        "\n",
        "## Phase 1 Features (Rule-Based)\n",
        "- **Age-based markdowns**: Products markdown based on days since receipt\n",
        "- **Inventory triggers**: Overstocked items get price reductions\n",
        "- **Seasonal clearance**: End-of-season products marked down\n",
        "\n",
        "## Phase 2 Features (NEW)\n",
        "- **Elasticity integration**: Uses price elasticity coefficients from gold_price_elasticity\n",
        "- **Revenue optimization**: Calculates optimal price point to maximize revenue\n",
        "- **Inventory urgency**: Adjusts recommendations based on stock levels and sell-through rate\n",
        "- **Revenue impact**: Estimates expected revenue change per recommendation\n",
        "- **Confidence levels**: Provides confidence scores based on data quality and elasticity estimates\n",
        "\n",
        "## Constraints\n",
        "- Min Margin: 15% (price must be >= cost * 1.15)\n",
        "- Max Price: MSRP (cannot exceed manufacturer suggested price)\n",
        "- Max Change/Week: 10% (limit price volatility)\n",
        "- Min Duration: 7 days (avoid frequent changes)\n",
        "\n",
        "## Data Flow\n",
        "```\n",
        "Silver (dim_products, fact_store_inventory_txn, fact_receipt_lines)\n",
        "  + Gold (gold_price_elasticity)\n",
        "  --> Gold (gold_pricing_recommendations)\n",
        "```\n",
        "\n",
        "## Usage\n",
        "Schedule this notebook to run **daily** via Fabric pipeline.\n",
        "\n",
        "## Output Schema\n",
        "The `gold_pricing_recommendations` table includes:\n",
        "- Current price and recommended price\n",
        "- Reason codes for transparency\n",
        "- Constraint validation flags\n",
        "- Price elasticity coefficient and category\n",
        "- Expected revenue impact\n",
        "- Confidence level (high/medium/low)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.utils import AnalysisException\n",
        "from datetime import datetime, timezone, timedelta\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# PARAMETERS\n",
        "# =============================================================================\n",
        "\n",
        "def get_env(var_name, default=None):\n",
        "    return os.environ.get(var_name, default)\n",
        "\n",
        "SILVER_DB = get_env(\"SILVER_DB\", default=\"ag\")\n",
        "GOLD_DB = get_env(\"GOLD_DB\", default=\"au\")\n",
        "\n",
        "# Pricing constraints (business rules)\n",
        "MIN_MARGIN_PCT = 0.15  # 15% minimum margin\n",
        "MAX_PRICE_FACTOR = 1.0  # Max price = MSRP\n",
        "MAX_CHANGE_PCT_WEEKLY = 0.10  # Max 10% change per week\n",
        "MIN_DURATION_DAYS = 7  # Min 7 days between price changes\n",
        "\n",
        "# Markdown rules (Phase 1)\n",
        "AGE_THRESHOLD_MODERATE = 30  # Days - start moderate markdown\n",
        "AGE_THRESHOLD_AGGRESSIVE = 60  # Days - aggressive markdown\n",
        "AGE_MARKDOWN_MODERATE = 0.10  # 10% markdown\n",
        "AGE_MARKDOWN_AGGRESSIVE = 0.25  # 25% markdown\n",
        "\n",
        "INVENTORY_HIGH_THRESHOLD = 100  # Units - considered overstocked\n",
        "INVENTORY_MARKDOWN = 0.15  # 15% markdown for overstocked\n",
        "\n",
        "# Seasonal clearance (example: end of Q4 for winter items)\n",
        "CLEARANCE_MARKDOWN = 0.30  # 30% markdown for clearance\n",
        "\n",
        "# Phase 2: Elasticity-based optimization parameters\n",
        "ELASTICITY_WEIGHT = 0.6  # Weight for elasticity-based price vs rule-based\n",
        "INVENTORY_URGENCY_DAYS = 14  # Days of inventory to trigger urgency\n",
        "MIN_OBSERVATIONS_FOR_ELASTICITY = 20  # Min data points to use elasticity\n",
        "\n",
        "print(f\"Configuration: SILVER_DB={SILVER_DB}, GOLD_DB={GOLD_DB}\")\n",
        "print(f\"Constraints: Min Margin={MIN_MARGIN_PCT*100}%, Max Price=MSRP, Max Change/Week={MAX_CHANGE_PCT_WEEKLY*100}%\")\n",
        "print(f\"Phase 2: ELASTICITY_WEIGHT={ELASTICITY_WEIGHT}, INVENTORY_URGENCY_DAYS={INVENTORY_URGENCY_DAYS}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# HELPER FUNCTIONS\n",
        "# =============================================================================\n",
        "\n",
        "def ensure_database(name):\n",
        "    spark.sql(f\"CREATE DATABASE IF NOT EXISTS {name}\")\n",
        "\n",
        "def read_silver(table_name):\n",
        "    return spark.table(f\"{SILVER_DB}.{table_name}\")\n",
        "\n",
        "def read_gold(table_name):\n",
        "    try:\n",
        "        return spark.table(f\"{GOLD_DB}.{table_name}\")\n",
        "    except AnalysisException:\n",
        "        return None\n",
        "\n",
        "def save_gold(df, table_name):\n",
        "    full_name = f\"{GOLD_DB}.{table_name}\"\n",
        "    df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(full_name)\n",
        "    print(f\"  {full_name}: {df.count()} rows\")\n",
        "\n",
        "def silver_exists(table_name):\n",
        "    try:\n",
        "        spark.table(f\"{SILVER_DB}.{table_name}\")\n",
        "        return True\n",
        "    except AnalysisException:\n",
        "        return False\n",
        "\n",
        "ensure_database(GOLD_DB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# PRICING CONSTRAINTS TABLE\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"CREATING PRICING CONSTRAINTS TABLE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Create constraints reference table for transparency and configurability\n",
        "constraints_data = [\n",
        "    {\"constraint_name\": \"min_margin_pct\", \"constraint_value\": MIN_MARGIN_PCT, \"description\": \"Minimum margin percentage (price >= cost * 1.15)\"},\n",
        "    {\"constraint_name\": \"max_price_factor\", \"constraint_value\": MAX_PRICE_FACTOR, \"description\": \"Maximum price as factor of MSRP (1.0 = cannot exceed MSRP)\"},\n",
        "    {\"constraint_name\": \"max_change_pct_weekly\", \"constraint_value\": MAX_CHANGE_PCT_WEEKLY, \"description\": \"Maximum price change per week (as percentage)\"},\n",
        "    {\"constraint_name\": \"min_duration_days\", \"constraint_value\": float(MIN_DURATION_DAYS), \"description\": \"Minimum days between price changes\"},\n",
        "    {\"constraint_name\": \"age_threshold_moderate\", \"constraint_value\": float(AGE_THRESHOLD_MODERATE), \"description\": \"Days to trigger moderate markdown\"},\n",
        "    {\"constraint_name\": \"age_threshold_aggressive\", \"constraint_value\": float(AGE_THRESHOLD_AGGRESSIVE), \"description\": \"Days to trigger aggressive markdown\"},\n",
        "    {\"constraint_name\": \"age_markdown_moderate\", \"constraint_value\": AGE_MARKDOWN_MODERATE, \"description\": \"Markdown percentage for moderate age threshold\"},\n",
        "    {\"constraint_name\": \"age_markdown_aggressive\", \"constraint_value\": AGE_MARKDOWN_AGGRESSIVE, \"description\": \"Markdown percentage for aggressive age threshold\"},\n",
        "    {\"constraint_name\": \"inventory_high_threshold\", \"constraint_value\": float(INVENTORY_HIGH_THRESHOLD), \"description\": \"Units threshold for overstocked items\"},\n",
        "    {\"constraint_name\": \"inventory_markdown\", \"constraint_value\": INVENTORY_MARKDOWN, \"description\": \"Markdown percentage for overstocked items\"},\n",
        "    {\"constraint_name\": \"clearance_markdown\", \"constraint_value\": CLEARANCE_MARKDOWN, \"description\": \"Markdown percentage for seasonal clearance\"},\n",
        "    {\"constraint_name\": \"elasticity_weight\", \"constraint_value\": ELASTICITY_WEIGHT, \"description\": \"Weight for elasticity-based pricing (Phase 2)\"},\n",
        "    {\"constraint_name\": \"inventory_urgency_days\", \"constraint_value\": float(INVENTORY_URGENCY_DAYS), \"description\": \"Days of inventory to trigger urgency (Phase 2)\"},\n",
        "]\n",
        "\n",
        "df_constraints = spark.createDataFrame(constraints_data)\n",
        "save_gold(df_constraints, \"pricing_constraints\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# LOAD SOURCE DATA\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"LOADING SOURCE DATA\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if not silver_exists(\"dim_products\"):\n",
        "    raise Exception(\"dim_products table not found. Run 02-historical-data-load.ipynb first.\")\n",
        "\n",
        "# Load product master with pricing data\n",
        "df_products = read_silver(\"dim_products\").select(\n",
        "    F.col(\"ID\").alias(\"product_id\"),\n",
        "    \"ProductName\",\n",
        "    \"Department\",\n",
        "    \"Category\",\n",
        "    \"Subcategory\",\n",
        "    \"Cost\",\n",
        "    \"MSRP\",\n",
        "    \"SalePrice\",\n",
        "    \"Tags\"\n",
        ")\n",
        "\n",
        "print(f\"Products loaded: {df_products.count()}\")\n",
        "\n",
        "# Load current inventory positions (aggregated across all stores)\n",
        "df_inventory = None\n",
        "if silver_exists(\"fact_store_inventory_txn\"):\n",
        "    # Calculate current inventory by product across all stores\n",
        "    window_spec = Window.partitionBy(\"product_id\").orderBy(F.desc(\"event_ts\"))\n",
        "    df_inventory = (\n",
        "        read_silver(\"fact_store_inventory_txn\")\n",
        "        .withColumn(\"rn\", F.row_number().over(window_spec))\n",
        "        .filter(F.col(\"rn\") == 1)\n",
        "        .groupBy(\"product_id\")\n",
        "        .agg(\n",
        "            F.sum(\"balance\").alias(\"total_inventory\"),\n",
        "            F.max(\"event_ts\").alias(\"inventory_as_of\")\n",
        "        )\n",
        "    )\n",
        "    print(f\"Inventory positions loaded: {df_inventory.count()}\")\n",
        "else:\n",
        "    print(\"No inventory data available - using product data only\")\n",
        "\n",
        "# Load previous pricing recommendations to check duration constraint\n",
        "df_previous_prices = read_gold(\"gold_pricing_recommendations\")\n",
        "if df_previous_prices:\n",
        "    print(f\"Previous pricing recommendations loaded: {df_previous_prices.count()}\")\n",
        "else:\n",
        "    print(\"No previous pricing recommendations - first run\")\n",
        "\n",
        "# Phase 2: Load price elasticity data\n",
        "df_elasticity = read_gold(\"gold_price_elasticity\")\n",
        "if df_elasticity:\n",
        "    print(f\"Price elasticity data loaded: {df_elasticity.count()} products\")\n",
        "else:\n",
        "    print(\"WARNING: No price elasticity data found - Phase 2 optimization will be limited\")\n",
        "    print(\"Run 11-ml-promotion-effectiveness.ipynb to generate elasticity data\")\n",
        "\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# CALCULATE PRODUCT AGE AND SALES VELOCITY\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"CALCULATING PRODUCT AGE AND SALES VELOCITY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "df_product_age = None\n",
        "df_sales_velocity = None\n",
        "\n",
        "if silver_exists(\"fact_receipt_lines\"):\n",
        "    # Calculate days since first/last receipt and recent sales velocity\n",
        "    df_receipt_lines = read_silver(\"fact_receipt_lines\")\n",
        "    \n",
        "    # Product age\n",
        "    df_product_age = (\n",
        "        df_receipt_lines\n",
        "        .groupBy(\"product_id\")\n",
        "        .agg(\n",
        "            F.min(\"event_ts\").alias(\"first_receipt_ts\"),\n",
        "            F.max(\"event_ts\").alias(\"last_receipt_ts\")\n",
        "        )\n",
        "        .withColumn(\"current_ts\", F.current_timestamp())\n",
        "        .withColumn(\n",
        "            \"days_since_first_receipt\",\n",
        "            F.datediff(F.col(\"current_ts\"), F.col(\"first_receipt_ts\"))\n",
        "        )\n",
        "        .withColumn(\n",
        "            \"days_since_last_receipt\",\n",
        "            F.datediff(F.col(\"current_ts\"), F.col(\"last_receipt_ts\"))\n",
        "        )\n",
        "        .select(\"product_id\", \"days_since_first_receipt\", \"days_since_last_receipt\")\n",
        "    )\n",
        "    print(f\"Product age calculated for {df_product_age.count()} products\")\n",
        "    \n",
        "    # Sales velocity (last 30 days)\n",
        "    thirty_days_ago = F.date_sub(F.current_date(), 30)\n",
        "    df_sales_velocity = (\n",
        "        df_receipt_lines\n",
        "        .filter(F.col(\"event_ts\") >= thirty_days_ago)\n",
        "        .groupBy(\"product_id\")\n",
        "        .agg(\n",
        "            F.sum(\"quantity\").alias(\"units_sold_30d\"),\n",
        "            F.countDistinct(F.to_date(\"event_ts\")).alias(\"days_with_sales\")\n",
        "        )\n",
        "        .withColumn(\n",
        "            \"avg_daily_sales\",\n",
        "            F.col(\"units_sold_30d\") / F.greatest(F.col(\"days_with_sales\"), F.lit(1))\n",
        "        )\n",
        "        .select(\"product_id\", \"units_sold_30d\", \"avg_daily_sales\")\n",
        "    )\n",
        "    print(f\"Sales velocity calculated for {df_sales_velocity.count()} products\")\n",
        "else:\n",
        "    print(\"No receipt data - product age and sales velocity will be 0\")\n",
        "\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# PHASE 1: RULE-BASED MARKDOWN LOGIC\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"PHASE 1: APPLYING RULE-BASED MARKDOWN LOGIC\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Start with product master\n",
        "df_pricing = df_products\n",
        "\n",
        "# Join with inventory if available\n",
        "if df_inventory is not None:\n",
        "    df_pricing = df_pricing.join(df_inventory, \"product_id\", \"left\")\n",
        "else:\n",
        "    df_pricing = df_pricing.withColumn(\"total_inventory\", F.lit(None).cast(\"long\"))\n",
        "    df_pricing = df_pricing.withColumn(\"inventory_as_of\", F.lit(None).cast(\"timestamp\"))\n",
        "\n",
        "# Join with product age if available\n",
        "if df_product_age is not None:\n",
        "    df_pricing = df_pricing.join(df_product_age, \"product_id\", \"left\")\n",
        "else:\n",
        "    df_pricing = df_pricing.withColumn(\"days_since_first_receipt\", F.lit(0))\n",
        "    df_pricing = df_pricing.withColumn(\"days_since_last_receipt\", F.lit(0))\n",
        "\n",
        "# Join with sales velocity if available\n",
        "if df_sales_velocity is not None:\n",
        "    df_pricing = df_pricing.join(df_sales_velocity, \"product_id\", \"left\")\n",
        "else:\n",
        "    df_pricing = df_pricing.withColumn(\"units_sold_30d\", F.lit(0))\n",
        "    df_pricing = df_pricing.withColumn(\"avg_daily_sales\", F.lit(0.0))\n",
        "\n",
        "# Initialize markdown factors and reason codes\n",
        "df_pricing = df_pricing.withColumn(\"markdown_factor\", F.lit(0.0))\n",
        "df_pricing = df_pricing.withColumn(\"reason_codes\", F.array())\n",
        "\n",
        "# Rule 1: Age-based markdowns\n",
        "df_pricing = df_pricing.withColumn(\n",
        "    \"age_markdown\",\n",
        "    F.when(\n",
        "        F.col(\"days_since_last_receipt\") >= AGE_THRESHOLD_AGGRESSIVE,\n",
        "        F.lit(AGE_MARKDOWN_AGGRESSIVE)\n",
        "    ).when(\n",
        "        F.col(\"days_since_last_receipt\") >= AGE_THRESHOLD_MODERATE,\n",
        "        F.lit(AGE_MARKDOWN_MODERATE)\n",
        "    ).otherwise(F.lit(0.0))\n",
        ")\n",
        "\n",
        "df_pricing = df_pricing.withColumn(\n",
        "    \"markdown_factor\",\n",
        "    F.greatest(F.col(\"markdown_factor\"), F.col(\"age_markdown\"))\n",
        ")\n",
        "\n",
        "df_pricing = df_pricing.withColumn(\n",
        "    \"reason_codes\",\n",
        "    F.when(\n",
        "        F.col(\"age_markdown\") == AGE_MARKDOWN_AGGRESSIVE,\n",
        "        F.array_union(F.col(\"reason_codes\"), F.array(F.lit(\"AGE_AGGRESSIVE\")))\n",
        "    ).when(\n",
        "        F.col(\"age_markdown\") == AGE_MARKDOWN_MODERATE,\n",
        "        F.array_union(F.col(\"reason_codes\"), F.array(F.lit(\"AGE_MODERATE\")))\n",
        "    ).otherwise(F.col(\"reason_codes\"))\n",
        ")\n",
        "\n",
        "# Rule 2: Inventory-based markdowns\n",
        "df_pricing = df_pricing.withColumn(\n",
        "    \"inventory_markdown\",\n",
        "    F.when(\n",
        "        F.col(\"total_inventory\") >= INVENTORY_HIGH_THRESHOLD,\n",
        "        F.lit(INVENTORY_MARKDOWN)\n",
        "    ).otherwise(F.lit(0.0))\n",
        ")\n",
        "\n",
        "df_pricing = df_pricing.withColumn(\n",
        "    \"markdown_factor\",\n",
        "    F.greatest(F.col(\"markdown_factor\"), F.col(\"inventory_markdown\"))\n",
        ")\n",
        "\n",
        "df_pricing = df_pricing.withColumn(\n",
        "    \"reason_codes\",\n",
        "    F.when(\n",
        "        F.col(\"inventory_markdown\") > 0,\n",
        "        F.array_union(F.col(\"reason_codes\"), F.array(F.lit(\"INVENTORY_HIGH\")))\n",
        "    ).otherwise(F.col(\"reason_codes\"))\n",
        ")\n",
        "\n",
        "# Rule 3: Seasonal clearance (example: products tagged with winter/holiday in Q1)\n",
        "current_month = datetime.now(timezone.utc).month\n",
        "is_clearance_period = current_month in [1, 2, 3]  # Q1 for winter clearance\n",
        "\n",
        "if is_clearance_period:\n",
        "    df_pricing = df_pricing.withColumn(\n",
        "        \"seasonal_markdown\",\n",
        "        F.when(\n",
        "            (F.col(\"Tags\").isNotNull()) & \n",
        "            ((F.lower(F.col(\"Tags\")).contains(\"winter\")) | \n",
        "             (F.lower(F.col(\"Tags\")).contains(\"holiday\"))),\n",
        "            F.lit(CLEARANCE_MARKDOWN)\n",
        "        ).otherwise(F.lit(0.0))\n",
        "    )\n",
        "    \n",
        "    df_pricing = df_pricing.withColumn(\n",
        "        \"markdown_factor\",\n",
        "        F.greatest(F.col(\"markdown_factor\"), F.col(\"seasonal_markdown\"))\n",
        "    )\n",
        "    \n",
        "    df_pricing = df_pricing.withColumn(\n",
        "        \"reason_codes\",\n",
        "        F.when(\n",
        "            F.col(\"seasonal_markdown\") > 0,\n",
        "            F.array_union(F.col(\"reason_codes\"), F.array(F.lit(\"SEASONAL_CLEARANCE\")))\n",
        "        ).otherwise(F.col(\"reason_codes\"))\n",
        "    )\n",
        "\n",
        "# Calculate rule-based recommended price\n",
        "df_pricing = df_pricing.withColumn(\n",
        "    \"rule_based_price\",\n",
        "    F.col(\"SalePrice\") * (1 - F.col(\"markdown_factor\"))\n",
        ")\n",
        "\n",
        "print(f\"Rule-based markdown logic applied to {df_pricing.count()} products\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# PHASE 2: ELASTICITY-BASED OPTIMIZATION\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"PHASE 2: APPLYING ELASTICITY-BASED OPTIMIZATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if df_elasticity is not None:\n",
        "    # Join elasticity data\n",
        "    df_pricing = df_pricing.join(\n",
        "        df_elasticity.select(\n",
        "            \"product_id\",\n",
        "            \"elasticity_coefficient\",\n",
        "            \"elasticity_category\",\n",
        "            \"n_observations\",\n",
        "            F.col(\"confidence_interval_lower\").alias(\"elasticity_ci_lower\"),\n",
        "            F.col(\"confidence_interval_upper\").alias(\"elasticity_ci_upper\")\n",
        "        ),\n",
        "        \"product_id\",\n",
        "        \"left\"\n",
        "    )\n",
        "    \n",
        "    # Calculate optimal price using elasticity\n",
        "    # Formula: optimal_price = cost * (elasticity / (elasticity + 1))\n",
        "    # This maximizes revenue = price * quantity, where quantity = f(price, elasticity)\n",
        "    df_pricing = df_pricing.withColumn(\n",
        "        \"elasticity_optimal_price\",\n",
        "        F.when(\n",
        "            (F.col(\"elasticity_coefficient\").isNotNull()) & \n",
        "            (F.col(\"elasticity_coefficient\") < -0.1) &  # Must be negative and meaningful\n",
        "            (F.col(\"n_observations\") >= MIN_OBSERVATIONS_FOR_ELASTICITY),\n",
        "            F.col(\"Cost\") * (F.abs(F.col(\"elasticity_coefficient\")) / (F.abs(F.col(\"elasticity_coefficient\")) + 1))\n",
        "        ).otherwise(F.lit(None))\n",
        "    )\n",
        "    \n",
        "    # Blend rule-based and elasticity-based prices\n",
        "    df_pricing = df_pricing.withColumn(\n",
        "        \"blended_price\",\n",
        "        F.when(\n",
        "            F.col(\"elasticity_optimal_price\").isNotNull(),\n",
        "            (F.col(\"elasticity_optimal_price\") * ELASTICITY_WEIGHT) + \n",
        "            (F.col(\"rule_based_price\") * (1 - ELASTICITY_WEIGHT))\n",
        "        ).otherwise(F.col(\"rule_based_price\"))\n",
        "    )\n",
        "    \n",
        "    # Add elasticity reason code\n",
        "    df_pricing = df_pricing.withColumn(\n",
        "        \"reason_codes\",\n",
        "        F.when(\n",
        "            F.col(\"elasticity_optimal_price\").isNotNull(),\n",
        "            F.array_union(F.col(\"reason_codes\"), F.array(F.lit(\"ELASTICITY_OPTIMIZED\")))\n",
        "        ).otherwise(F.col(\"reason_codes\"))\n",
        "    )\n",
        "    \n",
        "    print(f\"Elasticity optimization applied to products with sufficient data\")\n",
        "else:\n",
        "    # No elasticity data - use rule-based price only\n",
        "    df_pricing = df_pricing.withColumn(\"elasticity_coefficient\", F.lit(None).cast(\"decimal(10,4)\"))\n",
        "    df_pricing = df_pricing.withColumn(\"elasticity_category\", F.lit(None).cast(\"string\"))\n",
        "    df_pricing = df_pricing.withColumn(\"n_observations\", F.lit(None).cast(\"int\"))\n",
        "    df_pricing = df_pricing.withColumn(\"elasticity_ci_lower\", F.lit(None).cast(\"decimal(10,4)\"))\n",
        "    df_pricing = df_pricing.withColumn(\"elasticity_ci_upper\", F.lit(None).cast(\"decimal(10,4)\"))\n",
        "    df_pricing = df_pricing.withColumn(\"elasticity_optimal_price\", F.lit(None).cast(\"decimal(10,2)\"))\n",
        "    df_pricing = df_pricing.withColumn(\"blended_price\", F.col(\"rule_based_price\"))\n",
        "    print(\"No elasticity data available - using rule-based prices only\")\n",
        "\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# PHASE 2: INVENTORY URGENCY ADJUSTMENT\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"PHASE 2: APPLYING INVENTORY URGENCY ADJUSTMENT\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Calculate days of inventory on hand\n",
        "df_pricing = df_pricing.withColumn(\n",
        "    \"days_of_inventory\",\n",
        "    F.when(\n",
        "        (F.col(\"avg_daily_sales\") > 0.1),  # Avoid division by very small numbers\n",
        "        F.col(\"total_inventory\") / F.col(\"avg_daily_sales\")\n",
        "    ).otherwise(F.lit(999))  # High value = no urgency\n",
        ")\n",
        "\n",
        "# Apply urgency discount for low inventory days\n",
        "df_pricing = df_pricing.withColumn(\n",
        "    \"urgency_markdown\",\n",
        "    F.when(\n",
        "        F.col(\"days_of_inventory\") <= INVENTORY_URGENCY_DAYS,\n",
        "        0.05 + (0.10 * (1 - F.col(\"days_of_inventory\") / INVENTORY_URGENCY_DAYS))\n",
        "    ).otherwise(F.lit(0.0))\n",
        ")\n",
        "\n",
        "# Apply urgency adjustment to blended price\n",
        "df_pricing = df_pricing.withColumn(\n",
        "    \"recommended_price_raw\",\n",
        "    F.col(\"blended_price\") * (1 - F.col(\"urgency_markdown\"))\n",
        ")\n",
        "\n",
        "# Add urgency reason code\n",
        "df_pricing = df_pricing.withColumn(\n",
        "    \"reason_codes\",\n",
        "    F.when(\n",
        "        F.col(\"urgency_markdown\") > 0,\n",
        "        F.array_union(F.col(\"reason_codes\"), F.array(F.lit(\"INVENTORY_URGENCY\")))\n",
        "    ).otherwise(F.col(\"reason_codes\"))\n",
        ")\n",
        "\n",
        "print(f\"Inventory urgency adjustment applied\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# APPLY BUSINESS CONSTRAINTS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"APPLYING BUSINESS CONSTRAINTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Constraint 1: Minimum margin (price >= cost * 1.15)\n",
        "df_pricing = df_pricing.withColumn(\n",
        "    \"min_price\",\n",
        "    F.col(\"Cost\") * (1 + MIN_MARGIN_PCT)\n",
        ")\n",
        "\n",
        "# Constraint 2: Maximum price (cannot exceed MSRP)\n",
        "df_pricing = df_pricing.withColumn(\n",
        "    \"max_price\",\n",
        "    F.col(\"MSRP\") * MAX_PRICE_FACTOR\n",
        ")\n",
        "\n",
        "# Apply min/max constraints\n",
        "df_pricing = df_pricing.withColumn(\n",
        "    \"recommended_price\",\n",
        "    F.greatest(\n",
        "        F.col(\"min_price\"),\n",
        "        F.least(F.col(\"recommended_price_raw\"), F.col(\"max_price\"))\n",
        "    )\n",
        ")\n",
        "\n",
        "# Track constraint violations\n",
        "df_pricing = df_pricing.withColumn(\n",
        "    \"hit_min_margin\",\n",
        "    F.col(\"recommended_price_raw\") < F.col(\"min_price\")\n",
        ")\n",
        "\n",
        "df_pricing = df_pricing.withColumn(\n",
        "    \"hit_max_price\",\n",
        "    F.col(\"recommended_price_raw\") > F.col(\"max_price\")\n",
        ")\n",
        "\n",
        "# Add constraint violation to reason codes\n",
        "df_pricing = df_pricing.withColumn(\n",
        "    \"reason_codes\",\n",
        "    F.when(\n",
        "        F.col(\"hit_min_margin\"),\n",
        "        F.array_union(F.col(\"reason_codes\"), F.array(F.lit(\"CONSTRAINT_MIN_MARGIN\")))\n",
        "    ).otherwise(F.col(\"reason_codes\"))\n",
        ")\n",
        "\n",
        "df_pricing = df_pricing.withColumn(\n",
        "    \"reason_codes\",\n",
        "    F.when(\n",
        "        F.col(\"hit_max_price\"),\n",
        "        F.array_union(F.col(\"reason_codes\"), F.array(F.lit(\"CONSTRAINT_MAX_PRICE\")))\n",
        "    ).otherwise(F.col(\"reason_codes\"))\n",
        ")\n",
        "\n",
        "# Constraint 3: Max change per week (10%)\n",
        "if df_previous_prices is not None:\n",
        "    df_prev = df_previous_prices.select(\n",
        "        \"product_id\",\n",
        "        F.col(\"recommended_price\").alias(\"previous_price\"),\n",
        "        F.col(\"recommendation_ts\").alias(\"previous_ts\")\n",
        "    )\n",
        "    \n",
        "    df_pricing = df_pricing.join(df_prev, \"product_id\", \"left\")\n",
        "    \n",
        "    df_pricing = df_pricing.withColumn(\n",
        "        \"days_since_last_change\",\n",
        "        F.datediff(F.current_timestamp(), F.col(\"previous_ts\"))\n",
        "    )\n",
        "    \n",
        "    # Check if change exceeds 10% and duration < 7 days\n",
        "    df_pricing = df_pricing.withColumn(\n",
        "        \"change_pct\",\n",
        "        F.abs((F.col(\"recommended_price\") - F.col(\"previous_price\")) / F.col(\"previous_price\"))\n",
        "    )\n",
        "    \n",
        "    df_pricing = df_pricing.withColumn(\n",
        "        \"violates_max_change\",\n",
        "        (F.col(\"change_pct\") > MAX_CHANGE_PCT_WEEKLY) & \n",
        "        (F.col(\"days_since_last_change\") < MIN_DURATION_DAYS)\n",
        "    )\n",
        "    \n",
        "    # If violates, keep previous price\n",
        "    df_pricing = df_pricing.withColumn(\n",
        "        \"recommended_price\",\n",
        "        F.when(\n",
        "            F.col(\"violates_max_change\") & F.col(\"previous_price\").isNotNull(),\n",
        "            F.col(\"previous_price\")\n",
        "        ).otherwise(F.col(\"recommended_price\"))\n",
        "    )\n",
        "    \n",
        "    df_pricing = df_pricing.withColumn(\n",
        "        \"reason_codes\",\n",
        "        F.when(\n",
        "            F.col(\"violates_max_change\"),\n",
        "            F.array_union(F.col(\"reason_codes\"), F.array(F.lit(\"CONSTRAINT_MAX_CHANGE\")))\n",
        "        ).otherwise(F.col(\"reason_codes\"))\n",
        "    )\n",
        "else:\n",
        "    df_pricing = df_pricing.withColumn(\"previous_price\", F.lit(None).cast(\"decimal(10,2)\"))\n",
        "    df_pricing = df_pricing.withColumn(\"previous_ts\", F.lit(None).cast(\"timestamp\"))\n",
        "    df_pricing = df_pricing.withColumn(\"days_since_last_change\", F.lit(None).cast(\"int\"))\n",
        "    df_pricing = df_pricing.withColumn(\"change_pct\", F.lit(None).cast(\"decimal(5,2)\"))\n",
        "    df_pricing = df_pricing.withColumn(\"violates_max_change\", F.lit(False))\n",
        "\n",
        "print(f\"Constraints applied to {df_pricing.count()} products\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# PHASE 2: CALCULATE REVENUE IMPACT AND CONFIDENCE\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"PHASE 2: CALCULATING REVENUE IMPACT AND CONFIDENCE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Calculate expected revenue impact\n",
        "# Formula: revenue_impact = (new_price - old_price) * expected_quantity\n",
        "# where expected_quantity considers elasticity if available\n",
        "\n",
        "df_pricing = df_pricing.withColumn(\n",
        "    \"price_change_pct\",\n",
        "    F.round((F.col(\"recommended_price\") - F.col(\"SalePrice\")) / F.col(\"SalePrice\") * 100, 2)\n",
        ")\n",
        "\n",
        "# Estimate quantity change using elasticity\n",
        "df_pricing = df_pricing.withColumn(\n",
        "    \"expected_quantity_change_pct\",\n",
        "    F.when(\n",
        "        F.col(\"elasticity_coefficient\").isNotNull(),\n",
        "        F.col(\"elasticity_coefficient\") * F.col(\"price_change_pct\")\n",
        "    ).otherwise(F.lit(0.0))  # Assume no quantity change if no elasticity data\n",
        ")\n",
        "\n",
        "df_pricing = df_pricing.withColumn(\n",
        "    \"expected_daily_quantity\",\n",
        "    F.col(\"avg_daily_sales\") * (1 + F.col(\"expected_quantity_change_pct\") / 100)\n",
        ")\n",
        "\n",
        "# Calculate daily revenue impact\n",
        "df_pricing = df_pricing.withColumn(\n",
        "    \"current_daily_revenue\",\n",
        "    F.col(\"SalePrice\") * F.col(\"avg_daily_sales\")\n",
        ")\n",
        "\n",
        "df_pricing = df_pricing.withColumn(\n",
        "    \"expected_daily_revenue\",\n",
        "    F.col(\"recommended_price\") * F.col(\"expected_daily_quantity\")\n",
        ")\n",
        "\n",
        "df_pricing = df_pricing.withColumn(\n",
        "    \"daily_revenue_impact\",\n",
        "    F.col(\"expected_daily_revenue\") - F.col(\"current_daily_revenue\")\n",
        ")\n",
        "\n",
        "# Calculate 30-day revenue impact projection\n",
        "df_pricing = df_pricing.withColumn(\n",
        "    \"projected_revenue_impact_30d\",\n",
        "    F.col(\"daily_revenue_impact\") * 30\n",
        ")\n",
        "\n",
        "# Determine confidence level\n",
        "df_pricing = df_pricing.withColumn(\n",
        "    \"confidence_level\",\n",
        "    F.when(\n",
        "        (F.col(\"n_observations\") >= 50) & \n",
        "        (F.col(\"elasticity_coefficient\").isNotNull()) &\n",
        "        (F.col(\"avg_daily_sales\") >= 1.0),\n",
        "        \"HIGH\"\n",
        "    ).when(\n",
        "        (F.col(\"n_observations\") >= MIN_OBSERVATIONS_FOR_ELASTICITY) & \n",
        "        (F.col(\"elasticity_coefficient\").isNotNull()),\n",
        "        \"MEDIUM\"\n",
        "    ).otherwise(\"LOW\")\n",
        ")\n",
        "\n",
        "# Calculate confidence score (0-1)\n",
        "df_pricing = df_pricing.withColumn(\n",
        "    \"confidence_score\",\n",
        "    F.when(\n",
        "        F.col(\"confidence_level\") == \"HIGH\", F.lit(0.85)\n",
        "    ).when(\n",
        "        F.col(\"confidence_level\") == \"MEDIUM\", F.lit(0.60)\n",
        "    ).otherwise(F.lit(0.35))\n",
        ")\n",
        "\n",
        "# Adjust confidence based on elasticity CI width\n",
        "df_pricing = df_pricing.withColumn(\n",
        "    \"elasticity_ci_width\",\n",
        "    F.when(\n",
        "        (F.col(\"elasticity_ci_upper\").isNotNull()) & (F.col(\"elasticity_ci_lower\").isNotNull()),\n",
        "        F.col(\"elasticity_ci_upper\") - F.col(\"elasticity_ci_lower\")\n",
        "    ).otherwise(F.lit(None))\n",
        ")\n",
        "\n",
        "df_pricing = df_pricing.withColumn(\n",
        "    \"confidence_score\",\n",
        "    F.when(\n",
        "        (F.col(\"elasticity_ci_width\").isNotNull()) & (F.col(\"elasticity_ci_width\") > 1.0),\n",
        "        F.col(\"confidence_score\") * 0.9  # Reduce confidence for wide CI\n",
        "    ).otherwise(F.col(\"confidence_score\"))\n",
        ")\n",
        "\n",
        "print(f\"Revenue impact and confidence calculated\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# CREATE OUTPUT TABLE\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"CREATING PRICING RECOMMENDATIONS OUTPUT\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Add no-change reason for products that don't need markdown\n",
        "df_pricing = df_pricing.withColumn(\n",
        "    \"reason_codes\",\n",
        "    F.when(\n",
        "        F.size(F.col(\"reason_codes\")) == 0,\n",
        "        F.array(F.lit(\"NO_CHANGE\"))\n",
        "    ).otherwise(F.col(\"reason_codes\"))\n",
        ")\n",
        "\n",
        "# Create final output with Phase 2 enhancements\n",
        "df_output = df_pricing.select(\n",
        "    \"product_id\",\n",
        "    \"ProductName\",\n",
        "    \"Department\",\n",
        "    \"Category\",\n",
        "    \"Subcategory\",\n",
        "    F.col(\"Cost\").alias(\"cost\"),\n",
        "    F.col(\"MSRP\").alias(\"msrp\"),\n",
        "    F.col(\"SalePrice\").alias(\"current_price\"),\n",
        "    F.col(\"recommended_price\"),\n",
        "    F.col(\"price_change_pct\").alias(\"change_pct\"),\n",
        "    F.col(\"reason_codes\"),\n",
        "    F.col(\"markdown_factor\"),\n",
        "    F.col(\"total_inventory\"),\n",
        "    F.col(\"days_since_last_receipt\"),\n",
        "    F.col(\"avg_daily_sales\"),\n",
        "    F.col(\"days_of_inventory\"),\n",
        "    F.col(\"hit_min_margin\"),\n",
        "    F.col(\"hit_max_price\"),\n",
        "    F.col(\"violates_max_change\"),\n",
        "    # Phase 2 fields\n",
        "    F.col(\"elasticity_coefficient\"),\n",
        "    F.col(\"elasticity_category\"),\n",
        "    F.col(\"projected_revenue_impact_30d\"),\n",
        "    F.col(\"confidence_level\"),\n",
        "    F.col(\"confidence_score\"),\n",
        "    F.lit(\"ELASTICITY_OPTIMIZED\").alias(\"model_type\"),\n",
        "    F.col(\"confidence_score\").alias(\"ml_confidence\"),\n",
        "    F.current_timestamp().alias(\"recommendation_ts\"),\n",
        "    F.lit(\"2.0\").alias(\"schema_version\")\n",
        ")\n",
        "\n",
        "save_gold(df_output, \"gold_pricing_recommendations\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# SUMMARY STATISTICS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"PRICING RECOMMENDATIONS SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "total_products = df_output.count()\n",
        "print(f\"\\nTotal products analyzed: {total_products}\")\n",
        "\n",
        "# Count by reason code\n",
        "print(\"\\nRecommendations by reason:\")\n",
        "df_reasons = df_output.select(F.explode(\"reason_codes\").alias(\"reason\"))\n",
        "df_reasons.groupBy(\"reason\").count().orderBy(F.desc(\"count\")).show(truncate=False)\n",
        "\n",
        "# Count constraint violations\n",
        "print(\"\\nConstraint violations:\")\n",
        "min_margin_hits = df_output.filter(F.col(\"hit_min_margin\")).count()\n",
        "max_price_hits = df_output.filter(F.col(\"hit_max_price\")).count()\n",
        "max_change_hits = df_output.filter(F.col(\"violates_max_change\")).count()\n",
        "\n",
        "print(f\"  Min margin: {min_margin_hits} products\")\n",
        "print(f\"  Max price: {max_price_hits} products\")\n",
        "print(f\"  Max change/week: {max_change_hits} products\")\n",
        "\n",
        "# Price change distribution\n",
        "print(\"\\nPrice change distribution:\")\n",
        "df_output.select(\n",
        "    F.avg(\"change_pct\").alias(\"avg_change_pct\"),\n",
        "    F.min(\"change_pct\").alias(\"min_change_pct\"),\n",
        "    F.max(\"change_pct\").alias(\"max_change_pct\")\n",
        ").show()\n",
        "\n",
        "# Products with significant markdowns\n",
        "significant_markdowns = df_output.filter(F.col(\"change_pct\") < -5).count()\n",
        "print(f\"\\nProducts with >5% markdown: {significant_markdowns}\")\n",
        "\n",
        "# Phase 2: Elasticity-based recommendations\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PHASE 2: ELASTICITY-BASED OPTIMIZATION SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "elasticity_used = df_output.filter(F.col(\"elasticity_coefficient\").isNotNull()).count()\n",
        "print(f\"\\nProducts with elasticity data: {elasticity_used} ({elasticity_used*100/total_products:.1f}%)\")\n",
        "\n",
        "print(\"\\nConfidence level distribution:\")\n",
        "df_output.groupBy(\"confidence_level\").count().orderBy(F.desc(\"count\")).show(truncate=False)\n",
        "\n",
        "print(\"\\nElasticity category distribution:\")\n",
        "df_output.filter(F.col(\"elasticity_category\").isNotNull()).groupBy(\"elasticity_category\").count().orderBy(F.desc(\"count\")).show(truncate=False)\n",
        "\n",
        "print(\"\\nRevenue impact summary (30-day projection):\")\n",
        "df_output.select(\n",
        "    F.sum(\"projected_revenue_impact_30d\").alias(\"total_revenue_impact\"),\n",
        "    F.avg(\"projected_revenue_impact_30d\").alias(\"avg_revenue_impact_per_product\"),\n",
        "    F.max(\"projected_revenue_impact_30d\").alias(\"max_revenue_impact\")\n",
        ").show()\n",
        "\n",
        "print(\"\\nTop 10 products by expected revenue impact:\")\n",
        "df_output.orderBy(F.desc(\"projected_revenue_impact_30d\")).select(\n",
        "    \"product_id\",\n",
        "    \"ProductName\",\n",
        "    \"current_price\",\n",
        "    \"recommended_price\",\n",
        "    \"change_pct\",\n",
        "    \"projected_revenue_impact_30d\",\n",
        "    \"confidence_level\"\n",
        ").show(10, truncate=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DYNAMIC PRICING PHASE 2 COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nCompleted features:\")\n",
        "print(\"  ✓ Phase 1: Rule-based markdown engine\")\n",
        "print(\"  ✓ Phase 2: Price elasticity integration\")\n",
        "print(\"  ✓ Phase 2: Elasticity-based optimization\")\n",
        "print(\"  ✓ Phase 2: Inventory urgency adjustments\")\n",
        "print(\"  ✓ Phase 2: Revenue impact estimation\")\n",
        "print(\"  ✓ Phase 2: Confidence level scoring\")\n",
        "print(\"\\nNext steps:\")\n",
        "print(\"  - Review recommendations in gold_pricing_recommendations table\")\n",
        "print(\"  - Monitor revenue impact vs actuals\")\n",
        "print(\"  - Phase 3: Add competitor price intelligence\")\n",
        "print(\"  - Phase 3: Add multi-product bundle optimization\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "PySpark",
      "language": "python",
      "name": "pysparkkernel"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "mimetype": "text/x-python",
      "name": "pyspark",
      "pygments_lexer": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
