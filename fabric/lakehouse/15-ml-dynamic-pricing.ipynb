{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Dynamic Pricing - Phase 1: Rule-Based Markdown Engine\n",
    "\n",
    "Implements rule-based pricing recommendations to prepare for future ML enhancements.\n",
    "\n",
    "## Business Rules\n",
    "- **Age-based markdowns**: Products markdown based on days since receipt\n",
    "- **Inventory triggers**: Overstocked items get price reductions\n",
    "- **Seasonal clearance**: End-of-season products marked down\n",
    "\n",
    "## Constraints\n",
    "- Min Margin: 15% (price must be >= cost * 1.15)\n",
    "- Max Price: MSRP (cannot exceed manufacturer suggested price)\n",
    "- Max Change/Week: 10% (limit price volatility)\n",
    "- Min Duration: 7 days (avoid frequent changes)\n",
    "\n",
    "## Data Flow\n",
    "```\n",
    "Silver (dim_products, inventory_position_current) --> Gold (gold_pricing_recommendations)\n",
    "```\n",
    "\n",
    "## Usage\n",
    "Schedule this notebook to run **daily** via Fabric pipeline.\n",
    "\n",
    "## Output Schema\n",
    "The `gold_pricing_recommendations` table includes:\n",
    "- Current price and recommended price\n",
    "- Reason codes for transparency\n",
    "- Constraint validation flags\n",
    "- Extensible schema for future ML scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PARAMETERS\n",
    "# =============================================================================\n",
    "\n",
    "def get_env(var_name, default=None):\n",
    "    return os.environ.get(var_name, default)\n",
    "\n",
    "SILVER_DB = get_env(\"SILVER_DB\", default=\"ag\")\n",
    "GOLD_DB = get_env(\"GOLD_DB\", default=\"au\")\n",
    "\n",
    "# Pricing constraints (business rules)\n",
    "MIN_MARGIN_PCT = 0.15  # 15% minimum margin\n",
    "MAX_PRICE_FACTOR = 1.0  # Max price = MSRP\n",
    "MAX_CHANGE_PCT_WEEKLY = 0.10  # Max 10% change per week\n",
    "MIN_DURATION_DAYS = 7  # Min 7 days between price changes\n",
    "\n",
    "# Markdown rules\n",
    "AGE_THRESHOLD_MODERATE = 30  # Days - start moderate markdown\n",
    "AGE_THRESHOLD_AGGRESSIVE = 60  # Days - aggressive markdown\n",
    "AGE_MARKDOWN_MODERATE = 0.10  # 10% markdown\n",
    "AGE_MARKDOWN_AGGRESSIVE = 0.25  # 25% markdown\n",
    "\n",
    "INVENTORY_HIGH_THRESHOLD = 100  # Units - considered overstocked\n",
    "INVENTORY_MARKDOWN = 0.15  # 15% markdown for overstocked\n",
    "\n",
    "# Seasonal clearance (example: end of Q4 for winter items)\n",
    "CLEARANCE_MARKDOWN = 0.30  # 30% markdown for clearance\n",
    "\n",
    "print(f\"Configuration: SILVER_DB={SILVER_DB}, GOLD_DB={GOLD_DB}\")\n",
    "print(f\"Constraints: Min Margin={MIN_MARGIN_PCT*100}%, Max Price=MSRP, Max Change/Week={MAX_CHANGE_PCT_WEEKLY*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def ensure_database(name):\n",
    "    spark.sql(f\"CREATE DATABASE IF NOT EXISTS {name}\")\n",
    "\n",
    "def read_silver(table_name):\n",
    "    return spark.table(f\"{SILVER_DB}.{table_name}\")\n",
    "\n",
    "def read_gold(table_name):\n",
    "    try:\n",
    "        return spark.table(f\"{GOLD_DB}.{table_name}\")\n",
    "    except AnalysisException:\n",
    "        return None\n",
    "\n",
    "def save_gold(df, table_name):\n",
    "    full_name = f\"{GOLD_DB}.{table_name}\"\n",
    "    df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(full_name)\n",
    "    print(f\"  {full_name}: {df.count()} rows\")\n",
    "\n",
    "def silver_exists(table_name):\n",
    "    try:\n",
    "        spark.table(f\"{SILVER_DB}.{table_name}\")\n",
    "        return True\n",
    "    except AnalysisException:\n",
    "        return False\n",
    "\n",
    "ensure_database(GOLD_DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PRICING CONSTRAINTS TABLE\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CREATING PRICING CONSTRAINTS TABLE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create constraints reference table for transparency and configurability\n",
    "constraints_data = [\n",
    "    {\"constraint_name\": \"min_margin_pct\", \"constraint_value\": MIN_MARGIN_PCT, \"description\": \"Minimum margin percentage (price >= cost * 1.15)\"},\n",
    "    {\"constraint_name\": \"max_price_factor\", \"constraint_value\": MAX_PRICE_FACTOR, \"description\": \"Maximum price as factor of MSRP (1.0 = cannot exceed MSRP)\"},\n",
    "    {\"constraint_name\": \"max_change_pct_weekly\", \"constraint_value\": MAX_CHANGE_PCT_WEEKLY, \"description\": \"Maximum price change per week (as percentage)\"},\n",
    "    {\"constraint_name\": \"min_duration_days\", \"constraint_value\": float(MIN_DURATION_DAYS), \"description\": \"Minimum days between price changes\"},\n",
    "    {\"constraint_name\": \"age_threshold_moderate\", \"constraint_value\": float(AGE_THRESHOLD_MODERATE), \"description\": \"Days to trigger moderate markdown\"},\n",
    "    {\"constraint_name\": \"age_threshold_aggressive\", \"constraint_value\": float(AGE_THRESHOLD_AGGRESSIVE), \"description\": \"Days to trigger aggressive markdown\"},\n",
    "    {\"constraint_name\": \"age_markdown_moderate\", \"constraint_value\": AGE_MARKDOWN_MODERATE, \"description\": \"Markdown percentage for moderate age threshold\"},\n",
    "    {\"constraint_name\": \"age_markdown_aggressive\", \"constraint_value\": AGE_MARKDOWN_AGGRESSIVE, \"description\": \"Markdown percentage for aggressive age threshold\"},\n",
    "    {\"constraint_name\": \"inventory_high_threshold\", \"constraint_value\": float(INVENTORY_HIGH_THRESHOLD), \"description\": \"Units threshold for overstocked items\"},\n",
    "    {\"constraint_name\": \"inventory_markdown\", \"constraint_value\": INVENTORY_MARKDOWN, \"description\": \"Markdown percentage for overstocked items\"},\n",
    "    {\"constraint_name\": \"clearance_markdown\", \"constraint_value\": CLEARANCE_MARKDOWN, \"description\": \"Markdown percentage for seasonal clearance\"},\n",
    "]\n",
    "\n",
    "df_constraints = spark.createDataFrame(constraints_data)\n",
    "save_gold(df_constraints, \"pricing_constraints\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LOAD SOURCE DATA\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"LOADING SOURCE DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if not silver_exists(\"dim_products\"):\n",
    "    raise Exception(\"dim_products table not found. Run 02-historical-data-load.ipynb first.\")\n",
    "\n",
    "# Load product master with pricing data\n",
    "df_products = read_silver(\"dim_products\").select(\n",
    "    F.col(\"ID\").alias(\"product_id\"),\n",
    "    \"ProductName\",\n",
    "    \"Department\",\n",
    "    \"Category\",\n",
    "    \"Subcategory\",\n",
    "    \"Cost\",\n",
    "    \"MSRP\",\n",
    "    \"SalePrice\",\n",
    "    \"Tags\"\n",
    ")\n",
    "\n",
    "print(f\"Products loaded: {df_products.count()}\")\n",
    "\n",
    "# Load current inventory positions (aggregated across all stores)\n",
    "df_inventory = None\n",
    "if silver_exists(\"fact_store_inventory_txn\"):\n",
    "    # Calculate current inventory by product across all stores\n",
    "    window_spec = Window.partitionBy(\"product_id\").orderBy(F.desc(\"event_ts\"))\n",
    "    df_inventory = (\n",
    "        read_silver(\"fact_store_inventory_txn\")\n",
    "        .withColumn(\"rn\", F.row_number().over(window_spec))\n",
    "        .filter(F.col(\"rn\") == 1)\n",
    "        .groupBy(\"product_id\")\n",
    "        .agg(\n",
    "            F.sum(\"balance\").alias(\"total_inventory\"),\n",
    "            F.max(\"event_ts\").alias(\"inventory_as_of\")\n",
    "        )\n",
    "    )\n",
    "    print(f\"Inventory positions loaded: {df_inventory.count()}\")\n",
    "else:\n",
    "    print(\"No inventory data available - using product data only\")\n",
    "\n",
    "# Load previous pricing recommendations to check duration constraint\n",
    "df_previous_prices = read_gold(\"gold_pricing_recommendations\")\n",
    "if df_previous_prices:\n",
    "    print(f\"Previous pricing recommendations loaded: {df_previous_prices.count()}\")\n",
    "else:\n",
    "    print(\"No previous pricing recommendations - first run\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CALCULATE PRODUCT AGE\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CALCULATING PRODUCT AGE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# For this phase, simulate product age based on receipt data\n",
    "# In a real system, this would come from a product lifecycle table\n",
    "df_product_age = None\n",
    "\n",
    "if silver_exists(\"fact_receipt_lines\"):\n",
    "    # Calculate days since first receipt for each product\n",
    "    df_product_age = (\n",
    "        read_silver(\"fact_receipt_lines\")\n",
    "        .groupBy(\"product_id\")\n",
    "        .agg(\n",
    "            F.min(\"event_ts\").alias(\"first_receipt_ts\"),\n",
    "            F.max(\"event_ts\").alias(\"last_receipt_ts\")\n",
    "        )\n",
    "        .withColumn(\"current_ts\", F.current_timestamp())\n",
    "        .withColumn(\n",
    "            \"days_since_first_receipt\",\n",
    "            F.datediff(F.col(\"current_ts\"), F.col(\"first_receipt_ts\"))\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"days_since_last_receipt\",\n",
    "            F.datediff(F.col(\"current_ts\"), F.col(\"last_receipt_ts\"))\n",
    "        )\n",
    "        .select(\"product_id\", \"days_since_first_receipt\", \"days_since_last_receipt\")\n",
    "    )\n",
    "    print(f\"Product age calculated for {df_product_age.count()} products\")\n",
    "else:\n",
    "    print(\"No receipt data - product age will be 0\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# APPLY RULE-BASED MARKDOWN LOGIC\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"APPLYING RULE-BASED MARKDOWN LOGIC\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Start with product master\n",
    "df_pricing = df_products\n",
    "\n",
    "# Join with inventory if available\n",
    "if df_inventory is not None:\n",
    "    df_pricing = df_pricing.join(df_inventory, \"product_id\", \"left\")\n",
    "else:\n",
    "    df_pricing = df_pricing.withColumn(\"total_inventory\", F.lit(None).cast(\"long\"))\n",
    "    df_pricing = df_pricing.withColumn(\"inventory_as_of\", F.lit(None).cast(\"timestamp\"))\n",
    "\n",
    "# Join with product age if available\n",
    "if df_product_age is not None:\n",
    "    df_pricing = df_pricing.join(df_product_age, \"product_id\", \"left\")\n",
    "else:\n",
    "    df_pricing = df_pricing.withColumn(\"days_since_first_receipt\", F.lit(0))\n",
    "    df_pricing = df_pricing.withColumn(\"days_since_last_receipt\", F.lit(0))\n",
    "\n",
    "# Initialize markdown factors and reason codes\n",
    "df_pricing = df_pricing.withColumn(\"markdown_factor\", F.lit(0.0))\n",
    "df_pricing = df_pricing.withColumn(\"reason_codes\", F.array())\n",
    "\n",
    "# Rule 1: Age-based markdowns\n",
    "df_pricing = df_pricing.withColumn(\n",
    "    \"age_markdown\",\n",
    "    F.when(\n",
    "        F.col(\"days_since_last_receipt\") >= AGE_THRESHOLD_AGGRESSIVE,\n",
    "        F.lit(AGE_MARKDOWN_AGGRESSIVE)\n",
    "    ).when(\n",
    "        F.col(\"days_since_last_receipt\") >= AGE_THRESHOLD_MODERATE,\n",
    "        F.lit(AGE_MARKDOWN_MODERATE)\n",
    "    ).otherwise(F.lit(0.0))\n",
    ")\n",
    "\n",
    "df_pricing = df_pricing.withColumn(\n",
    "    \"markdown_factor\",\n",
    "    F.greatest(F.col(\"markdown_factor\"), F.col(\"age_markdown\"))\n",
    ")\n",
    "\n",
    "df_pricing = df_pricing.withColumn(\n",
    "    \"reason_codes\",\n",
    "    F.when(\n",
    "        F.col(\"age_markdown\") == AGE_MARKDOWN_AGGRESSIVE,\n",
    "        F.array_union(F.col(\"reason_codes\"), F.array(F.lit(\"AGE_AGGRESSIVE\")))\n",
    "    ).when(\n",
    "        F.col(\"age_markdown\") == AGE_MARKDOWN_MODERATE,\n",
    "        F.array_union(F.col(\"reason_codes\"), F.array(F.lit(\"AGE_MODERATE\")))\n",
    "    ).otherwise(F.col(\"reason_codes\"))\n",
    ")\n",
    "\n",
    "# Rule 2: Inventory-based markdowns\n",
    "df_pricing = df_pricing.withColumn(\n",
    "    \"inventory_markdown\",\n",
    "    F.when(\n",
    "        F.col(\"total_inventory\") >= INVENTORY_HIGH_THRESHOLD,\n",
    "        F.lit(INVENTORY_MARKDOWN)\n",
    "    ).otherwise(F.lit(0.0))\n",
    ")\n",
    "\n",
    "df_pricing = df_pricing.withColumn(\n",
    "    \"markdown_factor\",\n",
    "    F.greatest(F.col(\"markdown_factor\"), F.col(\"inventory_markdown\"))\n",
    ")\n",
    "\n",
    "df_pricing = df_pricing.withColumn(\n",
    "    \"reason_codes\",\n",
    "    F.when(\n",
    "        F.col(\"inventory_markdown\") > 0,\n",
    "        F.array_union(F.col(\"reason_codes\"), F.array(F.lit(\"INVENTORY_HIGH\")))\n",
    "    ).otherwise(F.col(\"reason_codes\"))\n",
    ")\n",
    "\n",
    "# Rule 3: Seasonal clearance (example: products tagged with winter/holiday in Q1)\n",
    "current_month = datetime.now(timezone.utc).month\n",
    "is_clearance_period = current_month in [1, 2, 3]  # Q1 for winter clearance\n",
    "\n",
    "if is_clearance_period:\n",
    "    df_pricing = df_pricing.withColumn(\n",
    "        \"seasonal_markdown\",\n",
    "        F.when(\n",
    "            (F.col(\"Tags\").isNotNull()) & \n",
    "            ((F.lower(F.col(\"Tags\")).contains(\"winter\")) | \n",
    "             (F.lower(F.col(\"Tags\")).contains(\"holiday\"))),\n",
    "            F.lit(CLEARANCE_MARKDOWN)\n",
    "        ).otherwise(F.lit(0.0))\n",
    "    )\n",
    "    \n",
    "    df_pricing = df_pricing.withColumn(\n",
    "        \"markdown_factor\",\n",
    "        F.greatest(F.col(\"markdown_factor\"), F.col(\"seasonal_markdown\"))\n",
    "    )\n",
    "    \n",
    "    df_pricing = df_pricing.withColumn(\n",
    "        \"reason_codes\",\n",
    "        F.when(\n",
    "            F.col(\"seasonal_markdown\") > 0,\n",
    "            F.array_union(F.col(\"reason_codes\"), F.array(F.lit(\"SEASONAL_CLEARANCE\")))\n",
    "        ).otherwise(F.col(\"reason_codes\"))\n",
    "    )\n",
    "\n",
    "# Calculate recommended price before constraints\n",
    "df_pricing = df_pricing.withColumn(\n",
    "    \"recommended_price_raw\",\n",
    "    F.col(\"SalePrice\") * (1 - F.col(\"markdown_factor\"))\n",
    ")\n",
    "\n",
    "print(f\"Markdown logic applied to {df_pricing.count()} products\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# APPLY BUSINESS CONSTRAINTS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"APPLYING BUSINESS CONSTRAINTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Constraint 1: Minimum margin (price >= cost * 1.15)\n",
    "df_pricing = df_pricing.withColumn(\n",
    "    \"min_price\",\n",
    "    F.col(\"Cost\") * (1 + MIN_MARGIN_PCT)\n",
    ")\n",
    "\n",
    "# Constraint 2: Maximum price (cannot exceed MSRP)\n",
    "df_pricing = df_pricing.withColumn(\n",
    "    \"max_price\",\n",
    "    F.col(\"MSRP\") * MAX_PRICE_FACTOR\n",
    ")\n",
    "\n",
    "# Apply min/max constraints\n",
    "df_pricing = df_pricing.withColumn(\n",
    "    \"recommended_price\",\n",
    "    F.greatest(\n",
    "        F.col(\"min_price\"),\n",
    "        F.least(F.col(\"recommended_price_raw\"), F.col(\"max_price\"))\n",
    "    )\n",
    ")\n",
    "\n",
    "# Track constraint violations\n",
    "df_pricing = df_pricing.withColumn(\n",
    "    \"hit_min_margin\",\n",
    "    F.col(\"recommended_price_raw\") < F.col(\"min_price\")\n",
    ")\n",
    "\n",
    "df_pricing = df_pricing.withColumn(\n",
    "    \"hit_max_price\",\n",
    "    F.col(\"recommended_price_raw\") > F.col(\"max_price\")\n",
    ")\n",
    "\n",
    "# Add constraint violation to reason codes\n",
    "df_pricing = df_pricing.withColumn(\n",
    "    \"reason_codes\",\n",
    "    F.when(\n",
    "        F.col(\"hit_min_margin\"),\n",
    "        F.array_union(F.col(\"reason_codes\"), F.array(F.lit(\"CONSTRAINT_MIN_MARGIN\")))\n",
    "    ).otherwise(F.col(\"reason_codes\"))\n",
    ")\n",
    "\n",
    "df_pricing = df_pricing.withColumn(\n",
    "    \"reason_codes\",\n",
    "    F.when(\n",
    "        F.col(\"hit_max_price\"),\n",
    "        F.array_union(F.col(\"reason_codes\"), F.array(F.lit(\"CONSTRAINT_MAX_PRICE\")))\n",
    "    ).otherwise(F.col(\"reason_codes\"))\n",
    ")\n",
    "\n",
    "# Constraint 3: Max change per week (10%)\n",
    "# For first run, we don't have previous prices, so this check is skipped\n",
    "if df_previous_prices is not None:\n",
    "    df_prev = df_previous_prices.select(\n",
    "        \"product_id\",\n",
    "        F.col(\"recommended_price\").alias(\"previous_price\"),\n",
    "        F.col(\"recommendation_ts\").alias(\"previous_ts\")\n",
    "    )\n",
    "    \n",
    "    df_pricing = df_pricing.join(df_prev, \"product_id\", \"left\")\n",
    "    \n",
    "    df_pricing = df_pricing.withColumn(\n",
    "        \"days_since_last_change\",\n",
    "        F.datediff(F.current_timestamp(), F.col(\"previous_ts\"))\n",
    "    )\n",
    "    \n",
    "    # Check if change exceeds 10% and duration < 7 days\n",
    "    df_pricing = df_pricing.withColumn(\n",
    "        \"change_pct\",\n",
    "        F.abs((F.col(\"recommended_price\") - F.col(\"previous_price\")) / F.col(\"previous_price\"))\n",
    "    )\n",
    "    \n",
    "    df_pricing = df_pricing.withColumn(\n",
    "        \"violates_max_change\",\n",
    "        (F.col(\"change_pct\") > MAX_CHANGE_PCT_WEEKLY) & \n",
    "        (F.col(\"days_since_last_change\") < MIN_DURATION_DAYS)\n",
    "    )\n",
    "    \n",
    "    # If violates, keep previous price\n",
    "    df_pricing = df_pricing.withColumn(\n",
    "        \"recommended_price\",\n",
    "        F.when(\n",
    "            F.col(\"violates_max_change\") & F.col(\"previous_price\").isNotNull(),\n",
    "            F.col(\"previous_price\")\n",
    "        ).otherwise(F.col(\"recommended_price\"))\n",
    "    )\n",
    "    \n",
    "    df_pricing = df_pricing.withColumn(\n",
    "        \"reason_codes\",\n",
    "        F.when(\n",
    "            F.col(\"violates_max_change\"),\n",
    "            F.array_union(F.col(\"reason_codes\"), F.array(F.lit(\"CONSTRAINT_MAX_CHANGE\")))\n",
    "        ).otherwise(F.col(\"reason_codes\"))\n",
    "    )\n",
    "else:\n",
    "    df_pricing = df_pricing.withColumn(\"previous_price\", F.lit(None).cast(\"decimal(10,2)\"))\n",
    "    df_pricing = df_pricing.withColumn(\"previous_ts\", F.lit(None).cast(\"timestamp\"))\n",
    "    df_pricing = df_pricing.withColumn(\"days_since_last_change\", F.lit(None).cast(\"int\"))\n",
    "    df_pricing = df_pricing.withColumn(\"change_pct\", F.lit(None).cast(\"decimal(5,2)\"))\n",
    "    df_pricing = df_pricing.withColumn(\"violates_max_change\", F.lit(False))\n",
    "\n",
    "print(f\"Constraints applied to {df_pricing.count()} products\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CREATE OUTPUT TABLE\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CREATING PRICING RECOMMENDATIONS OUTPUT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Add no-change reason for products that don't need markdown\n",
    "df_pricing = df_pricing.withColumn(\n",
    "    \"reason_codes\",\n",
    "    F.when(\n",
    "        F.size(F.col(\"reason_codes\")) == 0,\n",
    "        F.array(F.lit(\"NO_CHANGE\"))\n",
    "    ).otherwise(F.col(\"reason_codes\"))\n",
    ")\n",
    "\n",
    "# Create final output with extensible schema for future ML phases\n",
    "df_output = df_pricing.select(\n",
    "    \"product_id\",\n",
    "    \"ProductName\",\n",
    "    \"Department\",\n",
    "    \"Category\",\n",
    "    \"Subcategory\",\n",
    "    F.col(\"Cost\").alias(\"cost\"),\n",
    "    F.col(\"MSRP\").alias(\"msrp\"),\n",
    "    F.col(\"SalePrice\").alias(\"current_price\"),\n",
    "    F.col(\"recommended_price\"),\n",
    "    F.round((F.col(\"recommended_price\") - F.col(\"SalePrice\")) / F.col(\"SalePrice\") * 100, 2).alias(\"change_pct\"),\n",
    "    F.col(\"reason_codes\"),\n",
    "    F.col(\"markdown_factor\"),\n",
    "    F.col(\"total_inventory\"),\n",
    "    F.col(\"days_since_last_receipt\"),\n",
    "    F.col(\"hit_min_margin\"),\n",
    "    F.col(\"hit_max_price\"),\n",
    "    F.col(\"violates_max_change\"),\n",
    "    F.lit(\"RULE_BASED\").alias(\"model_type\"),\n",
    "    F.lit(None).cast(\"decimal(5,4)\").alias(\"ml_confidence\"),  # Placeholder for Phase 2\n",
    "    F.current_timestamp().alias(\"recommendation_ts\"),\n",
    "    F.lit(\"1.0\").alias(\"schema_version\")\n",
    ")\n",
    "\n",
    "save_gold(df_output, \"gold_pricing_recommendations\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SUMMARY STATISTICS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PRICING RECOMMENDATIONS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "total_products = df_output.count()\n",
    "print(f\"\\nTotal products analyzed: {total_products}\")\n",
    "\n",
    "# Count by reason code\n",
    "print(\"\\nRecommendations by reason:\")\n",
    "df_reasons = df_output.select(F.explode(\"reason_codes\").alias(\"reason\"))\n",
    "df_reasons.groupBy(\"reason\").count().orderBy(F.desc(\"count\")).show(truncate=False)\n",
    "\n",
    "# Count constraint violations\n",
    "print(\"\\nConstraint violations:\")\n",
    "min_margin_hits = df_output.filter(F.col(\"hit_min_margin\")).count()\n",
    "max_price_hits = df_output.filter(F.col(\"hit_max_price\")).count()\n",
    "max_change_hits = df_output.filter(F.col(\"violates_max_change\")).count()\n",
    "\n",
    "print(f\"  Min margin: {min_margin_hits} products\")\n",
    "print(f\"  Max price: {max_price_hits} products\")\n",
    "print(f\"  Max change/week: {max_change_hits} products\")\n",
    "\n",
    "# Price change distribution\n",
    "print(\"\\nPrice change distribution:\")\n",
    "df_output.select(\n",
    "    F.avg(\"change_pct\").alias(\"avg_change_pct\"),\n",
    "    F.min(\"change_pct\").alias(\"min_change_pct\"),\n",
    "    F.max(\"change_pct\").alias(\"max_change_pct\")\n",
    ").show()\n",
    "\n",
    "# Products with significant markdowns\n",
    "significant_markdowns = df_output.filter(F.col(\"change_pct\") < -5).count()\n",
    "print(f\"\\nProducts with >5% markdown: {significant_markdowns}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DYNAMIC PRICING PHASE 1 COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"  - Review recommendations in gold_pricing_recommendations table\")\n",
    "print(\"  - Validate constraint logic with business stakeholders\")\n",
    "print(\"  - Phase 2: Add ML model for demand forecasting\")\n",
    "print(\"  - Phase 3: Add competitor price intelligence\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
