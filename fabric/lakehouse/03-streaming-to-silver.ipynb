{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Streaming to Silver\n",
    "\n",
    "Incrementally processes real-time events from Eventhouse (cusn schema) to Silver Delta tables.\n",
    "\n",
    "## Data Flow\n",
    "```\n",
    "Tables/cusn.* (Eventhouse) --> Silver (Delta)\n",
    "```\n",
    "\n",
    "## Usage\n",
    "Schedule this notebook to run **every 5 minutes** via Fabric pipeline.\n",
    "\n",
    "Uses watermarks stored in `ag._watermarks` to track last processed timestamp per table.\n",
    "\n",
    "## Column Naming Convention\n",
    "All column names use `snake_case` throughout the data pipeline:\n",
    "- Aligns with Python (PEP 8), KQL tables, and datagen output\n",
    "- Examples: `event_ts`, `receipt_id_ext`, `customer_id`, `store_id`\n",
    "- See CLAUDE.md for full convention documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "from datetime import datetime, timezone\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PARAMETERS\n",
    "# =============================================================================\n",
    "\n",
    "def get_env(var_name, default=None):\n",
    "    return os.environ.get(var_name, default)\n",
    "\n",
    "SILVER_DB = get_env(\"SILVER_DB\", default=\"ag\")\n",
    "BRONZE_SCHEMA = get_env(\"BRONZE_SCHEMA\", default=\"cusn\")\n",
    "WATERMARK_TABLE = f\"{SILVER_DB}._watermarks\"\n",
    "\n",
    "print(f\"Configuration: SILVER_DB={SILVER_DB}, BRONZE_SCHEMA={BRONZE_SCHEMA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# WATERMARK MANAGEMENT\n",
    "# =============================================================================\n",
    "\n",
    "def ensure_watermark_table():\n",
    "    spark.sql(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {WATERMARK_TABLE} (\n",
    "            source_table STRING,\n",
    "            last_processed_ts TIMESTAMP,\n",
    "            updated_at TIMESTAMP\n",
    "        )\n",
    "        USING DELTA\n",
    "    \"\"\")\n",
    "    print(f\"Watermark table: {WATERMARK_TABLE}\")\n",
    "\n",
    "def get_watermark(source_table):\n",
    "    try:\n",
    "        result = spark.sql(f\"\"\"\n",
    "            SELECT last_processed_ts \n",
    "            FROM {WATERMARK_TABLE} \n",
    "            WHERE source_table = '{source_table}'\n",
    "        \"\"\").collect()\n",
    "        if result:\n",
    "            return result[0][0]\n",
    "    except Exception:\n",
    "        pass\n",
    "    return datetime(1970, 1, 1, tzinfo=timezone.utc)\n",
    "\n",
    "def update_watermark(source_table, new_ts):\n",
    "    now = datetime.now(timezone.utc)\n",
    "    spark.sql(f\"\"\"\n",
    "        MERGE INTO {WATERMARK_TABLE} AS target\n",
    "        USING (SELECT '{source_table}' AS source_table) AS source\n",
    "        ON target.source_table = source.source_table\n",
    "        WHEN MATCHED THEN UPDATE SET \n",
    "            last_processed_ts = '{new_ts}',\n",
    "            updated_at = '{now}'\n",
    "        WHEN NOT MATCHED THEN INSERT \n",
    "            (source_table, last_processed_ts, updated_at)\n",
    "            VALUES ('{source_table}', '{new_ts}', '{now}')\n",
    "    \"\"\")\n",
    "\n",
    "ensure_watermark_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def cast_id_columns(df):\n",
    "    \"\"\"Cast ID columns to proper integer types to fix type mismatches.\"\"\"\n",
    "    \n",
    "    # Define ID columns that should be int64/long\n",
    "    id_columns_to_cast = {\n",
    "        # Dimension IDs\n",
    "        \"store_id\": \"long\",\n",
    "        \"dc_id\": \"long\", \n",
    "        \"truck_id\": \"long\",\n",
    "        \"customer_id\": \"long\",\n",
    "        \"product_id\": \"long\",\n",
    "        \"geography_id\": \"long\",\n",
    "        \n",
    "        # Other numeric IDs\n",
    "        \"line_number\": \"int\",\n",
    "        \"line_num\": \"int\",\n",
    "        \"quantity\": \"int\",\n",
    "        \"count\": \"int\",\n",
    "        \"item_count\": \"int\",\n",
    "        \"dwell_seconds\": \"int\",\n",
    "        \"rssi\": \"int\"\n",
    "    }\n",
    "    \n",
    "    # Cast columns if they exist in the dataframe\n",
    "    for col_name, col_type in id_columns_to_cast.items():\n",
    "        if col_name in df.columns:\n",
    "            df = df.withColumn(col_name, F.col(col_name).cast(col_type))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def streaming_table_exists(table_name):\n",
    "    try:\n",
    "        spark.table(f\"{BRONZE_SCHEMA}.{table_name}\")\n",
    "        return True\n",
    "    except AnalysisException:\n",
    "        return False\n",
    "\n",
    "def process_events(source_table, target_table, transform_fn, ts_col=\"ingest_timestamp\"):\n",
    "    \"\"\"\n",
    "    Process new events from Eventhouse and append to Silver.\n",
    "    \n",
    "    Args:\n",
    "        source_table: Eventhouse source (e.g., \"receipt_created\")\n",
    "        target_table: Silver target (e.g., \"fact_receipts\")\n",
    "        transform_fn: Schema transformation function\n",
    "        ts_col: Timestamp column for watermarking\n",
    "    \"\"\"\n",
    "    print(f\"\\n{BRONZE_SCHEMA}.{source_table} -> {SILVER_DB}.{target_table}\")\n",
    "    \n",
    "    if not streaming_table_exists(source_table):\n",
    "        print(f\"  Skipping: source not found\")\n",
    "        return 0\n",
    "    \n",
    "    last_ts = get_watermark(source_table)\n",
    "    print(f\"  Watermark: {last_ts}\")\n",
    "    \n",
    "    df_stream = spark.table(f\"{BRONZE_SCHEMA}.{source_table}\")\n",
    "    df_new = df_stream.filter(F.col(ts_col) > last_ts)\n",
    "    \n",
    "    new_count = df_new.count()\n",
    "    if new_count == 0:\n",
    "        print(f\"  No new events\")\n",
    "        return 0\n",
    "    \n",
    "    print(f\"  Processing {new_count} events\")\n",
    "    \n",
    "    # Transform and cast ID columns\n",
    "    df_transformed = transform_fn(df_new)\n",
    "    df_transformed = cast_id_columns(df_transformed)\n",
    "    \n",
    "    df_transformed.write.format(\"delta\").mode(\"append\").saveAsTable(f\"{SILVER_DB}.{target_table}\")\n",
    "    \n",
    "    max_ts = df_new.agg(F.max(ts_col)).collect()[0][0]\n",
    "    update_watermark(source_table, max_ts)\n",
    "    print(f\"  Appended {new_count} rows, watermark -> {max_ts}\")\n",
    "    \n",
    "    return new_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# TRANSFORM FUNCTIONS\n# =============================================================================\n\nDEFAULT_RECEIPT_TYPE = \"SALE\"\nDEFAULT_DISCOUNT = 0.0\n\ndef transform_receipt_created(df):\n    return df.select(\n        F.col(\"ingest_timestamp\").alias(\"event_ts\"),\n        F.col(\"receipt_id\").alias(\"receipt_id_ext\"),\n        F.col(\"tender_type\").alias(\"payment_method\"),\n        F.lit(DEFAULT_DISCOUNT).cast(\"string\").alias(\"discount_amount\"),\n        F.col(\"tax\"),\n        F.round(F.col(\"tax\") * 100).cast(\"bigint\").alias(\"tax_cents\"),\n        F.col(\"subtotal\"),\n        F.col(\"total\"),\n        F.round(F.col(\"total\") * 100).cast(\"bigint\").alias(\"total_cents\"),\n        F.lit(DEFAULT_RECEIPT_TYPE).alias(\"receipt_type\"),\n        F.round(F.col(\"subtotal\") * 100).cast(\"bigint\").alias(\"subtotal_cents\"),\n        F.col(\"customer_id\").cast(\"long\"),\n        F.col(\"store_id\").cast(\"long\"),\n        F.lit(None).cast(\"string\").alias(\"return_for_receipt_id_ext\")\n    )\n\ndef transform_receipt_line_added(df):\n    return df.select(\n        F.col(\"receipt_id\").alias(\"receipt_id_ext\"),\n        F.col(\"ingest_timestamp\").alias(\"event_ts\"),\n        F.col(\"product_id\").cast(\"long\"),\n        F.col(\"line_number\").cast(\"int\").alias(\"line_num\"),\n        F.col(\"quantity\").cast(\"int\"),\n        F.col(\"unit_price\"),\n        F.col(\"extended_price\").alias(\"ext_price\"),\n        F.round(F.col(\"unit_price\") * 100).cast(\"bigint\").alias(\"unit_cents\"),\n        F.round(F.col(\"extended_price\") * 100).cast(\"bigint\").alias(\"ext_cents\"),\n        F.col(\"promo_code\")\n    )\n\ndef transform_payment_processed(df):\n    return df.select(\n        F.col(\"ingest_timestamp\").alias(\"event_ts\"),\n        F.col(\"transaction_id\").alias(\"payment_id\"),\n        F.col(\"receipt_id\"),\n        F.col(\"payment_method\").alias(\"tender_type\"),\n        F.col(\"amount\"),\n        F.round(F.col(\"amount\") * 100).cast(\"bigint\").alias(\"amount_cents\")\n    )\n\ndef transform_inventory_updated(df):\n    return df.select(\n        F.col(\"ingest_timestamp\").alias(\"event_ts\"),\n        F.col(\"store_id\").cast(\"long\"),\n        F.col(\"product_id\").cast(\"long\"),\n        F.col(\"quantity_delta\").alias(\"delta\"),\n        F.lit(None).cast(\"long\").alias(\"balance\"),  # Balance calculated later\n        F.col(\"reason\")\n    )\n\ndef transform_customer_entered(df):\n    return df.select(\n        F.col(\"ingest_timestamp\").alias(\"event_ts\"),\n        F.col(\"store_id\").cast(\"long\"),\n        F.lit(None).cast(\"long\").alias(\"customer_id\"),  # Not always available\n        F.col(\"zone\"),\n        F.col(\"dwell_time\").cast(\"int\").alias(\"dwell_seconds\"),\n        F.col(\"customer_count\").cast(\"int\").alias(\"count\")\n    )\n\ndef transform_truck_arrived(df):\n    return df.select(\n        F.col(\"ingest_timestamp\").alias(\"event_ts\"),\n        F.col(\"truck_id\"),\n        F.col(\"dc_id\").cast(\"long\"),\n        F.col(\"store_id\").cast(\"long\"),\n        F.col(\"shipment_id\"),\n        F.col(\"arrival_time\").alias(\"eta\"),\n        F.lit(None).cast(\"timestamp\").alias(\"etd\"),\n        F.lit(\"ARRIVED\").alias(\"status\")\n    )\n\ndef transform_truck_departed(df):\n    return df.select(\n        F.col(\"ingest_timestamp\").alias(\"event_ts\"),\n        F.col(\"truck_id\"),\n        F.col(\"dc_id\").cast(\"long\"),\n        F.col(\"store_id\").cast(\"long\"),\n        F.col(\"shipment_id\"),\n        F.lit(None).cast(\"timestamp\").alias(\"eta\"),\n        F.col(\"departure_time\").alias(\"etd\"),\n        F.lit(\"DEPARTED\").alias(\"status\")\n    )\n\ndef transform_stockout_detected(df):\n    return df.select(\n        F.col(\"ingest_timestamp\").alias(\"event_ts\"),\n        F.col(\"store_id\").cast(\"long\"),\n        F.col(\"dc_id\").cast(\"long\"),\n        F.col(\"product_id\").cast(\"long\"),\n        F.col(\"last_known_quantity\").cast(\"int\"),\n        F.col(\"detection_time\"),\n        F.col(\"trace_id\")\n    )\n\ndef transform_reorder_triggered(df):\n    return df.select(\n        F.col(\"ingest_timestamp\").alias(\"event_ts\"),\n        F.col(\"store_id\").cast(\"long\"),\n        F.col(\"dc_id\").cast(\"long\"),\n        F.col(\"product_id\").cast(\"long\"),\n        F.col(\"quantity_ordered\").cast(\"int\"),\n        F.col(\"reorder_point\").cast(\"int\"),\n        F.col(\"trace_id\")\n    )\n\ndef transform_store_operation(df, operation_type: str):\n    return df.select(\n        F.col(\"ingest_timestamp\").alias(\"event_ts\"),\n        F.col(\"store_id\").cast(\"long\"),\n        F.col(\"operation_time\"),\n        F.lit(operation_type).alias(\"operation_type\"),\n        F.col(\"trace_id\")\n    )\n\ndef transform_ad_impression(df):\n    return df.select(\n        F.col(\"ingest_timestamp\").alias(\"event_ts\"),\n        F.col(\"channel\"),\n        F.col(\"campaign_id\"),\n        F.col(\"creative_id\"),\n        F.col(\"customer_ad_id\"),\n        F.col(\"impression_id\").alias(\"impression_id_ext\"),\n        F.col(\"cost\"),\n        F.round(F.col(\"cost\") * 100).cast(\"bigint\").alias(\"cost_cents\"),\n        F.col(\"device_type\").alias(\"device\")\n    )\n\ndef transform_promotion_applied(df):\n    return df.select(\n        F.col(\"ingest_timestamp\").alias(\"event_ts\"),\n        F.col(\"promo_code\"),\n        F.col(\"store_id\").cast(\"long\"),\n        F.col(\"product_ids\"),\n        F.col(\"discount_amount\"),\n        F.col(\"discount_type\"),\n        F.col(\"receipt_id\"),\n        F.col(\"trace_id\")\n    )\n\ndef transform_customer_zone_changed(df):\n    return df.select(\n        F.col(\"ingest_timestamp\").alias(\"event_ts\"),\n        F.col(\"store_id\").cast(\"long\"),\n        F.col(\"customer_ble_id\"),\n        F.col(\"from_zone\"),\n        F.col(\"to_zone\"),\n        F.col(\"trace_id\")\n    )\n\ndef transform_ble_ping(df):\n    return df.select(\n        F.col(\"ingest_timestamp\").alias(\"event_ts\"),\n        F.col(\"store_id\").cast(\"long\"),\n        F.col(\"beacon_id\"),\n        F.col(\"customer_ble_id\"),\n        F.col(\"rssi\").cast(\"int\"),\n        F.col(\"zone\"),\n        F.col(\"trace_id\"),\n        F.lit(None).cast(\"long\").alias(\"customer_id\")\n    )\n\ndef transform_online_order_created(df):\n    return df.select(\n        F.col(\"ingest_timestamp\").alias(\"event_ts\"),\n        F.col(\"order_id\").alias(\"order_id_ext\"),\n        F.col(\"customer_id\").cast(\"long\"),\n        F.col(\"fulfillment_mode\"),\n        F.col(\"node_type\"),\n        F.col(\"node_id\").cast(\"long\"),\n        F.col(\"item_count\").cast(\"int\"),\n        F.col(\"subtotal\").alias(\"subtotal_amount\"),\n        F.col(\"tax\").alias(\"tax_amount\"),\n        F.col(\"total\").alias(\"total_amount\"),\n        F.col(\"tender_type\")\n    )\n\ndef transform_online_order_picked(df):\n    return df.select(\n        F.col(\"ingest_timestamp\").alias(\"event_ts\"),\n        F.col(\"order_id\").alias(\"order_id_ext\"),\n        F.col(\"node_type\"),\n        F.col(\"node_id\").cast(\"long\"),\n        F.col(\"fulfillment_mode\"),\n        F.col(\"picked_time\"),\n        F.lit(\"PICKED\").alias(\"status\")\n    )\n\ndef transform_online_order_shipped(df):\n    return df.select(\n        F.col(\"ingest_timestamp\").alias(\"event_ts\"),\n        F.col(\"order_id\").alias(\"order_id_ext\"),\n        F.col(\"node_type\"),\n        F.col(\"node_id\").cast(\"long\"),\n        F.col(\"fulfillment_mode\"),\n        F.col(\"shipped_time\"),\n        F.lit(\"SHIPPED\").alias(\"status\")\n    )"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\"*60)\nprint(\"STREAMING TO SILVER\")\nprint(\"=\"*60)\n\ntotal = 0\n\n# Transaction events\ntotal += process_events(\"receipt_created\", \"fact_receipts\", transform_receipt_created)\ntotal += process_events(\"receipt_line_added\", \"fact_receipt_lines\", transform_receipt_line_added)\ntotal += process_events(\"payment_processed\", \"fact_payments\", transform_payment_processed)\n\n# Inventory events\ntotal += process_events(\"inventory_updated\", \"fact_store_inventory_txn\", transform_inventory_updated)\n\n# Customer events\ntotal += process_events(\"customer_entered\", \"fact_foot_traffic\", transform_customer_entered)\n\n# Truck events\ntotal += process_events(\"truck_arrived\", \"fact_truck_moves\", transform_truck_arrived)\ntotal += process_events(\"truck_departed\", \"fact_truck_moves\", transform_truck_departed)\n\n# Inventory alert events\ntotal += process_events(\"stockout_detected\", \"fact_stockouts\", transform_stockout_detected)\ntotal += process_events(\"reorder_triggered\", \"fact_reorders\", transform_reorder_triggered)\n\n# Store operations events\ntotal += process_events(\"store_opened\", \"fact_store_ops\", lambda df: transform_store_operation(df, \"OPENED\"))\ntotal += process_events(\"store_closed\", \"fact_store_ops\", lambda df: transform_store_operation(df, \"CLOSED\"))\n\n# Marketing events\ntotal += process_events(\"ad_impression\", \"fact_marketing\", transform_ad_impression)\ntotal += process_events(\"promotion_applied\", \"fact_promotions\", transform_promotion_applied)\n\n# Customer tracking events\ntotal += process_events(\"customer_zone_changed\", \"fact_zone_changes\", transform_customer_zone_changed)\ntotal += process_events(\"ble_ping_detected\", \"fact_ble_pings\", transform_ble_ping)\n\n# Online order events\ntotal += process_events(\"online_order_created\", \"fact_online_orders\", transform_online_order_created)\ntotal += process_events(\"online_order_picked\", \"fact_online_order_status\", transform_online_order_picked)\ntotal += process_events(\"online_order_shipped\", \"fact_online_order_status\", transform_online_order_shipped)\n\nprint(\"\\n\" + \"=\"*60)\nprint(f\"COMPLETE: {total} events processed\")\nprint(\"=\"*60)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show watermarks\n",
    "print(\"\\nCurrent Watermarks:\")\n",
    "spark.table(WATERMARK_TABLE).show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}