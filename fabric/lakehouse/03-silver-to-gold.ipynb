{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 03 Silver to Gold\n\nCreates Gold layer aggregated tables from Silver Delta tables.\n\n**Prerequisites:**\n- Run `02-onelake-to-silver.ipynb` first to populate Silver tables\n\n**Gold Tables Created:**\n- Sales aggregates (minute, daily)\n- Inventory position (current snapshot)\n- Fulfillment metrics\n- Marketing/campaign metrics\n- Zone dwell and BLE presence\n\n**Note:** Some tables depend on fact tables not yet implemented (stockouts, reorders, promotions, store_ops). These are stubbed but will be empty until datagen is updated."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from datetime import datetime\n",
    "\n",
    "# Database names\n",
    "SILVER_DB = \"ag\"\n",
    "GOLD_DB = \"ag_gold\"\n",
    "\n",
    "def ensure_database(name):\n",
    "    spark.sql(f\"CREATE DATABASE IF NOT EXISTS {name}\")\n",
    "\n",
    "def save_gold_table(df, table_name, mode=\"overwrite\"):\n",
    "    full_name = f\"{GOLD_DB}.{table_name}\"\n",
    "    df.write.format(\"delta\").mode(mode).saveAsTable(full_name)\n",
    "    print(f\"  Written to {full_name}: {df.count()} rows\")\n",
    "\n",
    "def read_silver(table_name):\n",
    "    return spark.table(f\"{SILVER_DB}.{table_name}\")\n",
    "\n",
    "def table_exists(db, table):\n",
    "    try:\n",
    "        spark.table(f\"{db}.{table}\")\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "ensure_database(GOLD_DB)\n",
    "print(f\"Gold database ready: {GOLD_DB}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sales Aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gold_sales_minute_store - Sales by minute per store\n",
    "print(\"Creating gold_sales_minute_store...\")\n",
    "try:\n",
    "    df_receipts = read_silver(\"fact_receipts\")\n",
    "    \n",
    "    df_sales_minute = (\n",
    "        df_receipts\n",
    "        .withColumn(\"ts\", F.date_trunc(\"minute\", F.col(\"event_ts\")))\n",
    "        .groupBy(\"store_id\", \"ts\")\n",
    "        .agg(\n",
    "            F.sum(\"total\").alias(\"total_sales\"),\n",
    "            F.count(\"*\").alias(\"receipts\"),\n",
    "            F.avg(\"total\").alias(\"avg_basket\")\n",
    "        )\n",
    "        .orderBy(\"store_id\", \"ts\")\n",
    "    )\n",
    "    \n",
    "    save_gold_table(df_sales_minute, \"gold_sales_minute_store\")\n",
    "except Exception as e:\n",
    "    print(f\"  Skipping: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gold_top_products_15m - Top products by revenue (rolling 15m windows)\n",
    "print(\"Creating gold_top_products_15m...\")\n",
    "try:\n",
    "    df_lines = read_silver(\"fact_receipt_lines\")\n",
    "    \n",
    "    df_top_products = (\n",
    "        df_lines\n",
    "        .withColumn(\"ts\", F.date_trunc(\"minute\", F.col(\"event_ts\")))\n",
    "        .withColumn(\"window_15m\", F.window(F.col(\"event_ts\"), \"15 minutes\"))\n",
    "        .groupBy(\"product_id\", \"window_15m\")\n",
    "        .agg(\n",
    "            F.sum(\"ext_price\").alias(\"revenue\"),\n",
    "            F.sum(\"quantity\").alias(\"units\")\n",
    "        )\n",
    "        .withColumn(\"computed_at\", F.col(\"window_15m.end\"))\n",
    "        .drop(\"window_15m\")\n",
    "        .orderBy(F.desc(\"revenue\"))\n",
    "    )\n",
    "    \n",
    "    save_gold_table(df_top_products, \"gold_top_products_15m\")\n",
    "except Exception as e:\n",
    "    print(f\"  Skipping: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inventory Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gold_inventory_position_current - Current store inventory\n",
    "print(\"Creating gold_inventory_position_current...\")\n",
    "try:\n",
    "    df_store_inv = read_silver(\"fact_store_inventory_txn\")\n",
    "    \n",
    "    # Get latest balance per store/product\n",
    "    window_spec = Window.partitionBy(\"store_id\", \"product_id\").orderBy(F.desc(\"event_ts\"))\n",
    "    \n",
    "    df_current = (\n",
    "        df_store_inv\n",
    "        .withColumn(\"rn\", F.row_number().over(window_spec))\n",
    "        .filter(F.col(\"rn\") == 1)\n",
    "        .select(\n",
    "            \"store_id\",\n",
    "            \"product_id\",\n",
    "            F.col(\"balance\").alias(\"on_hand\"),\n",
    "            F.col(\"event_ts\").alias(\"as_of\")\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    save_gold_table(df_current, \"gold_inventory_position_current\")\n",
    "except Exception as e:\n",
    "    print(f\"  Skipping: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gold_dc_inventory_position_current - Current DC inventory\n",
    "print(\"Creating gold_dc_inventory_position_current...\")\n",
    "try:\n",
    "    df_dc_inv = read_silver(\"fact_dc_inventory_txn\")\n",
    "    \n",
    "    window_spec = Window.partitionBy(\"dc_id\", \"product_id\").orderBy(F.desc(\"event_ts\"))\n",
    "    \n",
    "    df_dc_current = (\n",
    "        df_dc_inv\n",
    "        .withColumn(\"rn\", F.row_number().over(window_spec))\n",
    "        .filter(F.col(\"rn\") == 1)\n",
    "        .select(\n",
    "            \"dc_id\",\n",
    "            \"product_id\",\n",
    "            F.col(\"balance\").alias(\"on_hand\"),\n",
    "            F.col(\"event_ts\").alias(\"as_of\")\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    save_gold_table(df_dc_current, \"gold_dc_inventory_position_current\")\n",
    "except Exception as e:\n",
    "    print(f\"  Skipping: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistics & Fulfillment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gold_truck_dwell_daily - Truck dwell time by site per day\n",
    "print(\"Creating gold_truck_dwell_daily...\")\n",
    "try:\n",
    "    df_trucks = read_silver(\"fact_truck_moves\")\n",
    "    \n",
    "    # Calculate dwell as time between eta and etd\n",
    "    df_dwell = (\n",
    "        df_trucks\n",
    "        .withColumn(\"day\", F.to_date(\"event_ts\"))\n",
    "        .withColumn(\"site\", \n",
    "            F.when(F.col(\"store_id\").isNotNull(), F.concat(F.lit(\"STORE_\"), F.col(\"store_id\")))\n",
    "             .otherwise(F.concat(F.lit(\"DC_\"), F.col(\"dc_id\")))\n",
    "        )\n",
    "        .withColumn(\"dwell_min\", \n",
    "            (F.unix_timestamp(\"etd\") - F.unix_timestamp(\"eta\")) / 60\n",
    "        )\n",
    "        .filter(F.col(\"dwell_min\").isNotNull() & (F.col(\"dwell_min\") > 0))\n",
    "        .groupBy(\"site\", \"day\")\n",
    "        .agg(\n",
    "            F.avg(\"dwell_min\").alias(\"avg_dwell_min\"),\n",
    "            F.countDistinct(\"truck_id\").alias(\"trucks\")\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    save_gold_table(df_dwell, \"gold_truck_dwell_daily\")\n",
    "except Exception as e:\n",
    "    print(f\"  Skipping: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gold_online_sales_daily - Online sales aggregated daily\n",
    "print(\"Creating gold_online_sales_daily...\")\n",
    "try:\n",
    "    df_online = read_silver(\"fact_online_order_headers\")\n",
    "    \n",
    "    df_online_daily = (\n",
    "        df_online\n",
    "        .withColumn(\"day\", F.to_date(\"event_ts\"))\n",
    "        .groupBy(\"day\")\n",
    "        .agg(\n",
    "            F.count(\"*\").alias(\"orders\"),\n",
    "            F.sum(\"subtotal\").alias(\"subtotal\"),\n",
    "            F.sum(\"tax\").alias(\"tax\"),\n",
    "            F.sum(\"total\").alias(\"total\"),\n",
    "            F.avg(\"total\").alias(\"avg_order_value\")\n",
    "        )\n",
    "        .orderBy(\"day\")\n",
    "    )\n",
    "    \n",
    "    save_gold_table(df_online_daily, \"gold_online_sales_daily\")\n",
    "except Exception as e:\n",
    "    print(f\"  Skipping: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gold_fulfillment_daily - Fulfillment performance daily\n",
    "print(\"Creating gold_fulfillment_daily...\")\n",
    "try:\n",
    "    df_lines = read_silver(\"fact_online_order_lines\")\n",
    "    \n",
    "    # Use shipped_ts or picked_ts for the day\n",
    "    df_fulfill = (\n",
    "        df_lines\n",
    "        .withColumn(\"day\", F.to_date(F.coalesce(\"shipped_ts\", \"picked_ts\", \"delivered_ts\")))\n",
    "        .filter(F.col(\"day\").isNotNull())\n",
    "        .groupBy(\"day\", \"fulfillment_mode\", \"fulfillment_status\")\n",
    "        .agg(\n",
    "            F.countDistinct(\"order_id\").alias(\"orders\"),\n",
    "            F.sum(\"quantity\").alias(\"units\")\n",
    "        )\n",
    "        .orderBy(\"day\")\n",
    "    )\n",
    "    \n",
    "    save_gold_table(df_fulfill, \"gold_fulfillment_daily\")\n",
    "except Exception as e:\n",
    "    print(f\"  Skipping: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customer & Zone Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gold_zone_dwell_minute - Zone dwell per minute\n",
    "print(\"Creating gold_zone_dwell_minute...\")\n",
    "try:\n",
    "    df_traffic = read_silver(\"fact_foot_traffic\")\n",
    "    \n",
    "    df_zone_dwell = (\n",
    "        df_traffic\n",
    "        .withColumn(\"ts\", F.date_trunc(\"minute\", F.col(\"event_ts\")))\n",
    "        .groupBy(\"store_id\", \"zone\", \"ts\")\n",
    "        .agg(\n",
    "            F.avg(\"dwell_seconds\").alias(\"avg_dwell\"),\n",
    "            F.sum(\"count\").alias(\"customers\")\n",
    "        )\n",
    "        .orderBy(\"store_id\", \"zone\", \"ts\")\n",
    "    )\n",
    "    \n",
    "    save_gold_table(df_zone_dwell, \"gold_zone_dwell_minute\")\n",
    "except Exception as e:\n",
    "    print(f\"  Skipping: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gold_ble_presence_minute - BLE device presence per minute\n",
    "print(\"Creating gold_ble_presence_minute...\")\n",
    "try:\n",
    "    df_ble = read_silver(\"fact_ble_pings\")\n",
    "    \n",
    "    df_presence = (\n",
    "        df_ble\n",
    "        .withColumn(\"ts\", F.date_trunc(\"minute\", F.col(\"event_ts\")))\n",
    "        .groupBy(\"store_id\", \"ts\")\n",
    "        .agg(\n",
    "            F.countDistinct(\"customer_ble_id\").alias(\"devices\")\n",
    "        )\n",
    "        .orderBy(\"store_id\", \"ts\")\n",
    "    )\n",
    "    \n",
    "    save_gold_table(df_presence, \"gold_ble_presence_minute\")\n",
    "except Exception as e:\n",
    "    print(f\"  Skipping: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marketing & Campaigns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gold_marketing_cost_daily - Marketing impressions and cost daily\n",
    "print(\"Creating gold_marketing_cost_daily...\")\n",
    "try:\n",
    "    df_marketing = read_silver(\"fact_marketing\")\n",
    "    \n",
    "    df_mkt_daily = (\n",
    "        df_marketing\n",
    "        .withColumn(\"day\", F.to_date(\"event_ts\"))\n",
    "        .groupBy(\"campaign_id\", \"day\")\n",
    "        .agg(\n",
    "            F.count(\"*\").alias(\"impressions\"),\n",
    "            F.sum(\"cost\").alias(\"cost\")\n",
    "        )\n",
    "        .orderBy(\"campaign_id\", \"day\")\n",
    "    )\n",
    "    \n",
    "    save_gold_table(df_mkt_daily, \"gold_marketing_cost_daily\")\n",
    "except Exception as e:\n",
    "    print(f\"  Skipping: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gold_campaign_revenue_daily - Campaign revenue with conversion tracking\n",
    "# Note: This requires joining marketing impressions with receipts via customer_id\n",
    "# which is a complex attribution model. Simplified version here.\n",
    "print(\"Creating gold_campaign_revenue_daily...\")\n",
    "try:\n",
    "    df_marketing = read_silver(\"fact_marketing\")\n",
    "    df_receipts = read_silver(\"fact_receipts\")\n",
    "    \n",
    "    # Simple attribution: count conversions where customer had impression same day\n",
    "    df_mkt_day = df_marketing.withColumn(\"day\", F.to_date(\"event_ts\")).select(\n",
    "        \"campaign_id\", \"day\", \"customer_id\"\n",
    "    ).distinct()\n",
    "    \n",
    "    df_receipts_day = df_receipts.withColumn(\"day\", F.to_date(\"event_ts\")).select(\n",
    "        \"customer_id\", \"day\", \"total\"\n",
    "    )\n",
    "    \n",
    "    df_attributed = (\n",
    "        df_mkt_day\n",
    "        .join(df_receipts_day, [\"customer_id\", \"day\"], \"left\")\n",
    "        .groupBy(\"campaign_id\", \"day\")\n",
    "        .agg(\n",
    "            F.count(\"*\").alias(\"impressions\"),\n",
    "            F.count(\"total\").alias(\"conversions\"),\n",
    "            F.sum(\"total\").alias(\"revenue\")\n",
    "        )\n",
    "        .orderBy(\"campaign_id\", \"day\")\n",
    "    )\n",
    "    \n",
    "    save_gold_table(df_attributed, \"gold_campaign_revenue_daily\")\n",
    "except Exception as e:\n",
    "    print(f\"  Skipping: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tender Mix (Payments)\n",
    "\n",
    "**Note:** This uses `payment_method` from `fact_receipts`. \n",
    "A dedicated `fact_payments` table is planned (see GitHub issue #7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gold_tender_mix_daily - Payment methods by day\n",
    "print(\"Creating gold_tender_mix_daily...\")\n",
    "try:\n",
    "    df_receipts = read_silver(\"fact_receipts\")\n",
    "    \n",
    "    df_tender = (\n",
    "        df_receipts\n",
    "        .withColumn(\"day\", F.to_date(\"event_ts\"))\n",
    "        .groupBy(\"day\", \"payment_method\")\n",
    "        .agg(\n",
    "            F.count(\"*\").alias(\"transactions\"),\n",
    "            F.sum(\"total\").alias(\"total_amount\")\n",
    "        )\n",
    "        .orderBy(\"day\", \"payment_method\")\n",
    "    )\n",
    "    \n",
    "    save_gold_table(df_tender, \"gold_tender_mix_daily\")\n",
    "except Exception as e:\n",
    "    print(f\"  Skipping: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Tables (Pending Datagen Updates)\n",
    "\n",
    "The following Gold tables depend on fact tables not yet implemented:\n",
    "\n",
    "| Gold Table | Depends On | GitHub Issue |\n",
    "|------------|------------|---------------|\n",
    "| `gold_stockouts_daily` | `fact_stockouts` | #8 |\n",
    "| `gold_reorders_daily` | `fact_reorders` | #9 |\n",
    "| `gold_promo_performance_daily` | `fact_promotions` | #10 |\n",
    "| `gold_store_ops_daily` | `fact_store_ops` | #11 |\n",
    "\n",
    "These are stubbed below but will return empty until the source tables are implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stubbed future tables - these will be empty until source facts exist\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, DateType, LongType, StringType, DoubleType, TimestampType\n",
    "\n",
    "# gold_stockouts_daily (pending fact_stockouts - issue #8)\n",
    "print(\"Creating gold_stockouts_daily (stub)...\")\n",
    "schema_stockouts = StructType([\n",
    "    StructField(\"day\", DateType(), True),\n",
    "    StructField(\"store_id\", LongType(), True),\n",
    "    StructField(\"dc_id\", LongType(), True),\n",
    "    StructField(\"stockout_count\", LongType(), True),\n",
    "    StructField(\"products_affected\", LongType(), True)\n",
    "])\n",
    "df_empty = spark.createDataFrame([], schema_stockouts)\n",
    "save_gold_table(df_empty, \"gold_stockouts_daily\")\n",
    "\n",
    "# gold_reorders_daily (pending fact_reorders - issue #9)\n",
    "print(\"Creating gold_reorders_daily (stub)...\")\n",
    "schema_reorders = StructType([\n",
    "    StructField(\"day\", DateType(), True),\n",
    "    StructField(\"store_id\", LongType(), True),\n",
    "    StructField(\"dc_id\", LongType(), True),\n",
    "    StructField(\"priority\", StringType(), True),\n",
    "    StructField(\"reorder_count\", LongType(), True),\n",
    "    StructField(\"total_units_ordered\", LongType(), True)\n",
    "])\n",
    "df_empty = spark.createDataFrame([], schema_reorders)\n",
    "save_gold_table(df_empty, \"gold_reorders_daily\")\n",
    "\n",
    "# gold_promo_performance_daily (pending fact_promotions - issue #10)\n",
    "print(\"Creating gold_promo_performance_daily (stub)...\")\n",
    "schema_promo = StructType([\n",
    "    StructField(\"day\", DateType(), True),\n",
    "    StructField(\"promo_code\", StringType(), True),\n",
    "    StructField(\"discount_type\", StringType(), True),\n",
    "    StructField(\"times_applied\", LongType(), True),\n",
    "    StructField(\"total_discount\", DoubleType(), True),\n",
    "    StructField(\"products_discounted\", LongType(), True)\n",
    "])\n",
    "df_empty = spark.createDataFrame([], schema_promo)\n",
    "save_gold_table(df_empty, \"gold_promo_performance_daily\")\n",
    "\n",
    "# gold_store_ops_daily (pending fact_store_ops - issue #11)\n",
    "print(\"Creating gold_store_ops_daily (stub)...\")\n",
    "schema_store_ops = StructType([\n",
    "    StructField(\"day\", DateType(), True),\n",
    "    StructField(\"store_id\", LongType(), True),\n",
    "    StructField(\"operation_type\", StringType(), True),\n",
    "    StructField(\"operation_count\", LongType(), True),\n",
    "    StructField(\"first_operation\", TimestampType(), True),\n",
    "    StructField(\"last_operation\", TimestampType(), True)\n",
    "])\n",
    "df_empty = spark.createDataFrame([], schema_store_ops)\n",
    "save_gold_table(df_empty, \"gold_store_ops_daily\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Silver to Gold transformation complete!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nGold tables created in: {GOLD_DB}\")\n",
    "print(\"\\nRun: spark.sql('SHOW TABLES IN ag_gold').show() to list all tables\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}