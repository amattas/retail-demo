{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Retail Datagen","text":"<p>Synthetic retail datasets for analytics POCs with a unified Local Data UI, historical generation, and realtime streaming to Azure Event Hub or Microsoft Fabric RTI.</p>"},{"location":"#quick-start","title":"Quick Start","text":"<ul> <li>Launch the app: <code>./launch.sh</code> then open http://localhost:8000</li> <li>Tabs:</li> <li>Dashboard: high\u2011level counts and recent events</li> <li>Local Data: generate Dimensions + Facts in one step; upload to Azure</li> <li>Streaming: start/stop realtime and monitor throughput</li> <li>Config: update volume/stream settings; clear all data</li> </ul>"},{"location":"#local-data-dimensions-facts","title":"Local Data (Dimensions + Facts)","text":"<ul> <li>One generate button runs dimensions first, then facts.</li> <li>After generation:</li> <li>The generate section hides</li> <li>Status shows Database Range (first \u2192 last) and last run info</li> <li>\u201cUpload Dimensions/Facts\u201d exports to Parquet and uploads to Azure Storage (if configured)</li> </ul>"},{"location":"#azure-storage-upload","title":"Azure Storage Upload","text":"<p>Configure Storage in <code>config.json</code> or via environment variables:</p> <pre><code>{\n  \"storage\": {\n    \"account_uri\": \"https://&lt;account&gt;.blob.core.windows.net/&lt;optional-container&gt;/&lt;optional-prefix&gt;\",\n    \"account_key\": \"&lt;account-key&gt;\"\n  }\n}\n</code></pre> <p>Alternatively: - <code>AZURE_STORAGE_ACCOUNT_URI=https://&lt;account&gt;.blob.core.windows.net</code> (container/prefix optional) - <code>AZURE_STORAGE_ACCOUNT_KEY=...</code></p> <p>Uploads use prefixes: - Master: <code>datagen/export/master/&lt;timestamp&gt;</code> - Facts: <code>datagen/export/facts/&lt;timestamp&gt;</code></p>"},{"location":"#realtime-streaming","title":"Realtime Streaming","text":"<ul> <li>Starts only after facts exist (state\u2011aware)</li> <li>Outbox mode publishes \u201cdaily\u201d increments \u2014 not the entire dataset</li> <li>Outbox endpoints:</li> <li>GET <code>/api/stream/outbox/status</code></li> <li>POST <code>/api/stream/outbox/drain</code></li> <li>DELETE <code>/api/stream/outbox/clear</code> (fast reset)</li> </ul> <p>See also: - Streaming Setup - Streaming API - Streaming Operations</p>"},{"location":"#fact-generation","title":"Fact Generation","text":"<ul> <li>Intelligent date ranges on first and subsequent runs</li> <li>9 fact tables with integrity and realistic behavior</li> </ul> <p>See: FACT_GENERATION.md</p>"},{"location":"#security","title":"Security","text":"<ul> <li>Event Hub credentials: environment, Key Vault, or config</li> <li>Storage credentials (for upload): account URI + key</li> <li>See CREDENTIALS.md</li> </ul>"},{"location":"CREDENTIALS/","title":"Credential Management Guide","text":"<p>Comprehensive guide for securely managing Azure Event Hub credentials and sensitive configuration.</p>"},{"location":"CREDENTIALS/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Security Principles</li> <li>Credential Storage Methods</li> <li>Environment Variables</li> <li>Azure Key Vault</li> <li>Configuration Files</li> <li>CI/CD Integration</li> <li>Rotation &amp; Revocation</li> <li>Audit &amp; Compliance</li> </ul>"},{"location":"CREDENTIALS/#security-principles","title":"Security Principles","text":""},{"location":"CREDENTIALS/#never-commit-credentials","title":"Never Commit Credentials","text":"<p>Critical Rule: Never commit credentials to version control.</p> <p>Why? - Credentials in git history remain accessible even after deletion - Public repositories expose credentials to the world - Automated bots scan GitHub for credentials within minutes - Compliance violations (SOC 2, ISO 27001, PCI DSS)</p> <p>Prevention:</p> <ol> <li> <p>Add to .gitignore: <code>bash    echo 'config.json' &gt;&gt; .gitignore    echo '.env' &gt;&gt; .gitignore    echo '*.secret' &gt;&gt; .gitignore</code></p> </li> <li> <p>Use git-secrets:    ```bash    # Install git-secrets    brew install git-secrets</p> </li> </ol> <p># Configure for repository    cd /path/to/retail-datagen    git secrets --install    git secrets --register-aws    ```</p> <ol> <li>Pre-commit hooks: <code>bash    # .git/hooks/pre-commit    #!/bin/bash    if git diff --cached | grep -i \"SharedAccessKey\"; then      echo \"ERROR: Attempting to commit Azure credentials!\"      exit 1    fi</code></li> </ol>"},{"location":"CREDENTIALS/#principle-of-least-privilege","title":"Principle of Least Privilege","text":"<p>Grant minimum necessary permissions:</p> <ul> <li>Development: Send-only permissions</li> <li>Production: Send-only with specific Event Hub access</li> <li>Monitoring: Listen-only permissions</li> <li>Management: Separate credentials for admin operations</li> </ul> <p>Azure Event Hub Access Policies:</p> <pre><code>Development Policy (Send Only):\n- Permissions: Send\n- Event Hub: retail-events-dev\n\nProduction Policy (Send Only):\n- Permissions: Send\n- Event Hub: retail-events-prod\n\nMonitoring Policy (Listen Only):\n- Permissions: Listen\n- Event Hub: retail-events-prod\n</code></pre>"},{"location":"CREDENTIALS/#defense-in-depth","title":"Defense in Depth","text":"<p>Multiple layers of security:</p> <ol> <li>Network: Firewall rules, private endpoints</li> <li>Identity: Azure Active Directory, Managed Identities</li> <li>Access: RBAC, access policies</li> <li>Audit: Logging, monitoring, alerts</li> <li>Encryption: TLS 1.2+, encryption at rest</li> </ol>"},{"location":"CREDENTIALS/#credential-storage-methods","title":"Credential Storage Methods","text":""},{"location":"CREDENTIALS/#method-comparison","title":"Method Comparison","text":"Method Security Complexity Best For Environment Variables Medium Low Development, CI/CD Azure Key Vault High Medium Production, Enterprise Configuration Files Low Low Local development only Managed Identity Highest Medium Azure deployments Azure Storage (Upload) Medium Low Optional upload after export"},{"location":"CREDENTIALS/#environment-variables","title":"Environment Variables","text":""},{"location":"CREDENTIALS/#overview","title":"Overview","text":"<p>Environment variables are the recommended method for development and CI/CD pipelines.</p> <p>Advantages: - Simple to use - No files to manage - Easy to rotate - Supported by all deployment platforms</p> <p>Disadvantages: - Visible in process listings - Not encrypted at rest - Can be leaked via error messages</p>"},{"location":"CREDENTIALS/#setting-environment-variables","title":"Setting Environment Variables","text":""},{"location":"CREDENTIALS/#linuxmacos-bashzsh","title":"Linux/macOS (Bash/Zsh)","text":"<p>Temporary (current session only):</p> <pre><code>export AZURE_EVENTHUB_CONNECTION_STRING=\"Endpoint=sb://your-namespace.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=your-key;EntityPath=retail-events\"\n</code></pre> <p>Persistent (add to shell profile):</p> <pre><code># Add to ~/.bashrc, ~/.zshrc, or ~/.profile\necho 'export AZURE_EVENTHUB_CONNECTION_STRING=\"Endpoint=sb://...\"' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre> <p>Verify:</p> <pre><code>echo $AZURE_EVENTHUB_CONNECTION_STRING\n</code></pre>"},{"location":"CREDENTIALS/#azure-storage-for-uploads-optional","title":"Azure Storage for Uploads (Optional)","text":"<p>Used by the \"Upload Dimensions/Facts\" actions after export.</p> <pre><code># Account URI (optionally include container/prefix)\nexport AZURE_STORAGE_ACCOUNT_URI=\"https://&lt;account&gt;.blob.core.windows.net[/&lt;container&gt;[/&lt;prefix&gt;]]\"\n\n# Account key\nexport AZURE_STORAGE_ACCOUNT_KEY=\"&lt;storage-account-key&gt;\"\n</code></pre> <p>You may also set these in <code>config.json</code> under <code>storage</code>.</p>"},{"location":"CREDENTIALS/#windows-powershell","title":"Windows (PowerShell)","text":"<p>Temporary (current session only):</p> <pre><code>$env:AZURE_EVENTHUB_CONNECTION_STRING = \"Endpoint=sb://your-namespace.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=your-key;EntityPath=retail-events\"\n</code></pre> <p>Persistent (user scope):</p> <pre><code>[System.Environment]::SetEnvironmentVariable('AZURE_EVENTHUB_CONNECTION_STRING', 'Endpoint=sb://...', 'User')\n</code></pre> <p>Persistent (system scope - requires admin):</p> <pre><code>[System.Environment]::SetEnvironmentVariable('AZURE_EVENTHUB_CONNECTION_STRING', 'Endpoint=sb://...', 'Machine')\n</code></pre> <p>Verify:</p> <pre><code>$env:AZURE_EVENTHUB_CONNECTION_STRING\n</code></pre>"},{"location":"CREDENTIALS/#docker","title":"Docker","text":"<p>Pass at runtime:</p> <pre><code>docker run -d \\\n  --name retail-datagen \\\n  -p 8000:8000 \\\n  -e AZURE_EVENTHUB_CONNECTION_STRING=\"$AZURE_EVENTHUB_CONNECTION_STRING\" \\\n  retail-datagen\n</code></pre> <p>Using .env file:</p> <pre><code># Create .env file (don't commit!)\ncat &gt; .env &lt;&lt;EOF\nAZURE_EVENTHUB_CONNECTION_STRING=Endpoint=sb://...\nEOF\n\n# Run with .env file\ndocker run -d \\\n  --name retail-datagen \\\n  -p 8000:8000 \\\n  --env-file .env \\\n  retail-datagen\n</code></pre>"},{"location":"CREDENTIALS/#kubernetes","title":"Kubernetes","text":"<p>Using Secrets:</p> <pre><code># Create secret from literal\nkubectl create secret generic azure-credentials \\\n  --from-literal=connection-string=\"Endpoint=sb://...\"\n\n# Create secret from file\necho \"Endpoint=sb://...\" &gt; connection-string.txt\nkubectl create secret generic azure-credentials \\\n  --from-file=connection-string=connection-string.txt\nrm connection-string.txt\n</code></pre> <p>Deployment manifest:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: retail-datagen\nspec:\n  template:\n    spec:\n      containers:\n      - name: retail-datagen\n        image: retail-datagen:latest\n        env:\n        - name: AZURE_EVENTHUB_CONNECTION_STRING\n          valueFrom:\n            secretKeyRef:\n              name: azure-credentials\n              key: connection-string\n</code></pre>"},{"location":"CREDENTIALS/#best-practices-for-environment-variables","title":"Best Practices for Environment Variables","text":"<ol> <li>Use strong naming conventions:</li> <li>Prefix with application name: <code>RETAIL_DATAGEN_*</code></li> <li> <p>Uppercase with underscores: <code>AZURE_EVENTHUB_CONNECTION_STRING</code></p> </li> <li> <p>Validate presence at startup:    ```python    import os</p> </li> </ol> <p>conn_str = os.getenv('AZURE_EVENTHUB_CONNECTION_STRING')    if not conn_str:        raise ValueError(\"AZURE_EVENTHUB_CONNECTION_STRING not set\")    ```</p> <ol> <li>Don't log environment variables:    ```python    # Bad - logs credential    logger.info(f\"Connection string: {conn_str}\")</li> </ol> <p># Good - masks credential    logger.info(\"Connection string: [REDACTED]\")    ```</p> <ol> <li>Clear after use (if sensitive): <code>bash    unset AZURE_EVENTHUB_CONNECTION_STRING</code></li> </ol>"},{"location":"CREDENTIALS/#azure-key-vault","title":"Azure Key Vault","text":""},{"location":"CREDENTIALS/#overview_1","title":"Overview","text":"<p>Azure Key Vault is the recommended solution for production environments.</p> <p>Advantages: - Centralized credential management - Encryption at rest and in transit - Audit logging - Access policies and RBAC - Automatic rotation support</p> <p>Disadvantages: - Requires Azure subscription - Additional setup complexity - Network dependency</p>"},{"location":"CREDENTIALS/#setup","title":"Setup","text":""},{"location":"CREDENTIALS/#1-create-key-vault","title":"1. Create Key Vault","text":"<pre><code># Variables\nRESOURCE_GROUP=\"retail-datagen-rg\"\nLOCATION=\"eastus\"\nVAULT_NAME=\"retail-datagen-kv\"\n\n# Create resource group\naz group create --name $RESOURCE_GROUP --location $LOCATION\n\n# Create Key Vault\naz keyvault create \\\n  --name $VAULT_NAME \\\n  --resource-group $RESOURCE_GROUP \\\n  --location $LOCATION \\\n  --enable-rbac-authorization false\n</code></pre>"},{"location":"CREDENTIALS/#2-store-connection-string","title":"2. Store Connection String","text":"<pre><code># Store secret\naz keyvault secret set \\\n  --vault-name $VAULT_NAME \\\n  --name \"eventhub-connection-string\" \\\n  --value \"Endpoint=sb://your-namespace.servicebus.windows.net/;...\"\n</code></pre>"},{"location":"CREDENTIALS/#3-grant-access","title":"3. Grant Access","text":"<p>Option A: Managed Identity (Recommended)</p> <pre><code># Enable system-assigned managed identity for VM/App Service\naz vm identity assign --name myVM --resource-group $RESOURCE_GROUP\n\n# Grant Key Vault access\nIDENTITY_ID=$(az vm show --name myVM --resource-group $RESOURCE_GROUP --query identity.principalId -o tsv)\n\naz keyvault set-policy \\\n  --name $VAULT_NAME \\\n  --object-id $IDENTITY_ID \\\n  --secret-permissions get list\n</code></pre> <p>Option B: Service Principal</p> <pre><code># Create service principal\naz ad sp create-for-rbac --name retail-datagen-sp\n\n# Grant Key Vault access\nSP_OBJECT_ID=$(az ad sp show --id &lt;app-id&gt; --query id -o tsv)\n\naz keyvault set-policy \\\n  --name $VAULT_NAME \\\n  --object-id $SP_OBJECT_ID \\\n  --secret-permissions get list\n</code></pre>"},{"location":"CREDENTIALS/#application-integration","title":"Application Integration","text":""},{"location":"CREDENTIALS/#install-dependencies","title":"Install Dependencies","text":"<pre><code>pip install azure-keyvault-secrets azure-identity\n</code></pre>"},{"location":"CREDENTIALS/#python-code","title":"Python Code","text":"<pre><code>from azure.identity import DefaultAzureCredential\nfrom azure.keyvault.secrets import SecretClient\n\n# Using Managed Identity (recommended)\ncredential = DefaultAzureCredential()\nvault_url = \"https://retail-datagen-kv.vault.azure.net/\"\nclient = SecretClient(vault_url=vault_url, credential=credential)\n\n# Retrieve secret\nconnection_string = client.get_secret(\"eventhub-connection-string\").value\n</code></pre>"},{"location":"CREDENTIALS/#configuration","title":"Configuration","text":"<p>Update <code>config.json</code>:</p> <pre><code>{\n  \"realtime\": {\n    \"use_keyvault\": true,\n    \"keyvault_url\": \"https://retail-datagen-kv.vault.azure.net/\",\n    \"keyvault_secret_name\": \"eventhub-connection-string\"\n  }\n}\n</code></pre>"},{"location":"CREDENTIALS/#best-practices-for-key-vault","title":"Best Practices for Key Vault","text":"<ol> <li> <p>Enable soft delete: <code>bash    az keyvault update --name $VAULT_NAME --enable-soft-delete true</code></p> </li> <li> <p>Enable purge protection: <code>bash    az keyvault update --name $VAULT_NAME --enable-purge-protection true</code></p> </li> <li> <p>Use RBAC instead of access policies: <code>bash    az keyvault create --name $VAULT_NAME --enable-rbac-authorization true</code></p> </li> <li> <p>Monitor access: <code>bash    az monitor diagnostic-settings create \\      --name KeyVaultAudit \\      --resource /subscriptions/{sub-id}/resourceGroups/{rg}/providers/Microsoft.KeyVault/vaults/{vault} \\      --logs '[{\"category\": \"AuditEvent\", \"enabled\": true}]' \\      --workspace /subscriptions/{sub-id}/resourcegroups/{rg}/providers/microsoft.operationalinsights/workspaces/{workspace}</code></p> </li> <li> <p>Implement caching:    ```python    # Cache secrets to reduce Key Vault calls    from functools import lru_cache</p> </li> </ol> <p>@lru_cache(maxsize=1)    def get_connection_string():        return client.get_secret(\"eventhub-connection-string\").value    ```</p>"},{"location":"CREDENTIALS/#configuration-files","title":"Configuration Files","text":""},{"location":"CREDENTIALS/#local-development-only","title":"Local Development Only","text":"<p>Configuration files should only be used for local development and must never be committed.</p>"},{"location":"CREDENTIALS/#template-pattern","title":"Template Pattern","text":"<p>Commit a template:</p> <pre><code>// config.template.json\n{\n  \"realtime\": {\n    \"azure_connection_string\": \"&lt;YOUR_CONNECTION_STRING_HERE&gt;\",\n    \"emit_interval_ms\": 500,\n    \"burst\": 100\n  }\n}\n</code></pre> <p>Create local config from template:</p> <pre><code>cp config.template.json config.json\n# Edit config.json with real credentials\n# config.json is in .gitignore\n</code></pre>"},{"location":"CREDENTIALS/#encryption-at-rest","title":"Encryption at Rest","text":"<p>For additional security, encrypt configuration files:</p> <pre><code># Encrypt config file\nopenssl enc -aes-256-cbc -salt -in config.json -out config.json.enc\n\n# Decrypt when needed\nopenssl enc -aes-256-cbc -d -in config.json.enc -out config.json\n</code></pre> <p>Store encryption key separately (environment variable or Key Vault).</p>"},{"location":"CREDENTIALS/#file-permissions","title":"File Permissions","text":"<p>Restrict access to configuration files:</p> <pre><code># Owner read/write only\nchmod 600 config.json\n\n# Verify permissions\nls -la config.json\n# -rw------- 1 user user 1234 Jan 15 10:00 config.json\n</code></pre>"},{"location":"CREDENTIALS/#cicd-integration","title":"CI/CD Integration","text":""},{"location":"CREDENTIALS/#github-actions","title":"GitHub Actions","text":"<p>Using GitHub Secrets:</p> <pre><code>name: Deploy\non: [push]\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Set up Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: '3.11'\n\n      - name: Install dependencies\n        run: pip install -e .\n\n      - name: Run tests with credentials\n        env:\n          AZURE_EVENTHUB_CONNECTION_STRING: ${{ secrets.AZURE_EVENTHUB_CONNECTION_STRING }}\n        run: pytest\n</code></pre> <p>Add secret to GitHub: 1. Repository \u2192 Settings \u2192 Secrets and variables \u2192 Actions 2. Click \"New repository secret\" 3. Name: <code>AZURE_EVENTHUB_CONNECTION_STRING</code> 4. Value: Your connection string 5. Click \"Add secret\"</p>"},{"location":"CREDENTIALS/#azure-devops","title":"Azure DevOps","text":"<p>Using Variable Groups:</p> <pre><code>trigger:\n  - main\n\npool:\n  vmImage: 'ubuntu-latest'\n\nvariables:\n  - group: retail-datagen-secrets\n\nsteps:\n- task: UsePythonVersion@0\n  inputs:\n    versionSpec: '3.11'\n\n- script: |\n    pip install -e .\n  displayName: 'Install dependencies'\n\n- script: |\n    pytest\n  env:\n    AZURE_EVENTHUB_CONNECTION_STRING: $(AZURE_EVENTHUB_CONNECTION_STRING)\n  displayName: 'Run tests'\n</code></pre> <p>Create variable group: 1. Pipelines \u2192 Library \u2192 Variable groups 2. Click \"Add variable group\" 3. Name: <code>retail-datagen-secrets</code> 4. Add variable: <code>AZURE_EVENTHUB_CONNECTION_STRING</code> 5. Lock icon: Make secret 6. Save</p>"},{"location":"CREDENTIALS/#gitlab-cicd","title":"GitLab CI/CD","text":"<p>Using CI/CD Variables:</p> <pre><code>test:\n  stage: test\n  image: python:3.11\n  before_script:\n    - pip install -e .\n  script:\n    - pytest\n  variables:\n    AZURE_EVENTHUB_CONNECTION_STRING: $AZURE_EVENTHUB_CONNECTION_STRING\n</code></pre> <p>Add CI/CD variable: 1. Settings \u2192 CI/CD \u2192 Variables 2. Click \"Add variable\" 3. Key: <code>AZURE_EVENTHUB_CONNECTION_STRING</code> 4. Value: Your connection string 5. Flags: Protected, Masked 6. Save</p>"},{"location":"CREDENTIALS/#rotation-revocation","title":"Rotation &amp; Revocation","text":""},{"location":"CREDENTIALS/#regular-rotation","title":"Regular Rotation","text":"<p>Recommended schedule: - Development: Every 6 months - Production: Every 3 months - After personnel changes: Immediately</p>"},{"location":"CREDENTIALS/#rotation-process","title":"Rotation Process","text":""},{"location":"CREDENTIALS/#1-generate-new-key","title":"1. Generate New Key","text":"<pre><code># Regenerate primary key\naz eventhubs namespace authorization-rule keys renew \\\n  --resource-group $RESOURCE_GROUP \\\n  --namespace-name $NAMESPACE \\\n  --name RootManageSharedAccessKey \\\n  --key PrimaryKey\n\n# Get new connection string\naz eventhubs namespace authorization-rule keys list \\\n  --resource-group $RESOURCE_GROUP \\\n  --namespace-name $NAMESPACE \\\n  --name RootManageSharedAccessKey \\\n  --query primaryConnectionString -o tsv\n</code></pre>"},{"location":"CREDENTIALS/#2-update-credentials","title":"2. Update Credentials","text":"<p>Environment variables:</p> <pre><code>export AZURE_EVENTHUB_CONNECTION_STRING=\"&lt;new-connection-string&gt;\"\n</code></pre> <p>Key Vault:</p> <pre><code>az keyvault secret set \\\n  --vault-name $VAULT_NAME \\\n  --name \"eventhub-connection-string\" \\\n  --value \"&lt;new-connection-string&gt;\"\n</code></pre>"},{"location":"CREDENTIALS/#3-restart-applications","title":"3. Restart Applications","text":"<pre><code># Docker\ndocker restart retail-datagen\n\n# Kubernetes\nkubectl rollout restart deployment/retail-datagen\n\n# Systemd\nsudo systemctl restart retail-datagen\n</code></pre>"},{"location":"CREDENTIALS/#4-verify","title":"4. Verify","text":"<pre><code>curl -X POST http://localhost:8000/api/stream/test\n</code></pre>"},{"location":"CREDENTIALS/#emergency-revocation","title":"Emergency Revocation","text":"<p>If credentials are compromised:</p> <ol> <li> <p>Immediately regenerate both keys: <code>bash    az eventhubs namespace authorization-rule keys renew \\      --key PrimaryKey    az eventhubs namespace authorization-rule keys renew \\      --key SecondaryKey</code></p> </li> <li> <p>Review audit logs: <code>bash    az monitor activity-log list \\      --resource-group $RESOURCE_GROUP \\      --start-time $(date -u -d '1 hour ago' '+%Y-%m-%dT%H:%M:%SZ')</code></p> </li> <li> <p>Notify security team</p> </li> <li> <p>Update all applications</p> </li> <li> <p>Document incident</p> </li> </ol>"},{"location":"CREDENTIALS/#audit-compliance","title":"Audit &amp; Compliance","text":""},{"location":"CREDENTIALS/#enable-audit-logging","title":"Enable Audit Logging","text":"<p>Azure Event Hub diagnostic settings:</p> <pre><code>az monitor diagnostic-settings create \\\n  --name EventHubAudit \\\n  --resource /subscriptions/{sub-id}/resourceGroups/{rg}/providers/Microsoft.EventHub/namespaces/{namespace} \\\n  --logs '[\n    {\"category\": \"ArchiveLogs\", \"enabled\": true},\n    {\"category\": \"OperationalLogs\", \"enabled\": true}\n  ]' \\\n  --workspace /subscriptions/{sub-id}/resourcegroups/{rg}/providers/microsoft.operationalinsights/workspaces/{workspace}\n</code></pre> <p>Key Vault audit logging:</p> <pre><code>az monitor diagnostic-settings create \\\n  --name KeyVaultAudit \\\n  --resource /subscriptions/{sub-id}/resourceGroups/{rg}/providers/Microsoft.KeyVault/vaults/{vault} \\\n  --logs '[{\"category\": \"AuditEvent\", \"enabled\": true}]' \\\n  --workspace /subscriptions/{sub-id}/resourcegroups/{rg}/providers/microsoft.operationalinsights/workspaces/{workspace}\n</code></pre>"},{"location":"CREDENTIALS/#query-audit-logs","title":"Query Audit Logs","text":"<p>Azure Monitor Logs (KQL):</p> <pre><code>// Key Vault access logs\nAzureDiagnostics\n| where ResourceType == \"VAULTS\"\n| where OperationName == \"SecretGet\"\n| where ResultSignature == \"OK\"\n| project TimeGenerated, CallerIPAddress, Resource, OperationName\n| order by TimeGenerated desc\n\n// Event Hub operations\nAzureDiagnostics\n| where ResourceType == \"EVENTHUBS\"\n| where Category == \"OperationalLogs\"\n| project TimeGenerated, OperationName, ResultDescription\n| order by TimeGenerated desc\n</code></pre>"},{"location":"CREDENTIALS/#compliance-reports","title":"Compliance Reports","text":"<p>Generate credential usage report:</p> <pre><code>#!/bin/bash\n\necho \"=== Credential Audit Report ===\"\necho \"Generated: $(date)\"\necho \"\"\n\necho \"=== Key Vault Secrets ===\"\naz keyvault secret list --vault-name $VAULT_NAME --query \"[].{Name:name, Created:attributes.created, Updated:attributes.updated}\" -o table\n\necho \"\"\necho \"=== Event Hub Access Policies ===\"\naz eventhubs namespace authorization-rule list \\\n  --resource-group $RESOURCE_GROUP \\\n  --namespace-name $NAMESPACE \\\n  --query \"[].{Name:name, Rights:rights}\" -o table\n\necho \"\"\necho \"=== Recent Key Vault Access ===\"\naz monitor activity-log list \\\n  --resource-group $RESOURCE_GROUP \\\n  --start-time $(date -u -d '7 days ago' '+%Y-%m-%dT%H:%M:%SZ') \\\n  --query \"[?contains(resourceId, 'vaults')].{Time:eventTimestamp, Operation:operationName.value, Status:status.value}\" -o table\n</code></pre>"},{"location":"CREDENTIALS/#compliance-checklist","title":"Compliance Checklist","text":"<ul> <li>[ ] Credentials not in version control</li> <li>[ ] Environment variables or Key Vault used</li> <li>[ ] Least privilege access policies configured</li> <li>[ ] Audit logging enabled</li> <li>[ ] Rotation schedule defined</li> <li>[ ] Emergency revocation procedure documented</li> <li>[ ] Access reviewed quarterly</li> <li>[ ] Compliance requirements met (SOC 2, ISO 27001, etc.)</li> </ul>"},{"location":"CREDENTIALS/#security-incident-response","title":"Security Incident Response","text":""},{"location":"CREDENTIALS/#if-credentials-are-leaked","title":"If Credentials Are Leaked","text":"<ol> <li>Immediately revoke compromised credentials</li> <li>Generate new credentials</li> <li>Update all applications</li> <li>Review logs for unauthorized access</li> <li>Notify security team and stakeholders</li> <li>Document incident and lessons learned</li> <li>Implement additional controls</li> </ol>"},{"location":"CREDENTIALS/#prevention-checklist","title":"Prevention Checklist","text":"<ul> <li>[ ] Pre-commit hooks prevent credential commits</li> <li>[ ] <code>.gitignore</code> configured correctly</li> <li>[ ] Secrets scanning enabled (GitHub, GitLab, etc.)</li> <li>[ ] Regular security training for team</li> <li>[ ] Incident response plan documented</li> <li>[ ] Regular credential rotation schedule</li> </ul>"},{"location":"CREDENTIALS/#resources","title":"Resources","text":"<ul> <li>Azure Key Vault Documentation</li> <li>Azure Event Hubs Security</li> <li>OWASP Secrets Management Cheat Sheet</li> <li>NIST SP 800-57: Key Management</li> </ul>"},{"location":"CREDENTIALS/#next-steps","title":"Next Steps","text":"<ul> <li>Setup: See STREAMING_SETUP.md for initial configuration</li> <li>Operations: See STREAMING_OPERATIONS.md for monitoring</li> <li>API Reference: See STREAMING_API.md for endpoint documentation</li> </ul>"},{"location":"FACT_GENERATION/","title":"Fact Data Generation System","text":""},{"location":"FACT_GENERATION/#overview","title":"Overview","text":"<p>The Historical Fact Data Generation System creates realistic retail transaction data for analytics and testing purposes. It generates all fact tables specified in AGENTS.md with proper temporal patterns, business logic coordination, and partitioned output, including unified online orders.</p>"},{"location":"FACT_GENERATION/#key-features","title":"\ud83c\udfaf Key Features","text":""},{"location":"FACT_GENERATION/#complete-fact-table-generation","title":"\u2705 Complete Fact Table Generation","text":"<ul> <li>DC Inventory Transactions: Supplier deliveries, adjustments, outbound shipments</li> <li>Truck Movements: Realistic logistics with status progression and timing</li> <li>Store Inventory Transactions: Receiving, sales, adjustments with proper sourcing</li> <li>Receipts &amp; Receipt Lines: Customer transactions with realistic basket composition</li> <li>Foot Traffic: Sensor data with zone-based movement patterns</li> <li>BLE Pings: Beacon interactions with realistic RSSI values</li> <li>Marketing: Multi-channel campaigns with targeting and cost tracking</li> <li>Online Orders: Unified online order facts with inventory impacts on stores/DCs</li> </ul>"},{"location":"FACT_GENERATION/#realistic-temporal-patterns","title":"\u2705 Realistic Temporal Patterns","text":"<ul> <li>Seasonal Effects: Holiday spikes, back-to-school, weather impacts</li> <li>Daily Patterns: Peak hours, lunch rushes, weekend vs weekday differences</li> <li>Store Hours: Realistic operating schedules with closed-time handling</li> <li>Event-Driven: Promotional periods, flash sales, special events</li> </ul>"},{"location":"FACT_GENERATION/#advanced-retail-behavior-simulation","title":"\u2705 Advanced Retail Behavior Simulation","text":"<ul> <li>Customer Segments: Budget-conscious, convenience-focused, quality-seekers, brand-loyal</li> <li>Shopping Behaviors: Quick trips, grocery runs, family shopping, bulk purchases</li> <li>Realistic Baskets: Category-based product combinations with segment preferences</li> <li>Geographic Logic: Customer-store proximity affects shopping patterns</li> </ul>"},{"location":"FACT_GENERATION/#supply-chain-coordination","title":"\u2705 Supply Chain Coordination","text":"<ul> <li>Inventory Flow: DC \u2192 Truck \u2192 Store \u2192 Customer with realistic timing</li> <li>Demand-Driven Reordering: Automatic shipment triggers based on sales</li> <li>Capacity Constraints: Truck limits, store capacity, DC throughput</li> <li>Business Rules: No negative inventory, proper pricing validation</li> </ul>"},{"location":"FACT_GENERATION/#data-quality-validation","title":"\u2705 Data Quality &amp; Validation","text":"<ul> <li>Referential Integrity: All foreign keys validated across tables</li> <li>Business Rule Compliance: Receipt totals, pricing constraints, timing logic</li> <li>Synthetic Data Safety: No real personal information generated</li> <li>Reproducible Results: Seed-based deterministic generation</li> </ul>"},{"location":"FACT_GENERATION/#production-ready-output","title":"\u2705 Production-Ready Output","text":"<ul> <li>Partitioned Storage: Monthly Parquet files under <code>data/export/&lt;table&gt;</code></li> <li>Scalable Generation: Handle millions of transactions efficiently</li> <li>Progress Reporting: Real-time feedback with table completion counter, ETA estimation, and throttled updates</li> <li>Configurable Volumes: Adjust store count, customer traffic, basket sizes</li> </ul>"},{"location":"FACT_GENERATION/#system-architecture","title":"\ud83c\udfd7\ufe0f System Architecture","text":""},{"location":"FACT_GENERATION/#core-components","title":"Core Components","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    FactDataGenerator                            \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502 SeasonalPatterns\u2502 CustomerJourney  \u2502  InventoryFlow       \u2502  \u2502\n\u2502  \u2502 TemporalPatterns\u2502 Simulator        \u2502  Simulator           \u2502  \u2502\n\u2502  \u2502 EventPatterns   \u2502                  \u2502                      \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502 MarketingCampaign\u2502 BusinessRules   \u2502  Cross-Fact          \u2502  \u2502\n\u2502  \u2502 Simulator        \u2502 Engine          \u2502  Coordination        \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"FACT_GENERATION/#data-flow","title":"Data Flow","text":"<pre><code>Daily Generation Loop:\n1. Calculate temporal multipliers (seasonal, daily, hourly)\n2. Generate DC inventory transactions (supplier deliveries)\n3. Generate marketing campaigns and impressions\n4. For each hour of day:\n   - Generate customer transactions (receipts + lines)\n   - Generate foot traffic and BLE pings\n   - Process inventory deductions\n5. Analyze inventory needs \u2192 Generate truck movements\n6. Process truck deliveries \u2192 Update store inventory\n7. Validate business rules and export to monthly Parquet files\n</code></pre>"},{"location":"FACT_GENERATION/#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"FACT_GENERATION/#1-basic-usage","title":"1. Basic Usage","text":"<pre><code>from datetime import datetime, timedelta\nfrom retail_datagen.config.models import RetailConfig\nfrom retail_datagen.generators.fact_generator import FactDataGenerator\n\n# Load configuration\nconfig = RetailConfig.from_file(\"config.json\")\n\n# Initialize generator (loads dimension data automatically)\ngenerator = FactDataGenerator(config)\n\n# Generate 30 days of fact data\nstart_date = datetime(2024, 1, 1)\nend_date = datetime(2024, 1, 30)\n\nsummary = generator.generate_historical_data(start_date, end_date)\n\nprint(f\"Generated {summary.total_records} records in {summary.generation_time_seconds:.1f}s\")\n</code></pre>"},{"location":"FACT_GENERATION/#2-configuration-example","title":"2. Configuration Example","text":"<pre><code>{\n  \"seed\": 42,\n  \"volume\": {\n    \"stores\": 250,\n    \"dcs\": 12,\n    \"customers_per_day\": 20000,\n    \"items_per_ticket_mean\": 4.2,\n    \"online_orders_per_day\": 2500\n  },\n  \"realtime\": {\n    \"emit_interval_ms\": 500,\n    \"burst\": 100\n  },\n  \"paths\": {\n    \"dict\": \"data/dictionaries\"\n  },\n  \"stream\": {\n    \"hub\": \"retail-events\"\n  }\n}\n</code></pre>"},{"location":"FACT_GENERATION/#3-output-structure","title":"3. Output Structure","text":"<pre><code>data/export/\n\u251c\u2500\u2500 fact_receipts/\n\u2502   \u251c\u2500\u2500 fact_receipts_2024-01.parquet\n\u2502   \u251c\u2500\u2500 fact_receipts_2024-02.parquet\n\u251c\u2500\u2500 fact_receipt_lines/\n\u2502   \u251c\u2500\u2500 fact_receipt_lines_2024-01.parquet\n\u251c\u2500\u2500 fact_store_inventory_txn/\n\u2502   \u251c\u2500\u2500 fact_store_inventory_txn_2024-01.parquet\n\u251c\u2500\u2500 fact_truck_moves/\n\u2502   \u251c\u2500\u2500 fact_truck_moves_2024-01.parquet\n\u251c\u2500\u2500 fact_dc_inventory_txn/\n\u2502   \u251c\u2500\u2500 fact_dc_inventory_txn_2024-01.parquet\n\u251c\u2500\u2500 fact_foot_traffic/\n\u2502   \u251c\u2500\u2500 fact_foot_traffic_2024-01.parquet\n\u251c\u2500\u2500 fact_ble_pings/\n\u2502   \u251c\u2500\u2500 fact_ble_pings_2024-01.parquet\n\u251c\u2500\u2500 fact_marketing/\n\u2502   \u251c\u2500\u2500 fact_marketing_2024-01.parquet\n\u2514\u2500\u2500 fact_online_order_lines/\n    \u251c\u2500\u2500 fact_online_order_lines_2024-01.parquet\n</code></pre>"},{"location":"FACT_GENERATION/#generated-fact-tables-example-rows","title":"\ud83d\udcca Generated Fact Tables (Example Rows)","text":""},{"location":"FACT_GENERATION/#1-dc-inventory-transactions","title":"1. DC Inventory Transactions","text":"<pre><code>TraceId,EventTS,DCID,ProductID,QtyDelta,Reason\nTRC0000000001,2024-01-01 08:30:45,1,1001,500,INBOUND_SHIPMENT\nTRC0000000002,2024-01-01 09:15:22,1,1002,-250,OUTBOUND_SHIPMENT\n</code></pre>"},{"location":"FACT_GENERATION/#2-truck-movements","title":"2. Truck Movements","text":"<pre><code>TraceId,EventTS,TruckId,DCID,StoreID,ShipmentId,Status,ETA,ETD\nTRC0000000003,2024-01-01 06:00:00,TRK1001,1,15,SHIP20240101,SCHEDULED,2024-01-01 14:00:00,2024-01-01 15:00:00\n</code></pre>"},{"location":"FACT_GENERATION/#3-store-inventory-transactions","title":"3. Store Inventory Transactions","text":"<pre><code>TraceId,EventTS,StoreID,ProductID,QtyDelta,Reason,Source\nTRC0000000004,2024-01-01 14:30:15,15,1001,100,INBOUND_SHIPMENT,TRK1001\nTRC0000000005,2024-01-01 15:45:30,15,1001,-2,SALE,CUSTOMER_PURCHASE\n</code></pre>"},{"location":"FACT_GENERATION/#4-receipts","title":"4. Receipts","text":"<pre><code>TraceId,EventTS,StoreID,CustomerID,ReceiptId,Subtotal,Tax,Total,TenderType\nTRC0000000006,2024-01-01 15:45:30,15,5001,RCP202401011545015,25.98,2.08,28.06,CREDIT_CARD\n</code></pre>"},{"location":"FACT_GENERATION/#5-receipt-lines","title":"5. Receipt Lines","text":"<pre><code>TraceId,EventTS,ReceiptId,Line,ProductID,Qty,UnitPrice,ExtPrice,PromoCode\nTRC0000000006,2024-01-01 15:45:30,RCP202401011545015,1,1001,2,12.99,25.98,\n</code></pre>"},{"location":"FACT_GENERATION/#6-foot-traffic","title":"6. Foot Traffic","text":"<pre><code>TraceId,EventTS,StoreID,SensorId,Zone,Dwell,Count\nTRC0000000007,2024-01-01 15:42:18,15,SENSOR_015_ENTRANCE,ENTRANCE,45,1\n</code></pre>"},{"location":"FACT_GENERATION/#7-ble-pings","title":"7. BLE Pings","text":"<pre><code>TraceId,EventTS,StoreID,BeaconId,CustomerBLEId,RSSI,Zone\nTRC0000000008,2024-01-01 15:43:25,15,BEACON_015_GROCERY,BLE500123,-65,GROCERY\n</code></pre>"},{"location":"FACT_GENERATION/#8-marketing","title":"8. Marketing","text":"<pre><code>TraceId,EventTS,Channel,CampaignId,CreativeId,CustomerAdId,ImpressionId,Cost,Device\nTRC0000000009,2024-01-01 10:15:30,FACEBOOK,CAMP20240101,CREAT001FB01,AD500123,IMP20240101234567,0.15,MOBILE\n</code></pre>"},{"location":"FACT_GENERATION/#realistic-behavior-examples","title":"\ud83c\udfaf Realistic Behavior Examples","text":""},{"location":"FACT_GENERATION/#seasonal-patterns","title":"Seasonal Patterns","text":"<ul> <li>Black Friday: 3.5x normal traffic with extended hours</li> <li>Christmas: 2x normal traffic with gift-focused purchases</li> <li>Back-to-School: Electronics and clothing surge in August</li> <li>Summer: Outdoor and BBQ products increase</li> </ul>"},{"location":"FACT_GENERATION/#daily-patterns","title":"Daily Patterns","text":"<ul> <li>Monday: 70% of baseline traffic (slow start)</li> <li>Friday: 120% of baseline (weekend prep)</li> <li>Saturday: 140% of baseline (peak shopping)</li> <li>Lunch Rush: 11:30 AM - 1:30 PM traffic spike</li> <li>After Work: 5:00 PM - 8:00 PM peak period</li> </ul>"},{"location":"FACT_GENERATION/#customer-behavior","title":"Customer Behavior","text":"<ul> <li>Budget-Conscious: Bulk shopping, promotional focus, longer baskets</li> <li>Convenience-Focused: Quick trips, premium for convenience</li> <li>Quality-Seekers: Higher-priced items, selective shopping</li> <li>Brand-Loyal: Consistent brand preferences, moderate baskets</li> </ul>"},{"location":"FACT_GENERATION/#supply-chain-logic","title":"Supply Chain Logic","text":"<ol> <li>Sales reduce store inventory</li> <li>Inventory hits reorder point \u2192 Triggers truck shipment</li> <li>Truck travels realistic time \u2192 Delivers to store</li> <li>Store receives inventory \u2192 Ready for more sales</li> </ol>"},{"location":"FACT_GENERATION/#advanced-configuration","title":"\ud83d\udd27 Advanced Configuration","text":""},{"location":"FACT_GENERATION/#temporal-pattern-customization","title":"Temporal Pattern Customization","text":"<pre><code>from retail_datagen.generators.seasonal_patterns import CompositeTemporalPatterns\n\n# Override seasonal multipliers\npatterns = CompositeTemporalPatterns(seed=42)\ncustom_multiplier = patterns.get_overall_multiplier(datetime(2024, 12, 25))\n</code></pre>"},{"location":"FACT_GENERATION/#customer-journey-customization","title":"Customer Journey Customization","text":"<pre><code>from retail_datagen.generators.retail_patterns import CustomerJourneySimulator\n\n# Generate specific shopping behavior\nsimulator = CustomerJourneySimulator(customers, products, stores)\nbasket = simulator.generate_shopping_basket(\n    customer_id=123, \n    behavior_type=ShoppingBehaviorType.FAMILY_SHOPPING\n)\n</code></pre>"},{"location":"FACT_GENERATION/#business-rules-validation","title":"Business Rules Validation","text":"<pre><code>from retail_datagen.generators.retail_patterns import BusinessRulesEngine\n\nrules = BusinessRulesEngine()\nis_valid = rules.validate_receipt_totals(receipt_lines, total_amount)\nvalidation_summary = rules.get_validation_summary()\n</code></pre>"},{"location":"FACT_GENERATION/#performance-scaling","title":"\ud83d\ude80 Performance &amp; Scaling","text":""},{"location":"FACT_GENERATION/#recommended-specifications","title":"Recommended Specifications","text":"Store Count Daily Customers Generation Time Memory Usage Storage/Day 10 stores 1,000 30 seconds 100 MB 50 MB 100 stores 10,000 5 minutes 500 MB 500 MB 1,000 stores 100,000 45 minutes 2 GB 5 GB"},{"location":"FACT_GENERATION/#optimization-tips","title":"Optimization Tips","text":"<ol> <li>Use appropriate date ranges: Start with small ranges for testing</li> <li>Monitor memory usage: Large customer bases require more memory</li> <li>Configure customer density: Adjust <code>customers_per_day</code> for your needs</li> </ol>"},{"location":"FACT_GENERATION/#testing-validation","title":"\ud83e\uddea Testing &amp; Validation","text":""},{"location":"FACT_GENERATION/#run-verification-script","title":"Run Verification Script","text":"<pre><code>python verify_fact_generation.py\n</code></pre>"},{"location":"FACT_GENERATION/#run-demonstration","title":"Run Demonstration","text":"<pre><code>python demo_fact_generation.py\n</code></pre>"},{"location":"FACT_GENERATION/#unit-tests","title":"Unit Tests","text":"<pre><code>python -m pytest tests/unit/test_fact_generation.py\n</code></pre>"},{"location":"FACT_GENERATION/#troubleshooting","title":"\ud83d\udd0d Troubleshooting","text":""},{"location":"FACT_GENERATION/#common-issues","title":"Common Issues","text":"<p>1. \"Dimension data not found\" - Ensure dimension data exists in DuckDB (dim_* tables) or export files under <code>data/export/&lt;table&gt;</code> - Run dimension data generation first</p> <p>2. \"Negative inventory\" - Check inventory reorder logic - Verify business rules are properly applied</p> <p>3. \"Large memory usage\" - Reduce <code>customers_per_day</code> in config - Generate smaller date ranges - Use incremental generation</p> <p>4. \"Slow generation\" - Check disk I/O performance - Reduce fact table complexity - Use SSD storage for output</p>"},{"location":"FACT_GENERATION/#debug-mode","title":"Debug Mode","text":"<pre><code>generator = FactDataGenerator(config)\ngenerator.business_rules.clear_validation_results()  # Clear previous validations\n\n# Enable detailed logging\nimport logging\nlogging.basicConfig(level=logging.DEBUG)\n</code></pre>"},{"location":"FACT_GENERATION/#next-steps","title":"\ud83c\udfaf Next Steps","text":"<ol> <li>Integration: Incorporate into your data pipeline</li> <li>Customization: Modify patterns for your specific retail scenario</li> <li>Real-time: Extend to real-time event streaming</li> <li>Analytics: Use generated data for BI/ML model training</li> <li>Scale: Generate production-volume datasets</li> </ol>"},{"location":"FACT_GENERATION/#related-files","title":"\ud83d\udcda Related Files","text":"<ul> <li><code>/src/retail_datagen/generators/fact_generator.py</code> - Main generation engine</li> <li><code>/src/retail_datagen/generators/seasonal_patterns.py</code> - Temporal modeling</li> <li><code>/src/retail_datagen/generators/retail_patterns.py</code> - Behavior simulation</li> <li><code>/src/retail_datagen/shared/models.py</code> - Data models and validation</li> <li><code>/tests/unit/test_fact_generation.py</code> - Unit tests</li> <li><code>/demo_fact_generation.py</code> - Complete demonstration</li> <li><code>/verify_fact_generation.py</code> - System verification</li> </ul> <p>The historical fact data generation system provides a comprehensive, realistic, and scalable solution for generating retail transaction data that follows real-world patterns and business rules.</p>"},{"location":"LOCAL_DATA/","title":"Local Data (Dimensions + Facts)","text":"<p>The Local Data tab consolidates dimension and fact generation in one place.</p>"},{"location":"LOCAL_DATA/#workflow","title":"Workflow","text":"<ol> <li>Click \u201cGenerate Dimensions + Facts\u201d</li> <li>Dimensions are generated first</li> <li>Facts are generated next using intelligent date range logic</li> <li>After generation completes:</li> <li>The generate section hides automatically</li> <li>The Status card appears and shows:<ul> <li>Fact Data: \u2705/\u274c</li> <li>Last Generated timestamp</li> <li>Real\u2011time Ready (requires facts)</li> <li>Last Run timestamp</li> <li>Database Range: first \u2192 last event_ts across fact tables</li> </ul> </li> <li>\u201cUpload Dimensions/Facts\u201d becomes available</li> <li>Exports Parquet files and optionally uploads them to Azure Storage if configured.</li> </ol>"},{"location":"LOCAL_DATA/#database-range","title":"Database Range","text":"<ul> <li>Computed from the earliest and latest <code>event_ts</code> values across fact tables.</li> <li>API: <code>GET /api/facts/date-range</code></li> </ul>"},{"location":"LOCAL_DATA/#upload-data-export-upload","title":"Upload Data (Export + Upload)","text":"<ul> <li>Export locations (local): <code>data/export/&lt;table&gt;/...</code></li> <li>Uploads (if configured):</li> <li>Master: <code>datagen/export/master/&lt;timestamp&gt;</code></li> <li>Facts: <code>datagen/export/facts/&lt;timestamp&gt;</code></li> <li>Configure Azure Storage in <code>config.json</code> or environment variables. See Upload Data.</li> </ul>"},{"location":"LOCAL_DATA/#streaming-outbox","title":"Streaming Outbox","text":"<ul> <li>The outbox queue is only populated by the realtime outbox path.</li> <li>Historical (Local Data) runs do not add to the outbox.</li> <li>Manage with:</li> <li><code>GET /api/stream/outbox/status</code></li> <li><code>POST /api/stream/outbox/drain</code></li> <li><code>DELETE /api/stream/outbox/clear</code></li> </ul>"},{"location":"STORE_PROFILES/","title":"Store Profile System","text":""},{"location":"STORE_PROFILES/#overview","title":"Overview","text":"<p>The store profile system creates realistic variability in transaction volumes and operational characteristics across stores in the retail network. Instead of all stores having identical traffic patterns, stores are classified into volume tiers and assigned profiles that reflect real-world diversity in retail operations.</p>"},{"location":"STORE_PROFILES/#problem-solved","title":"Problem Solved","text":"<p>Before: All stores generated identical transaction counts, creating unrealistic uniform distribution.</p> <p>After: Stores exhibit realistic variability based on: - Geographic location (urban vs rural) - Store format (hypermarket vs express) - Volume classification (flagship vs kiosk) - Operating hours and peak patterns</p>"},{"location":"STORE_PROFILES/#architecture","title":"Architecture","text":""},{"location":"STORE_PROFILES/#components","title":"Components","text":"<pre><code>shared/store_profiles.py\n\u251c\u2500\u2500 StoreVolumeClass (enum)      # Traffic tier classification\n\u251c\u2500\u2500 StoreFormat (enum)           # Physical store format\n\u251c\u2500\u2500 OperatingHours (enum)        # Operating hour patterns\n\u251c\u2500\u2500 StoreProfile (dataclass)     # Complete store profile\n\u2514\u2500\u2500 StoreProfiler (class)        # Profile assignment engine\n</code></pre>"},{"location":"STORE_PROFILES/#volume-classifications","title":"Volume Classifications","text":"Volume Class % of Stores Traffic Multiplier Description FLAGSHIP 5% 2.5 - 3.0x Major metro flagship stores HIGH_VOLUME 15% 1.8 - 2.4x Busy urban/suburban locations MEDIUM_VOLUME 50% 0.8 - 1.2x Typical suburban stores LOW_VOLUME 25% 0.4 - 0.7x Rural/small town locations KIOSK 5% 0.25 - 0.35x Express/convenience formats"},{"location":"STORE_PROFILES/#store-formats","title":"Store Formats","text":"Format Typical Size Basket Size Basket Value HYPERMARKET 150k+ sq ft 12-15 items $120-$180 SUPERSTORE 80-150k sq ft 8-10 items $80-$120 STANDARD 40-80k sq ft 5-7 items $40-$70 NEIGHBORHOOD 15-40k sq ft 3-5 items $25-$45 EXPRESS &lt;15k sq ft 1.5-3 items $15-$30"},{"location":"STORE_PROFILES/#operating-hours","title":"Operating Hours","text":"Pattern Hours Typical Use ALWAYS_OPEN 24/7 Urban convenience stores EXTENDED 6am-midnight Large format stores STANDARD 8am-10pm Typical suburban LIMITED 9am-9pm Smaller formats REDUCED 9am-6pm Sundays/holidays"},{"location":"STORE_PROFILES/#integration-points","title":"Integration Points","text":""},{"location":"STORE_PROFILES/#1-dimension-data-generation","title":"1. Dimension Data Generation","text":"<p>File: <code>generators/master_generator.py</code></p> <p>Profiles are assigned during store generation:</p> <pre><code># After stores are created\nprofiler = StoreProfiler(self.stores, self.geography_master, self.config.seed)\nstore_profiles = profiler.assign_profiles()\n\n# Update store records with profile information\nfor store in self.stores:\n    if store.ID in store_profiles:\n        profile = store_profiles[store.ID]\n        store.volume_class = profile.volume_class.value\n        store.store_format = profile.store_format.value\n        store.operating_hours = profile.operating_hours.value\n        store.daily_traffic_multiplier = profile.daily_traffic_multiplier\n</code></pre>"},{"location":"STORE_PROFILES/#2-database-storage","title":"2. Database Storage","text":"<p>File: <code>db/models/master.py</code></p> <p>Store profiles are persisted in the <code>dim_stores</code> table:</p> <pre><code>class Store(Base):\n    __tablename__ = \"dim_stores\"\n\n    # Standard fields\n    store_id: Mapped[int]\n    store_number: Mapped[str]\n    address: Mapped[str]\n    geography_id: Mapped[int]\n\n    # Profile fields\n    volume_class: Mapped[str | None]\n    store_format: Mapped[str | None]\n    operating_hours: Mapped[str | None]\n    daily_traffic_multiplier: Mapped[float | None]\n</code></pre>"},{"location":"STORE_PROFILES/#3-fact-generation","title":"3. Fact Generation","text":"<p>File: <code>generators/fact_generator.py</code></p> <p>Traffic multipliers are applied during hourly activity generation:</p> <pre><code>def _generate_store_hour_activity(self, store: Store, hour_datetime: datetime, multiplier: float):\n    # Base customer count\n    base_customers_per_hour = self.config.volume.customers_per_day / 24\n\n    # Apply store profile multiplier for realistic variability\n    store_multiplier = float(getattr(store, 'daily_traffic_multiplier', Decimal(\"1.0\")))\n\n    # Final customer count includes temporal AND store-specific multipliers\n    expected_customers = int(base_customers_per_hour * multiplier * store_multiplier)\n</code></pre>"},{"location":"STORE_PROFILES/#profile-assignment-logic","title":"Profile Assignment Logic","text":""},{"location":"STORE_PROFILES/#geographic-bias","title":"Geographic Bias","text":"<p>Urban stores have higher probability of being high-volume:</p> <pre><code># Urban distribution (skewed higher)\nFLAGSHIP: 10%      # Double the base rate\nHIGH_VOLUME: 25%\nMEDIUM_VOLUME: 45%\nLOW_VOLUME: 15%\nKIOSK: 5%\n\n# Rural/suburban distribution (skewed lower)\nFLAGSHIP: 2%\nHIGH_VOLUME: 10%\nMEDIUM_VOLUME: 53%\nLOW_VOLUME: 30%\nKIOSK: 5%\n</code></pre>"},{"location":"STORE_PROFILES/#format-selection","title":"Format Selection","text":"<p>Store format is influenced by both volume class and geography:</p> <ul> <li>Flagship stores: Tend toward HYPERMARKET or SUPERSTORE</li> <li>Urban locations: Tend toward smaller formats due to space constraints</li> <li>Rural areas: Can support larger formats with parking</li> </ul>"},{"location":"STORE_PROFILES/#operating-hours_1","title":"Operating Hours","text":"<p>Operating hours depend on format and location:</p> <ul> <li>Express stores: Often 24/7 in urban areas</li> <li>Hypermarkets: Extended hours (6am-midnight)</li> <li>Neighborhood stores: Standard hours (8am-10pm)</li> </ul>"},{"location":"STORE_PROFILES/#validation-metrics","title":"Validation Metrics","text":"<p>The system ensures sufficient variability through statistical checks:</p>"},{"location":"STORE_PROFILES/#coefficient-of-variation-cv","title":"Coefficient of Variation (CV)","text":"<p>Target: CV \u2265 0.5</p> <p>Measures relative variability of traffic multipliers:</p> <pre><code>CV = standard_deviation / mean\n</code></pre> <p>A CV of 0.5+ indicates strong variability (not uniform distribution).</p>"},{"location":"STORE_PROFILES/#range-check","title":"Range Check","text":"<p>Target: Max - Min \u2265 2.0</p> <p>The difference between highest and lowest multipliers should span at least 2.0x.</p>"},{"location":"STORE_PROFILES/#volume-class-distribution","title":"Volume Class Distribution","text":"<p>Target: At least 3 different volume classes present</p> <p>Ensures the dataset isn't dominated by a single store type.</p>"},{"location":"STORE_PROFILES/#testing","title":"Testing","text":""},{"location":"STORE_PROFILES/#unit-tests","title":"Unit Tests","text":"<p>File: <code>tests/unit/test_store_profile_variability.py</code></p> <p>Tests validate: - Profile assignment logic - Volume class distribution - Traffic multiplier variability - Basket size correlation with format - Geographic bias in volume classes</p>"},{"location":"STORE_PROFILES/#validation-script","title":"Validation Script","text":"<p>File: <code>test_store_profiles.py</code></p> <p>Quick validation script that: - Creates 200 test stores - Assigns profiles - Calculates variability metrics - Reports distribution statistics - Validates against thresholds</p> <p>Run with:</p> <pre><code>python test_store_profiles.py\n</code></pre> <p>Expected output:</p> <pre><code>\u2713 Multiple volume classes: 5 classes found\n\u2713 Coefficient of variation: 0.623 (&gt;= 0.5)\n\u2713 Multiplier range: 2.648 (&gt;= 2.0)\n\u2713 Flagship multipliers: min=2.543 (&gt;= 2.0)\n\u2713 Kiosk multipliers: max=0.347 (&lt;= 0.5)\n\nRESULTS: 5/5 checks passed\n</code></pre>"},{"location":"STORE_PROFILES/#impact-on-data-generation","title":"Impact on Data Generation","text":""},{"location":"STORE_PROFILES/#transaction-volume-distribution","title":"Transaction Volume Distribution","text":"<p>With profiles enabled, a typical 200-store network shows:</p> <pre><code>Store Volume Distribution:\n  Top 10 stores:  35% of transactions\n  Middle 100:     50% of transactions\n  Bottom 90:      15% of transactions\n</code></pre>"},{"location":"STORE_PROFILES/#temporal-store-effects","title":"Temporal + Store Effects","text":"<p>The final customer count at any hour is:</p> <pre><code>customers = base_rate \u00d7 temporal_multiplier \u00d7 store_multiplier\n</code></pre> <p>Where: - <code>base_rate</code>: Configured customers_per_day / 24 - <code>temporal_multiplier</code>: Seasonal, daily, hourly patterns (0.3 - 2.5x) - <code>store_multiplier</code>: Store profile traffic multiplier (0.25 - 3.0x)</p>"},{"location":"STORE_PROFILES/#example-scenarios","title":"Example Scenarios","text":"<p>Flagship store on Saturday afternoon:</p> <pre><code>base_rate = 2000 / 24 = 83 customers/hour\ntemporal_multiplier = 2.2 (weekend peak)\nstore_multiplier = 2.8 (flagship)\n\ncustomers = 83 \u00d7 2.2 \u00d7 2.8 = 511 customers/hour\n</code></pre> <p>Kiosk on Tuesday morning:</p> <pre><code>base_rate = 2000 / 24 = 83 customers/hour\ntemporal_multiplier = 0.5 (weekday morning)\nstore_multiplier = 0.3 (kiosk)\n\ncustomers = 83 \u00d7 0.5 \u00d7 0.3 = 12 customers/hour\n</code></pre>"},{"location":"STORE_PROFILES/#configuration","title":"Configuration","text":"<p>Store profiling is deterministic and uses the same seed as master generation:</p> <pre><code># In RetailConfig\nseed: 42  # Controls both dimension data AND profile assignment\n\n# In MasterDataGenerator\nprofiler = StoreProfiler(stores, geographies, seed=self.config.seed)\n</code></pre> <p>This ensures: - Reproducible profiles for the same seed - Consistent store characteristics across runs - Ability to regenerate identical datasets</p>"},{"location":"STORE_PROFILES/#future-enhancements","title":"Future Enhancements","text":"<p>Potential improvements to the profile system:</p> <ol> <li>Seasonal Operating Hours: Adjust hours based on holidays/seasons</li> <li>Store Remodeling Events: Change format/profile over time</li> <li>Competitive Clustering: Model stores near each other</li> <li>Performance Tiers: Link to sales performance metrics</li> <li>Format-Specific Product Mix: Tailor product availability by format</li> </ol>"},{"location":"STORE_PROFILES/#troubleshooting","title":"Troubleshooting","text":""},{"location":"STORE_PROFILES/#all-stores-have-multiplier-10","title":"All stores have multiplier = 1.0","text":"<p>Cause: Profiles not assigned during master generation or not loaded during fact generation.</p> <p>Fix: Ensure <code>StoreProfiler.assign_profiles()</code> is called in <code>master_generator.py</code> and profile fields are loaded in <code>fact_generator.py</code>.</p>"},{"location":"STORE_PROFILES/#database-missing-profile-columns","title":"Database missing profile columns","text":"<p>Cause: Database schema not updated after adding profile fields.</p> <p>Fix: Regenerate dimension data (dim_* tables) in DuckDB, or run a migration to add missing columns.</p>"},{"location":"STORE_PROFILES/#profile-fields-are-none-in-fact-generation","title":"Profile fields are None in fact generation","text":"<p>Cause: Database loader not including profile fields when converting ORM models to Pydantic models.</p> <p>Fix: Verify <code>load_master_data_from_db()</code> includes all profile fields in Store constructor.</p>"},{"location":"STORE_PROFILES/#references","title":"References","text":"<ul> <li>Store Profile Implementation: <code>src/retail_datagen/shared/store_profiles.py</code></li> <li>Master Generator Integration: <code>src/retail_datagen/generators/master_generator.py</code> (lines 806-820)</li> <li>Fact Generator Integration: <code>src/retail_datagen/generators/fact_generator.py</code> (lines 1738-1739)</li> <li>Database Models: <code>src/retail_datagen/db/models/master.py</code> (Store class)</li> <li>Pydantic Models: <code>src/retail_datagen/shared/models.py</code> (Store class)</li> <li>Tests: <code>tests/unit/test_store_profile_variability.py</code></li> </ul>"},{"location":"STREAMING/","title":"Real-Time Event Streaming System","text":"<p>The retail data generator includes a comprehensive real-time event streaming system that generates and streams synthetic retail events to Azure Event Hub. This system simulates live retail operations with realistic patterns, correlations, and timing.</p>"},{"location":"STREAMING/#quick-start","title":"\ud83d\ude80 Quick Start","text":"<pre><code>import asyncio\nfrom datetime import timedelta\nfrom retail_datagen.config.models import RetailConfig\nfrom retail_datagen.streaming import EventStreamer\n\n# Load configuration\nconfig = RetailConfig.from_file(\"config.json\")\n\n# Create and initialize streamer\nstreamer = EventStreamer(config, azure_connection_string=\"your_connection_string\")\n\n# Stream events for 5 minutes\nasync def stream_events():\n    async with streamer.streaming_session(duration=timedelta(minutes=5)):\n        # Streaming runs in background\n        stats = await streamer.get_statistics()\n        print(f\"Generated {stats['events_generated']} events\")\n\nasyncio.run(stream_events())\n</code></pre>"},{"location":"STREAMING/#system-architecture","title":"\ud83d\udccb System Architecture","text":""},{"location":"STREAMING/#core-components","title":"Core Components","text":"<ol> <li>EventStreamer - Main orchestration engine</li> <li>EventFactory - Generates realistic retail events</li> <li>AzureEventHubClient - Azure integration with resilience</li> <li>Event Schemas - Type-safe event definitions</li> </ol>"},{"location":"STREAMING/#event-flow","title":"Event Flow","text":"<pre><code>EventFactory \u2192 EventBuffer \u2192 BatchProcessor \u2192 AzureEventHub\n     \u2193              \u2193             \u2193              \u2193\n  Statistics \u2192 DeadLetterQueue \u2192 CircuitBreaker \u2192 Monitoring\n</code></pre>"},{"location":"STREAMING/#event-types","title":"\ud83c\udfaf Event Types","text":"<p>The system generates these retail event types:</p>"},{"location":"STREAMING/#transaction-events","title":"Transaction Events","text":"<ul> <li><code>receipt_created</code> - New customer purchases</li> <li><code>receipt_line_added</code> - Individual items scanned</li> <li><code>payment_processed</code> - Payment completion</li> </ul>"},{"location":"STREAMING/#inventory-events","title":"Inventory Events","text":"<ul> <li><code>inventory_updated</code> - Stock level changes</li> <li><code>stockout_detected</code> - Out-of-stock conditions</li> <li><code>reorder_triggered</code> - Automatic reordering</li> </ul>"},{"location":"STREAMING/#customer-events","title":"Customer Events","text":"<ul> <li><code>customer_entered</code> - Foot traffic entry</li> <li><code>customer_zone_changed</code> - Movement between store zones</li> <li><code>ble_ping_detected</code> - Bluetooth beacon interactions</li> </ul>"},{"location":"STREAMING/#operational-events","title":"Operational Events","text":"<ul> <li><code>truck_arrived</code> - Delivery events</li> <li><code>truck_departed</code> - Shipment completion</li> <li><code>store_opened</code> - Daily operations start</li> <li><code>store_closed</code> - Daily operations end</li> </ul>"},{"location":"STREAMING/#marketing-events","title":"Marketing Events","text":"<ul> <li><code>ad_impression</code> - Marketing campaign exposures</li> <li><code>promotion_applied</code> - Discount code usage</li> </ul>"},{"location":"STREAMING/#event-envelope-format","title":"\ud83d\udce6 Event Envelope Format","text":"<p>All events use a standardized envelope:</p> <pre><code>{\n  \"event_type\": \"receipt_created\",\n  \"payload\": { /* event-specific data */ },\n  \"trace_id\": \"TR_1704067200_00001\",\n  \"ingest_timestamp\": \"2024-01-01T12:00:00.000Z\",\n  \"schema_version\": \"1.0\",\n  \"source\": \"retail-datagen\",\n  \"correlation_id\": \"optional_correlation_id\",\n  \"partition_key\": \"store_123\"\n}\n</code></pre>"},{"location":"STREAMING/#configuration","title":"\u2699\ufe0f Configuration","text":""},{"location":"STREAMING/#basic-configuration-configjson","title":"Basic Configuration (config.json)","text":"<pre><code>{\n  \"realtime\": {\n    \"emit_interval_ms\": 500,\n    \"burst\": 100,\n    \"azure_connection_string\": \"Endpoint=sb://...\",\n    \"max_batch_size\": 256,\n    \"batch_timeout_ms\": 1000,\n    \"retry_attempts\": 3,\n    \"backoff_multiplier\": 2.0,\n    \"circuit_breaker_enabled\": true,\n    \"monitoring_interval\": 30,\n    \"max_buffer_size\": 10000,\n    \"enable_dead_letter_queue\": true\n  },\n  \"stream\": {\n    \"hub\": \"retail-events\"\n  }\n}\n</code></pre>"},{"location":"STREAMING/#configuration-parameters","title":"Configuration Parameters","text":"Parameter Description Default <code>emit_interval_ms</code> Time between event bursts 500 <code>burst</code> Events per burst 100 <code>max_batch_size</code> Events per Azure batch 256 <code>batch_timeout_ms</code> Max batch wait time 1000 <code>retry_attempts</code> Retry count for failures 3 <code>circuit_breaker_enabled</code> Enable failure protection true <code>monitoring_interval</code> Stats update frequency 30"},{"location":"STREAMING/#advanced-usage","title":"\ud83d\udd27 Advanced Usage","text":""},{"location":"STREAMING/#custom-event-generation","title":"Custom Event Generation","text":"<pre><code>from retail_datagen.streaming import EventFactory, EventType\n\nfactory = EventFactory(stores, customers, products, dcs, seed=42)\n\n# Generate specific event types\nreceipt_event = factory.generate_event(EventType.RECEIPT_CREATED, timestamp)\n\n# Generate mixed events with custom weights\nevent_weights = {\n    EventType.RECEIPT_CREATED: 0.3,\n    EventType.CUSTOMER_ENTERED: 0.4,\n    EventType.INVENTORY_UPDATED: 0.3\n}\nevents = factory.generate_mixed_events(100, timestamp, event_weights)\n</code></pre>"},{"location":"STREAMING/#event-hooks-and-monitoring","title":"Event Hooks and Monitoring","text":"<pre><code>streamer = EventStreamer(config)\n\n# Add event hooks\ndef log_high_value_receipts(event):\n    if event.event_type == EventType.RECEIPT_CREATED:\n        if event.payload.get('total', 0) &gt; 100:\n            print(f\"High-value receipt: ${event.payload['total']}\")\n\ndef log_batch_stats(events):\n    print(f\"Sent batch of {len(events)} events\")\n\ndef handle_errors(error, context):\n    print(f\"Error in {context}: {error}\")\n\nstreamer.add_event_generated_hook(log_high_value_receipts)\nstreamer.add_batch_sent_hook(log_batch_stats)\nstreamer.add_error_hook(handle_errors)\n</code></pre>"},{"location":"STREAMING/#health-monitoring","title":"Health Monitoring","text":"<pre><code># Get real-time statistics\nstats = await streamer.get_statistics()\nprint(f\"Events/sec: {stats['events_per_second']}\")\nprint(f\"Success rate: {stats['events_sent_successfully'] / stats['events_generated']}\")\n\n# Get health status\nhealth = await streamer.get_health_status()\nprint(f\"System healthy: {health['overall_healthy']}\")\nprint(f\"Azure connection: {health['components']['azure_event_hub']['healthy']}\")\n</code></pre>"},{"location":"STREAMING/#resilience-features","title":"\ud83d\udee1\ufe0f Resilience Features","text":""},{"location":"STREAMING/#circuit-breaker-pattern","title":"Circuit Breaker Pattern","text":"<p>Automatically opens circuit after 5 consecutive failures, preventing cascade failures.</p>"},{"location":"STREAMING/#retry-logic","title":"Retry Logic","text":"<p>Exponential backoff with configurable retry attempts for transient failures.</p>"},{"location":"STREAMING/#dead-letter-queue","title":"Dead Letter Queue","text":"<p>Failed events are queued for later processing or analysis.</p>"},{"location":"STREAMING/#buffer-management","title":"Buffer Management","text":"<p>Internal buffering prevents data loss during temporary outages.</p>"},{"location":"STREAMING/#graceful-shutdown","title":"Graceful Shutdown","text":"<p>Proper cleanup ensures no events are lost during shutdown.</p>"},{"location":"STREAMING/#performance-characteristics","title":"\ud83d\udcca Performance Characteristics","text":""},{"location":"STREAMING/#throughput","title":"Throughput","text":"<ul> <li>Target: 1000+ events/second</li> <li>Burst capacity: 10,000 events/burst</li> <li>Azure batching: Up to 256 events/batch</li> </ul>"},{"location":"STREAMING/#latency","title":"Latency","text":"<ul> <li>Event generation: &lt;1ms per event</li> <li>Azure delivery: 100-500ms (network dependent)</li> <li>End-to-end: &lt;1 second typical</li> </ul>"},{"location":"STREAMING/#resource-usage","title":"Resource Usage","text":"<ul> <li>Memory: ~50MB base + 1KB per buffered event</li> <li>CPU: 5-10% of single core at 1000 events/sec</li> <li>Network: ~100KB/sec at 1000 events/sec</li> </ul>"},{"location":"STREAMING/#realistic-event-patterns","title":"\ud83d\udd0d Realistic Event Patterns","text":""},{"location":"STREAMING/#time-based-distribution","title":"Time-based Distribution","text":"<ul> <li>Business hours: Peak activity 9 AM - 8 PM</li> <li>Off-hours: Minimal activity with maintenance events</li> <li>Weekends: Reduced but consistent activity</li> </ul>"},{"location":"STREAMING/#store-based-variation","title":"Store-based Variation","text":"<ul> <li>Large stores: More frequent, higher-value transactions</li> <li>Small stores: Fewer, smaller transactions</li> <li>Geographic factors: Regional shopping patterns</li> </ul>"},{"location":"STREAMING/#event-correlations","title":"Event Correlations","text":"<ul> <li>Receipt creation triggers inventory updates</li> <li>Low inventory triggers reorder events</li> <li>Customer entry correlates with BLE pings</li> <li>Marketing impressions lead to promotional purchases</li> </ul>"},{"location":"STREAMING/#seasonal-effects","title":"Seasonal Effects","text":"<ul> <li>Holiday shopping spikes</li> <li>Weather-related patterns</li> <li>Promotional calendar alignment</li> </ul>"},{"location":"STREAMING/#testing","title":"\ud83e\uddea Testing","text":""},{"location":"STREAMING/#unit-tests","title":"Unit Tests","text":"<pre><code>python -m pytest tests/unit/test_streaming.py\n</code></pre>"},{"location":"STREAMING/#integration-tests","title":"Integration Tests","text":"<pre><code>python -m pytest tests/integration/test_streaming.py\n</code></pre>"},{"location":"STREAMING/#manual-testing","title":"Manual Testing","text":"<pre><code># Test without Azure connection\npython test_streaming_implementation.py\n\n# Example usage\npython example_streaming_usage.py\n</code></pre>"},{"location":"STREAMING/#troubleshooting","title":"\ud83d\udea8 Troubleshooting","text":""},{"location":"STREAMING/#common-issues","title":"Common Issues","text":"<p>Connection Failures - Verify Azure connection string - Check network connectivity - Validate Event Hub name</p> <p>High Memory Usage - Reduce <code>max_buffer_size</code> - Increase <code>batch_timeout_ms</code> - Check for buffer flush failures</p> <p>Low Throughput - Decrease <code>emit_interval_ms</code> - Increase <code>burst</code> size - Optimize <code>max_batch_size</code></p> <p>Event Delivery Failures - Check Azure Event Hub quotas - Verify authentication - Monitor circuit breaker state</p>"},{"location":"STREAMING/#debug-mode","title":"Debug Mode","text":"<p>Enable debug logging for detailed troubleshooting:</p> <pre><code>import logging\nlogging.basicConfig(level=logging.DEBUG)\n\n# Now run streaming system\n</code></pre>"},{"location":"STREAMING/#monitoring-and-metrics","title":"\ud83d\udcc8 Monitoring and Metrics","text":""},{"location":"STREAMING/#key-metrics","title":"Key Metrics","text":"<ul> <li><code>events_generated</code> - Total events created</li> <li><code>events_sent_successfully</code> - Events delivered to Azure</li> <li><code>events_failed</code> - Failed delivery attempts</li> <li><code>events_per_second</code> - Current throughput</li> <li><code>batches_sent</code> - Azure batches delivered</li> <li><code>connection_failures</code> - Azure connectivity issues</li> </ul>"},{"location":"STREAMING/#health-checks","title":"Health Checks","text":"<ul> <li>Azure Event Hub connectivity</li> <li>Circuit breaker state</li> <li>Buffer utilization</li> <li>Error rates</li> <li>Resource usage</li> </ul>"},{"location":"STREAMING/#security-considerations","title":"\ud83d\udd10 Security Considerations","text":""},{"location":"STREAMING/#data-privacy","title":"Data Privacy","text":"<ul> <li>All generated data is synthetic</li> <li>No real customer information</li> <li>GDPR/CCPA compliant by design</li> </ul>"},{"location":"STREAMING/#azure-integration","title":"Azure Integration","text":"<ul> <li>Connection string encryption recommended</li> <li>Network security group restrictions</li> <li>Azure Active Directory integration supported</li> </ul>"},{"location":"STREAMING/#audit-logging","title":"Audit Logging","text":"<ul> <li>All events include trace IDs</li> <li>Comprehensive error logging</li> <li>Security event monitoring</li> </ul>"},{"location":"STREAMING/#production-deployment","title":"\ud83c\udfaf Production Deployment","text":""},{"location":"STREAMING/#azure-event-hub-setup","title":"Azure Event Hub Setup","text":"<ol> <li>Create Event Hub namespace</li> <li>Create retail-events hub</li> <li>Configure access policies</li> <li>Set up monitoring alerts</li> </ol>"},{"location":"STREAMING/#configuration-management","title":"Configuration Management","text":"<ul> <li>Store connection strings securely</li> <li>Use environment variables</li> <li>Implement configuration validation</li> </ul>"},{"location":"STREAMING/#monitoring-setup","title":"Monitoring Setup","text":"<ul> <li>Azure Monitor integration</li> <li>Custom metric dashboards</li> <li>Alert rules for failures</li> </ul>"},{"location":"STREAMING/#scaling-considerations","title":"Scaling Considerations","text":"<ul> <li>Multiple streamer instances</li> <li>Event Hub partition strategy</li> <li>Load balancing across regions</li> </ul>"},{"location":"STREAMING/#api-reference","title":"\ud83d\udcda API Reference","text":""},{"location":"STREAMING/#eventstreamer-class","title":"EventStreamer Class","text":""},{"location":"STREAMING/#methods","title":"Methods","text":"<ul> <li><code>initialize()</code> - Initialize streaming components</li> <li><code>start(duration)</code> - Begin streaming</li> <li><code>stop()</code> - Graceful shutdown</li> <li><code>get_statistics()</code> - Current metrics</li> <li><code>get_health_status()</code> - Health information</li> </ul>"},{"location":"STREAMING/#context-manager","title":"Context Manager","text":"<pre><code>async with streamer.streaming_session(duration):\n    # Streaming active\n    pass\n# Automatically cleaned up\n</code></pre>"},{"location":"STREAMING/#eventfactory-class","title":"EventFactory Class","text":""},{"location":"STREAMING/#methods_1","title":"Methods","text":"<ul> <li><code>generate_event(type, timestamp)</code> - Single event</li> <li><code>generate_mixed_events(count, timestamp, weights)</code> - Mixed batch</li> <li><code>should_generate_event(type, timestamp)</code> - Pattern check</li> </ul>"},{"location":"STREAMING/#azureeventhubclient-class","title":"AzureEventHubClient Class","text":""},{"location":"STREAMING/#methods_2","title":"Methods","text":"<ul> <li><code>connect()</code> - Establish connection</li> <li><code>disconnect()</code> - Close connection</li> <li><code>send_events(events)</code> - Batch send</li> <li><code>health_check()</code> - Connection status</li> <li><code>get_statistics()</code> - Client metrics</li> </ul> <p>For complete API documentation, see the inline docstrings and type hints in the source code.</p>"},{"location":"STREAMING_API/","title":"Streaming API Reference","text":"<p>Complete REST API reference for real-time event streaming endpoints.</p>"},{"location":"STREAMING_API/#base-url","title":"Base URL","text":"<pre><code>http://localhost:8000/api\n</code></pre>"},{"location":"STREAMING_API/#authentication","title":"Authentication","text":"<p>Currently no authentication required for local development. For production deployments, implement authentication middleware.</p>"},{"location":"STREAMING_API/#streaming-control-endpoints","title":"Streaming Control Endpoints","text":""},{"location":"STREAMING_API/#start-streaming","title":"Start Streaming","text":"<p>Start real-time event streaming to Azure Event Hub.</p> <pre><code>POST /stream/start\n</code></pre> <p>Request Body:</p> <pre><code>{\n  \"emit_interval_ms\": 500,\n  \"burst\": 100,\n  \"duration_minutes\": null,\n  \"event_types\": [\"receipt_created\", \"inventory_updated\"]\n}\n</code></pre> <p>Parameters: - <code>emit_interval_ms</code> (integer, optional): Milliseconds between event bursts. Default: 500 - <code>burst</code> (integer, optional): Number of events per burst. Default: 100 - <code>duration_minutes</code> (integer, optional): Auto-stop after N minutes. Null = run indefinitely - <code>event_types</code> (array, optional): Filter specific event types. Null = all types</p> <p>Response (200 OK):</p> <pre><code>{\n  \"success\": true,\n  \"message\": \"Event streaming started\",\n  \"operation_id\": \"streaming_a1b2c3d4\",\n  \"started_at\": \"2024-01-15T10:30:00Z\"\n}\n</code></pre> <p>Error Responses:</p> <ul> <li>409 Conflict: Streaming already active</li> <li>400 Bad Request: Invalid event types or missing fact data</li> <li>400 Bad Request: Azure connection string not configured</li> </ul> <p>Example:</p> <pre><code>curl -X POST http://localhost:8000/api/stream/start \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"emit_interval_ms\": 1000,\n    \"burst\": 50,\n    \"duration_minutes\": 10\n  }'\n</code></pre>"},{"location":"STREAMING_API/#stop-streaming","title":"Stop Streaming","text":"<p>Stop the currently active streaming session.</p> <pre><code>POST /stream/stop\n</code></pre> <p>Response (200 OK):</p> <pre><code>{\n  \"success\": true,\n  \"message\": \"Event streaming stopped\",\n  \"operation_id\": \"streaming_a1b2c3d4\"\n}\n</code></pre> <p>Error Responses:</p> <ul> <li>400 Bad Request: No active streaming session</li> <li>404 Not Found: Streaming session not found</li> </ul> <p>Example:</p> <pre><code>curl -X POST http://localhost:8000/api/stream/stop\n</code></pre>"},{"location":"STREAMING_API/#get-streaming-status","title":"Get Streaming Status","text":"<p>Get current streaming status and basic statistics.</p> <pre><code>GET /stream/status\n</code></pre> <p>Response (200 OK):</p> <pre><code>{\n  \"is_streaming\": true,\n  \"status\": \"running\",\n  \"uptime_seconds\": 450.5,\n  \"events_sent\": 15234,\n  \"events_per_second\": 33.8,\n  \"last_event_time\": \"2024-01-15T10:37:30Z\"\n}\n</code></pre> <p>Status Values: - <code>running</code>: Actively streaming events - <code>stopped</code>: No active streaming session - <code>error</code>: Streaming encountered errors</p> <p>Example:</p> <pre><code>curl http://localhost:8000/api/stream/status\n</code></pre>"},{"location":"STREAMING_API/#statistics-monitoring-endpoints","title":"Statistics &amp; Monitoring Endpoints","text":""},{"location":"STREAMING_API/#get-detailed-statistics","title":"Get Detailed Statistics","text":"<p>Get comprehensive streaming statistics and metrics.</p> <pre><code>GET /stream/statistics\n</code></pre> <p>Response (200 OK):</p> <pre><code>{\n  \"events_generated\": 25000,\n  \"events_sent_successfully\": 24897,\n  \"events_failed\": 103,\n  \"batches_sent\": 250,\n  \"total_streaming_time\": 600.5,\n  \"events_per_second\": 41.6,\n  \"bytes_sent\": 15728640,\n  \"last_event_time\": \"2024-01-15T10:40:00Z\",\n  \"event_type_counts\": {\n    \"receipt_created\": 5000,\n    \"receipt_line_added\": 15000,\n    \"inventory_updated\": 3000,\n    \"customer_entered\": 2000\n  },\n  \"error_counts\": {\n    \"connection_timeout\": 85,\n    \"throttling\": 18\n  },\n  \"connection_failures\": 12,\n  \"circuit_breaker_trips\": 2\n}\n</code></pre> <p>Example:</p> <pre><code>curl http://localhost:8000/api/stream/statistics\n</code></pre>"},{"location":"STREAMING_API/#get-recent-events","title":"Get Recent Events","text":"<p>Retrieve the most recent streaming events (last 100 events buffered).</p> <pre><code>GET /stream/events/recent?limit=50\n</code></pre> <p>Query Parameters: - <code>limit</code> (integer): Number of events to return (1-100). Default: 100</p> <p>Response (200 OK):</p> <pre><code>{\n  \"events\": [\n    {\n      \"timestamp\": \"2024-01-15T10:40:15Z\",\n      \"event_type\": \"receipt_created\",\n      \"trace_id\": \"TR_20240115_abc123\",\n      \"payload\": {\n        \"store_id\": 42,\n        \"customer_id\": 15678,\n        \"receipt_id\": \"RCT_20240115_xyz789\",\n        \"total\": 85.42,\n        \"item_count\": 8\n      }\n    }\n  ],\n  \"count\": 50,\n  \"timestamp\": \"2024-01-15T10:40:30Z\"\n}\n</code></pre> <p>Example:</p> <pre><code>curl \"http://localhost:8000/api/stream/events/recent?limit=20\"\n</code></pre>"},{"location":"STREAMING_API/#stream-health-check","title":"Stream Health Check","text":"<p>Check health of streaming components.</p> <pre><code>GET /stream/health\n</code></pre> <p>Response (200 OK):</p> <pre><code>{\n  \"status\": \"healthy\",\n  \"timestamp\": \"2024-01-15T10:40:00Z\",\n  \"checks\": {\n    \"streaming_task\": {\n      \"status\": \"active\",\n      \"task_status\": \"running\",\n      \"uptime_seconds\": 600\n    },\n    \"azure_config\": {\n      \"status\": \"configured\",\n      \"hub_name\": \"retail-events\"\n    },\n    \"statistics\": {\n      \"status\": \"healthy\",\n      \"events_generated\": 25000,\n      \"events_per_second\": 41.6,\n      \"failure_rate\": 0.004\n    }\n  }\n}\n</code></pre> <p>Status Values: - <code>healthy</code>: All components operational - <code>degraded</code>: Some components not configured or have issues - <code>unhealthy</code>: Critical failures detected</p> <p>Example:</p> <pre><code>curl http://localhost:8000/api/stream/health\n</code></pre>"},{"location":"STREAMING_API/#configuration-endpoints","title":"Configuration Endpoints","text":""},{"location":"STREAMING_API/#get-streaming-configuration","title":"Get Streaming Configuration","text":"<p>Get current streaming and real-time configuration.</p> <pre><code>GET /stream/config\n</code></pre> <p>Response (200 OK):</p> <pre><code>{\n  \"realtime\": {\n    \"emit_interval_ms\": 500,\n    \"burst\": 100,\n    \"azure_connection_string\": \"Endpoint=sb://...\",\n    \"max_batch_size\": 256,\n    \"circuit_breaker_enabled\": true\n  },\n  \"stream\": {\n    \"hub\": \"retail-events\"\n  },\n  \"available_event_types\": [\n    \"receipt_created\",\n    \"receipt_line_added\",\n    \"payment_processed\",\n    \"inventory_updated\",\n    \"stockout_detected\",\n    \"reorder_triggered\",\n    \"customer_entered\",\n    \"customer_zone_changed\",\n    \"ble_ping_detected\",\n    \"truck_arrived\",\n    \"truck_departed\",\n    \"store_opened\",\n    \"store_closed\",\n    \"ad_impression\",\n    \"promotion_applied\"\n  ]\n}\n</code></pre> <p>Example:</p> <pre><code>curl http://localhost:8000/api/stream/config\n</code></pre>"},{"location":"STREAMING_API/#update-streaming-configuration","title":"Update Streaming Configuration","text":"<p>Update streaming configuration settings.</p> <pre><code>PUT /stream/config\n</code></pre> <p>Request Body:</p> <pre><code>{\n  \"emit_interval_ms\": 1000,\n  \"burst\": 50,\n  \"max_batch_size\": 128,\n  \"circuit_breaker_enabled\": true\n}\n</code></pre> <p>Parameters (all optional): - <code>emit_interval_ms</code> (integer): Time between bursts - <code>burst</code> (integer): Events per burst - <code>max_batch_size</code> (integer): Max events per batch - <code>batch_timeout_ms</code> (integer): Batch timeout - <code>retry_attempts</code> (integer): Send retry attempts - <code>circuit_breaker_enabled</code> (boolean): Enable circuit breaker - <code>monitoring_interval</code> (integer): Monitoring interval seconds</p> <p>Response (200 OK):</p> <pre><code>{\n  \"success\": true,\n  \"message\": \"Streaming configuration updated successfully\"\n}\n</code></pre> <p>Error Responses:</p> <ul> <li>409 Conflict: Cannot update while streaming is active</li> <li>400 Bad Request: Invalid configuration values</li> </ul> <p>Example:</p> <pre><code>curl -X PUT http://localhost:8000/api/stream/config \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"emit_interval_ms\": 2000, \"burst\": 25}'\n</code></pre>"},{"location":"STREAMING_API/#test-azure-connection","title":"Test Azure Connection","text":"<p>Test connection to Azure Event Hub.</p> <pre><code>POST /stream/test\n</code></pre> <p>Response (200 OK - Success):</p> <pre><code>{\n  \"success\": true,\n  \"message\": \"Connection test successful\",\n  \"response_time_ms\": 45.2,\n  \"details\": {\n    \"namespace\": \"retail-analytics\",\n    \"event_hub\": \"retail-events\"\n  }\n}\n</code></pre> <p>Response (200 OK - Failure):</p> <pre><code>{\n  \"success\": false,\n  \"message\": \"Connection test failed: Authentication failed\",\n  \"response_time_ms\": 125.8,\n  \"details\": {\n    \"exception_type\": \"AuthenticationError\"\n  }\n}\n</code></pre> <p>Example:</p> <pre><code>curl -X POST http://localhost:8000/api/stream/test\n</code></pre>"},{"location":"STREAMING_API/#event-type-management","title":"Event Type Management","text":""},{"location":"STREAMING_API/#list-available-event-types","title":"List Available Event Types","text":"<p>Get list of all available event types for streaming.</p> <pre><code>GET /stream/event-types\n</code></pre> <p>Response (200 OK):</p> <pre><code>{\n  \"event_types\": [\n    \"receipt_created\",\n    \"receipt_line_added\",\n    \"payment_processed\",\n    \"inventory_updated\",\n    \"stockout_detected\",\n    \"reorder_triggered\",\n    \"customer_entered\",\n    \"customer_zone_changed\",\n    \"ble_ping_detected\",\n    \"truck_arrived\",\n    \"truck_departed\",\n    \"store_opened\",\n    \"store_closed\",\n    \"ad_impression\",\n    \"promotion_applied\"\n  ],\n  \"count\": 15,\n  \"description\": \"Available event types for real-time streaming\"\n}\n</code></pre> <p>Example:</p> <pre><code>curl http://localhost:8000/api/stream/event-types\n</code></pre>"},{"location":"STREAMING_API/#supply-chain-disruption-endpoints","title":"Supply Chain Disruption Endpoints","text":"<p>Simulate supply chain disruptions that affect streaming events.</p>"},{"location":"STREAMING_API/#create-disruption","title":"Create Disruption","text":"<p>Create a supply chain disruption simulation.</p> <pre><code>POST /disruption/create\n</code></pre> <p>Request Body:</p> <pre><code>{\n  \"disruption_type\": \"truck_breakdown\",\n  \"target_id\": 5,\n  \"severity\": 0.7,\n  \"duration_minutes\": 30,\n  \"product_ids\": [101, 102, 103]\n}\n</code></pre> <p>Parameters: - <code>disruption_type</code> (string): Type of disruption   - <code>dc_outage</code>: Distribution center outage   - <code>inventory_shortage</code>: Inventory shortage   - <code>truck_breakdown</code>: Truck breakdown   - <code>weather_delay</code>: Weather-related delays - <code>target_id</code> (integer): Target entity ID (DC, store, or truck) - <code>severity</code> (float): Disruption severity (0.0-1.0) - <code>duration_minutes</code> (integer): Duration in minutes - <code>product_ids</code> (array, optional): Affected product IDs</p> <p>Response (200 OK):</p> <pre><code>{\n  \"success\": true,\n  \"disruption_id\": \"disruption_x7y8z9\",\n  \"message\": \"Created truck_breakdown disruption for target 5\",\n  \"active_until\": \"2024-01-15T11:10:00Z\"\n}\n</code></pre> <p>Example:</p> <pre><code>curl -X POST http://localhost:8000/api/disruption/create \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"disruption_type\": \"inventory_shortage\",\n    \"target_id\": 10,\n    \"severity\": 0.5,\n    \"duration_minutes\": 15\n  }'\n</code></pre>"},{"location":"STREAMING_API/#list-active-disruptions","title":"List Active Disruptions","text":"<p>Get all currently active disruptions.</p> <pre><code>GET /disruption/list\n</code></pre> <p>Response (200 OK):</p> <pre><code>{\n  \"disruptions\": [\n    {\n      \"disruption_id\": \"disruption_x7y8z9\",\n      \"type\": \"truck_breakdown\",\n      \"target_id\": 5,\n      \"severity\": 0.7,\n      \"created_at\": \"2024-01-15T10:40:00Z\",\n      \"active_until\": \"2024-01-15T11:10:00Z\",\n      \"time_remaining_minutes\": 12.5,\n      \"events_affected\": 45,\n      \"status\": \"active\"\n    }\n  ],\n  \"count\": 1,\n  \"timestamp\": \"2024-01-15T10:57:30Z\"\n}\n</code></pre> <p>Example:</p> <pre><code>curl http://localhost:8000/api/disruption/list\n</code></pre>"},{"location":"STREAMING_API/#cancel-disruption","title":"Cancel Disruption","text":"<p>Cancel a specific active disruption.</p> <pre><code>DELETE /disruption/{disruption_id}\n</code></pre> <p>Response (200 OK):</p> <pre><code>{\n  \"success\": true,\n  \"message\": \"Cancelled disruption disruption_x7y8z9\",\n  \"operation_id\": \"disruption_x7y8z9\"\n}\n</code></pre> <p>Error Response:</p> <ul> <li>404 Not Found: Disruption not found or already expired</li> </ul> <p>Example:</p> <pre><code>curl -X DELETE http://localhost:8000/api/disruption/disruption_x7y8z9\n</code></pre>"},{"location":"STREAMING_API/#clear-all-disruptions","title":"Clear All Disruptions","text":"<p>Cancel all active disruptions.</p> <pre><code>POST /disruption/clear-all\n</code></pre> <p>Response (200 OK):</p> <pre><code>{\n  \"success\": true,\n  \"message\": \"Cleared 3 active disruptions\"\n}\n</code></pre> <p>Example:</p> <pre><code>curl -X POST http://localhost:8000/api/disruption/clear-all\n</code></pre>"},{"location":"STREAMING_API/#event-envelope-format","title":"Event Envelope Format","text":"<p>All events use a standard envelope format for consistency and traceability.</p>"},{"location":"STREAMING_API/#envelope-schema","title":"Envelope Schema","text":"<pre><code>{\n  \"event_type\": \"receipt_created\",\n  \"payload\": {\n    \"store_id\": 42,\n    \"customer_id\": 15678,\n    \"receipt_id\": \"RCT_20240115_xyz789\",\n    \"subtotal\": 78.50,\n    \"tax\": 6.92,\n    \"total\": 85.42,\n    \"tender_type\": \"CREDIT_CARD\",\n    \"item_count\": 8\n  },\n  \"trace_id\": \"TR_20240115_abc123xyz\",\n  \"ingest_timestamp\": \"2024-01-15T10:40:15.123Z\",\n  \"schema_version\": \"1.0\",\n  \"source\": \"retail-datagen\",\n  \"correlation_id\": \"SESSION_xyz789\",\n  \"partition_key\": \"store_42\"\n}\n</code></pre> <p>Envelope Fields: - <code>event_type</code> (string): Event type identifier (see Event Types section) - <code>payload</code> (object): Event-specific data - <code>trace_id</code> (string): Unique trace identifier for tracking - <code>ingest_timestamp</code> (string): ISO-8601 timestamp when event was created - <code>schema_version</code> (string): Event schema version (default: \"1.0\") - <code>source</code> (string): Source system (default: \"retail-datagen\") - <code>correlation_id</code> (string, optional): Links related events - <code>partition_key</code> (string, optional): Event Hub partition key</p>"},{"location":"STREAMING_API/#event-types-payloads","title":"Event Types &amp; Payloads","text":""},{"location":"STREAMING_API/#transaction-events","title":"Transaction Events","text":""},{"location":"STREAMING_API/#receipt_created","title":"receipt_created","text":"<pre><code>{\n  \"store_id\": 42,\n  \"customer_id\": 15678,\n  \"receipt_id\": \"RCT_20240115_xyz789\",\n  \"subtotal\": 78.50,\n  \"tax\": 6.92,\n  \"total\": 85.42,\n  \"tender_type\": \"CREDIT_CARD\",\n  \"item_count\": 8\n}\n</code></pre>"},{"location":"STREAMING_API/#receipt_line_added","title":"receipt_line_added","text":"<pre><code>{\n  \"receipt_id\": \"RCT_20240115_xyz789\",\n  \"line_number\": 1,\n  \"product_id\": 1523,\n  \"quantity\": 2,\n  \"unit_price\": 12.99,\n  \"extended_price\": 25.98,\n  \"promo_code\": \"SAVE10\"\n}\n</code></pre>"},{"location":"STREAMING_API/#payment_processed","title":"payment_processed","text":"<pre><code>{\n  \"receipt_id\": \"RCT_20240115_xyz789\",\n  \"payment_method\": \"CREDIT_CARD\",\n  \"amount\": 85.42,\n  \"transaction_id\": \"TXN_abc123\",\n  \"processing_time\": \"2024-01-15T10:40:15Z\",\n  \"status\": \"APPROVED\"\n}\n</code></pre>"},{"location":"STREAMING_API/#inventory-events","title":"Inventory Events","text":""},{"location":"STREAMING_API/#inventory_updated","title":"inventory_updated","text":"<pre><code>{\n  \"store_id\": 42,\n  \"dc_id\": null,\n  \"product_id\": 1523,\n  \"quantity_delta\": -2,\n  \"reason\": \"SALE\",\n  \"source\": \"POS\"\n}\n</code></pre>"},{"location":"STREAMING_API/#stockout_detected","title":"stockout_detected","text":"<pre><code>{\n  \"store_id\": 42,\n  \"dc_id\": null,\n  \"product_id\": 1523,\n  \"last_known_quantity\": 0,\n  \"detection_time\": \"2024-01-15T10:40:00Z\"\n}\n</code></pre>"},{"location":"STREAMING_API/#reorder_triggered","title":"reorder_triggered","text":"<pre><code>{\n  \"store_id\": 42,\n  \"dc_id\": null,\n  \"product_id\": 1523,\n  \"current_quantity\": 5,\n  \"reorder_quantity\": 50,\n  \"reorder_point\": 10,\n  \"priority\": \"HIGH\"\n}\n</code></pre>"},{"location":"STREAMING_API/#customer-events","title":"Customer Events","text":""},{"location":"STREAMING_API/#customer_entered","title":"customer_entered","text":"<pre><code>{\n  \"store_id\": 42,\n  \"sensor_id\": \"SENSOR_ENTRANCE_A\",\n  \"zone\": \"ENTRANCE\",\n  \"customer_count\": 1,\n  \"dwell_time\": 0\n}\n</code></pre>"},{"location":"STREAMING_API/#customer_zone_changed","title":"customer_zone_changed","text":"<pre><code>{\n  \"store_id\": 42,\n  \"customer_ble_id\": \"BLE_abc123\",\n  \"from_zone\": \"ENTRANCE\",\n  \"to_zone\": \"PRODUCE\",\n  \"timestamp\": \"2024-01-15T10:40:15Z\"\n}\n</code></pre>"},{"location":"STREAMING_API/#ble_ping_detected","title":"ble_ping_detected","text":"<pre><code>{\n  \"store_id\": 42,\n  \"beacon_id\": \"BEACON_PRODUCE_1\",\n  \"customer_ble_id\": \"BLE_abc123\",\n  \"rssi\": -65,\n  \"zone\": \"PRODUCE\"\n}\n</code></pre>"},{"location":"STREAMING_API/#operational-events","title":"Operational Events","text":""},{"location":"STREAMING_API/#truck_arrived","title":"truck_arrived","text":"<pre><code>{\n  \"truck_id\": \"TRK_12345\",\n  \"dc_id\": null,\n  \"store_id\": 42,\n  \"shipment_id\": \"SHIP_xyz789\",\n  \"arrival_time\": \"2024-01-15T10:40:00Z\",\n  \"estimated_unload_duration\": 45\n}\n</code></pre>"},{"location":"STREAMING_API/#truck_departed","title":"truck_departed","text":"<pre><code>{\n  \"truck_id\": \"TRK_12345\",\n  \"dc_id\": 5,\n  \"store_id\": null,\n  \"shipment_id\": \"SHIP_xyz789\",\n  \"departure_time\": \"2024-01-15T11:25:00Z\",\n  \"actual_unload_duration\": 48\n}\n</code></pre>"},{"location":"STREAMING_API/#store_opened-store_closed","title":"store_opened / store_closed","text":"<pre><code>{\n  \"store_id\": 42,\n  \"operation_time\": \"2024-01-15T08:00:00Z\",\n  \"operation_type\": \"opened\"\n}\n</code></pre>"},{"location":"STREAMING_API/#marketing-events","title":"Marketing Events","text":""},{"location":"STREAMING_API/#ad_impression","title":"ad_impression","text":"<pre><code>{\n  \"channel\": \"SOCIAL_MEDIA\",\n  \"campaign_id\": \"CAMP_WINTER_2024\",\n  \"creative_id\": \"CREATIVE_001\",\n  \"customer_ad_id\": \"AD_xyz789\",\n  \"impression_id\": \"IMP_abc123\",\n  \"cost\": 0.15,\n  \"device_type\": \"MOBILE\"\n}\n</code></pre>"},{"location":"STREAMING_API/#promotion_applied","title":"promotion_applied","text":"<pre><code>{\n  \"receipt_id\": \"RCT_20240115_xyz789\",\n  \"promo_code\": \"SAVE10\",\n  \"discount_amount\": 8.50,\n  \"discount_type\": \"percentage\",\n  \"product_ids\": [1523, 1524, 1525]\n}\n</code></pre>"},{"location":"STREAMING_API/#rate-limiting","title":"Rate Limiting","text":"<p>Some endpoints have rate limiting to prevent abuse:</p> <ul> <li><code>/stream/start</code>: 5 requests per 60 seconds</li> <li><code>/stream/test</code>: 10 requests per 60 seconds</li> <li><code>/disruption/create</code>: 20 requests per 60 seconds</li> </ul> <p>Rate limit exceeded response (429):</p> <pre><code>{\n  \"detail\": \"Rate limit exceeded. Try again later.\"\n}\n</code></pre>"},{"location":"STREAMING_API/#error-responses","title":"Error Responses","text":"<p>Standard error response format:</p> <pre><code>{\n  \"detail\": \"Error message describing the issue\"\n}\n</code></pre> <p>Common HTTP Status Codes: - <code>200 OK</code>: Request successful - <code>400 Bad Request</code>: Invalid request parameters - <code>404 Not Found</code>: Resource not found - <code>409 Conflict</code>: Conflicting state (e.g., streaming already active) - <code>429 Too Many Requests</code>: Rate limit exceeded - <code>500 Internal Server Error</code>: Server-side error - <code>501 Not Implemented</code>: Feature not yet implemented</p>"},{"location":"STREAMING_API/#websocket-support-future","title":"WebSocket Support (Future)","text":"<p>WebSocket support for real-time event streaming is planned for future releases:</p> <pre><code>ws://localhost:8000/ws/stream\n</code></pre> <p>This will enable browser-based real-time event monitoring without polling.</p>"},{"location":"STREAMING_API/#openapi-documentation","title":"OpenAPI Documentation","text":"<p>Interactive API documentation available at:</p> <ul> <li>Swagger UI: http://localhost:8000/docs</li> <li>ReDoc: http://localhost:8000/redoc</li> <li>OpenAPI JSON: http://localhost:8000/openapi.json</li> </ul>"},{"location":"STREAMING_API/#sdk-examples","title":"SDK Examples","text":""},{"location":"STREAMING_API/#python","title":"Python","text":"<pre><code>import requests\n\n# Start streaming\nresponse = requests.post('http://localhost:8000/api/stream/start', json={\n    'emit_interval_ms': 1000,\n    'burst': 50,\n    'duration_minutes': 10\n})\nprint(response.json())\n\n# Get status\nstatus = requests.get('http://localhost:8000/api/stream/status')\nprint(status.json())\n\n# Stop streaming\nstop = requests.post('http://localhost:8000/api/stream/stop')\nprint(stop.json())\n</code></pre>"},{"location":"STREAMING_API/#javascriptnodejs","title":"JavaScript/Node.js","text":"<pre><code>const axios = require('axios');\n\nconst baseURL = 'http://localhost:8000/api';\n\n// Start streaming\nasync function startStreaming() {\n  const response = await axios.post(`${baseURL}/stream/start`, {\n    emit_interval_ms: 1000,\n    burst: 50,\n    duration_minutes: 10\n  });\n  console.log(response.data);\n}\n\n// Get status\nasync function getStatus() {\n  const response = await axios.get(`${baseURL}/stream/status`);\n  console.log(response.data);\n}\n\n// Stop streaming\nasync function stopStreaming() {\n  const response = await axios.post(`${baseURL}/stream/stop`);\n  console.log(response.data);\n}\n</code></pre>"},{"location":"STREAMING_API/#curl","title":"cURL","text":"<pre><code># Start streaming\ncurl -X POST http://localhost:8000/api/stream/start \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"emit_interval_ms\": 1000, \"burst\": 50, \"duration_minutes\": 10}'\n\n# Get status\ncurl http://localhost:8000/api/stream/status\n\n# Stop streaming\ncurl -X POST http://localhost:8000/api/stream/stop\n</code></pre>"},{"location":"STREAMING_API/#next-steps","title":"Next Steps","text":"<ul> <li>Setup: See STREAMING_SETUP.md for configuration</li> <li>Operations: See STREAMING_OPERATIONS.md for monitoring</li> <li>Security: See CREDENTIALS.md for credential management</li> </ul>"},{"location":"STREAMING_OPERATIONS/","title":"Streaming Operations Guide","text":"<p>Comprehensive guide for monitoring, troubleshooting, and operating real-time event streaming in production.</p>"},{"location":"STREAMING_OPERATIONS/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Monitoring</li> <li>Key Metrics</li> <li>Health Checks</li> <li>Troubleshooting</li> <li>Circuit Breaker</li> <li>Dead Letter Queue</li> <li>Performance Tuning</li> <li>Production Deployment</li> <li>Best Practices</li> </ul>"},{"location":"STREAMING_OPERATIONS/#monitoring","title":"Monitoring","text":""},{"location":"STREAMING_OPERATIONS/#dashboard-overview","title":"Dashboard Overview","text":"<p>The web UI provides real-time monitoring at http://localhost:8000:</p> <p>Key Sections: - Streaming Status: Active/stopped, uptime, events sent - Event Rate: Events per second graph - Event Type Distribution: Breakdown by event type - Error Rate: Failed events and circuit breaker status - Recent Events: Last 100 events with payloads</p>"},{"location":"STREAMING_OPERATIONS/#api-monitoring","title":"API Monitoring","text":"<p>Use the REST API for programmatic monitoring and alerting.</p>"},{"location":"STREAMING_OPERATIONS/#get-current-status","title":"Get Current Status","text":"<pre><code>curl http://localhost:8000/api/stream/status\n</code></pre> <p>Response:</p> <pre><code>{\n  \"is_streaming\": true,\n  \"status\": \"running\",\n  \"uptime_seconds\": 3600,\n  \"events_sent\": 120000,\n  \"events_per_second\": 33.3,\n  \"last_event_time\": \"2024-01-15T11:30:00Z\"\n}\n</code></pre>"},{"location":"STREAMING_OPERATIONS/#get-detailed-statistics","title":"Get Detailed Statistics","text":"<pre><code>curl http://localhost:8000/api/stream/statistics\n</code></pre> <p>Response:</p> <pre><code>{\n  \"events_generated\": 125000,\n  \"events_sent_successfully\": 124500,\n  \"events_failed\": 500,\n  \"batches_sent\": 1250,\n  \"total_streaming_time\": 3600,\n  \"events_per_second\": 34.7,\n  \"bytes_sent\": 62500000,\n  \"event_type_counts\": {\n    \"receipt_created\": 25000,\n    \"receipt_line_added\": 75000,\n    \"inventory_updated\": 15000,\n    \"customer_entered\": 10000\n  },\n  \"error_counts\": {\n    \"connection_timeout\": 350,\n    \"throttling\": 150\n  },\n  \"connection_failures\": 50,\n  \"circuit_breaker_trips\": 5\n}\n</code></pre>"},{"location":"STREAMING_OPERATIONS/#health-check","title":"Health Check","text":"<pre><code>curl http://localhost:8000/api/stream/health\n</code></pre> <p>Response:</p> <pre><code>{\n  \"status\": \"healthy\",\n  \"timestamp\": \"2024-01-15T11:30:00Z\",\n  \"checks\": {\n    \"streaming_task\": {\n      \"status\": \"active\",\n      \"task_status\": \"running\",\n      \"uptime_seconds\": 3600\n    },\n    \"azure_config\": {\n      \"status\": \"configured\",\n      \"hub_name\": \"retail-events\"\n    },\n    \"statistics\": {\n      \"status\": \"healthy\",\n      \"events_generated\": 125000,\n      \"events_per_second\": 34.7,\n      \"failure_rate\": 0.004\n    }\n  }\n}\n</code></pre>"},{"location":"STREAMING_OPERATIONS/#key-metrics","title":"Key Metrics","text":""},{"location":"STREAMING_OPERATIONS/#essential-metrics-to-monitor","title":"Essential Metrics to Monitor","text":""},{"location":"STREAMING_OPERATIONS/#1-event-throughput","title":"1. Event Throughput","text":"<p>Metric: <code>events_per_second</code> Target: 20-50 events/sec (configurable based on needs) Alert: &lt; 10 events/sec when streaming is active</p> <p>How to check:</p> <pre><code>curl http://localhost:8000/api/stream/status | jq '.events_per_second'\n</code></pre>"},{"location":"STREAMING_OPERATIONS/#2-success-rate","title":"2. Success Rate","text":"<p>Metric: <code>(events_sent_successfully / events_generated) * 100</code> Target: &gt; 99% Alert: &lt; 95%</p> <p>Calculate:</p> <pre><code>curl http://localhost:8000/api/stream/statistics | jq '(.events_sent_successfully / .events_generated) * 100'\n</code></pre>"},{"location":"STREAMING_OPERATIONS/#3-failure-rate","title":"3. Failure Rate","text":"<p>Metric: <code>(events_failed / events_generated) * 100</code> Target: &lt; 1% Alert: &gt; 5%</p> <p>Calculate:</p> <pre><code>curl http://localhost:8000/api/stream/statistics | jq '(.events_failed / .events_generated) * 100'\n</code></pre>"},{"location":"STREAMING_OPERATIONS/#4-circuit-breaker-trips","title":"4. Circuit Breaker Trips","text":"<p>Metric: <code>circuit_breaker_trips</code> Target: 0 Alert: &gt; 3 trips in 1 hour</p> <p>How to check:</p> <pre><code>curl http://localhost:8000/api/stream/statistics | jq '.circuit_breaker_trips'\n</code></pre>"},{"location":"STREAMING_OPERATIONS/#5-connection-failures","title":"5. Connection Failures","text":"<p>Metric: <code>connection_failures</code> Target: 0 Alert: &gt; 10 failures in 10 minutes</p> <p>How to check:</p> <pre><code>curl http://localhost:8000/api/stream/statistics | jq '.connection_failures'\n</code></pre>"},{"location":"STREAMING_OPERATIONS/#azure-event-hub-metrics","title":"Azure Event Hub Metrics","text":"<p>Monitor these in Azure Portal:</p> <ul> <li>Incoming Messages: Should match <code>events_sent_successfully</code></li> <li>Throttled Requests: Should be 0 or minimal</li> <li>Server Errors: Should be 0</li> <li>User Errors: Check for 400/403/413 errors</li> <li>Throughput Units Used: Monitor for capacity</li> </ul> <p>Azure CLI:</p> <pre><code>az monitor metrics list \\\n  --resource \"/subscriptions/{subscription-id}/resourceGroups/{rg}/providers/Microsoft.EventHub/namespaces/{namespace}\" \\\n  --metric \"IncomingMessages\" \\\n  --start-time 2024-01-15T10:00:00Z \\\n  --end-time 2024-01-15T11:00:00Z\n</code></pre>"},{"location":"STREAMING_OPERATIONS/#health-checks","title":"Health Checks","text":""},{"location":"STREAMING_OPERATIONS/#application-health","title":"Application Health","text":"<p>Endpoint: <code>GET /api/stream/health</code></p> <p>Status Levels: - <code>healthy</code>: All systems operational - <code>degraded</code>: Some issues but still functional - <code>unhealthy</code>: Critical failures</p> <p>Integration with monitoring tools:</p> <pre><code># Prometheus scrape config\nscrape_configs:\n  - job_name: 'retail-datagen'\n    metrics_path: '/api/stream/health'\n    static_configs:\n      - targets: ['localhost:8000']\n</code></pre>"},{"location":"STREAMING_OPERATIONS/#kubernetes-liveness-probe","title":"Kubernetes Liveness Probe","text":"<pre><code>livenessProbe:\n  httpGet:\n    path: /health\n    port: 8000\n  initialDelaySeconds: 30\n  periodSeconds: 10\n  failureThreshold: 3\n</code></pre>"},{"location":"STREAMING_OPERATIONS/#kubernetes-readiness-probe","title":"Kubernetes Readiness Probe","text":"<pre><code>readinessProbe:\n  httpGet:\n    path: /api/stream/health\n    port: 8000\n  initialDelaySeconds: 10\n  periodSeconds: 5\n  failureThreshold: 2\n</code></pre>"},{"location":"STREAMING_OPERATIONS/#troubleshooting","title":"Troubleshooting","text":""},{"location":"STREAMING_OPERATIONS/#common-issues-solutions","title":"Common Issues &amp; Solutions","text":""},{"location":"STREAMING_OPERATIONS/#issue-1-connection-failures","title":"Issue 1: Connection Failures","text":"<p>Symptoms: - High <code>connection_failures</code> count - Circuit breaker opens immediately - Events not reaching Azure Event Hub</p> <p>Diagnosis:</p> <pre><code># Test connection\ncurl -X POST http://localhost:8000/api/stream/test\n\n# Check Azure config\ncurl http://localhost:8000/api/stream/config | jq '.realtime.azure_connection_string'\n</code></pre> <p>Solutions:</p> <ol> <li> <p>Verify connection string format: <code>bash    # Should include: Endpoint, SharedAccessKeyName, SharedAccessKey    echo $AZURE_EVENTHUB_CONNECTION_STRING</code></p> </li> <li> <p>Check network connectivity:    ```bash    # Test DNS resolution    nslookup your-namespace.servicebus.windows.net</p> </li> </ol> <p># Test connectivity (port 5671 for AMQP)    telnet your-namespace.servicebus.windows.net 5671    ```</p> <ol> <li>Verify Azure credentials:</li> <li>Check SharedAccessKey is correct</li> <li>Verify policy has Send permissions</li> <li> <p>Check key hasn't expired</p> </li> <li> <p>Check firewall rules:</p> </li> <li>Allow outbound connections to <code>*.servicebus.windows.net</code></li> <li>Ports: 5671 (AMQP), 443 (HTTPS)</li> </ol>"},{"location":"STREAMING_OPERATIONS/#issue-2-high-failure-rate","title":"Issue 2: High Failure Rate","text":"<p>Symptoms: - <code>failure_rate</code> &gt; 5% - Many events in dead letter queue - Throttling errors in statistics</p> <p>Diagnosis:</p> <pre><code># Check error breakdown\ncurl http://localhost:8000/api/stream/statistics | jq '.error_counts'\n\n# Check DLQ size\ncurl http://localhost:8000/api/stream/dlq | jq '.count'\n</code></pre> <p>Solutions:</p> <ol> <li>Azure Event Hub throttling:</li> <li>Check Azure metrics for throttled requests</li> <li>Reduce <code>burst</code> size: <code>curl -X PUT http://localhost:8000/api/stream/config -d '{\"burst\": 50}'</code></li> <li>Increase <code>emit_interval_ms</code>: <code>curl -X PUT http://localhost:8000/api/stream/config -d '{\"emit_interval_ms\": 1000}'</code></li> <li> <p>Upgrade Event Hub tier (Standard \u2192 Premium)</p> </li> <li> <p>Network congestion:</p> </li> <li>Increase <code>batch_timeout_ms</code> to allow more time for sends</li> <li>Reduce <code>max_batch_size</code> to smaller batches</li> <li> <p>Check network latency: <code>ping your-namespace.servicebus.windows.net</code></p> </li> <li> <p>Application issues:</p> </li> <li>Check application logs for exceptions</li> <li>Verify Python version (requires 3.11+)</li> <li>Check memory usage: <code>ps aux | grep python</code></li> </ol>"},{"location":"STREAMING_OPERATIONS/#issue-3-circuit-breaker-opens-frequently","title":"Issue 3: Circuit Breaker Opens Frequently","text":"<p>Symptoms: - <code>circuit_breaker_trips</code> increasing - Streaming stops automatically - Status shows \"error\"</p> <p>Diagnosis:</p> <pre><code># Check circuit breaker status\ncurl http://localhost:8000/api/stream/statistics | jq '.circuit_breaker_trips'\n\n# Check failure pattern\ncurl http://localhost:8000/api/stream/statistics | jq '.error_counts'\n</code></pre> <p>Solutions:</p> <ol> <li> <p>Increase failure threshold: <code>json    {      \"realtime\": {        \"failure_threshold\": 10,        \"circuit_breaker_enabled\": true      }    }</code></p> </li> <li> <p>Increase timeout: <code>json    {      \"realtime\": {        \"timeout_seconds\": 120      }    }</code></p> </li> <li> <p>Fix underlying connection issues (see Issue 1)</p> </li> </ol>"},{"location":"STREAMING_OPERATIONS/#issue-4-low-throughput","title":"Issue 4: Low Throughput","text":"<p>Symptoms: - <code>events_per_second</code> &lt; 10 - Slow event generation - High uptime but low event count</p> <p>Diagnosis:</p> <pre><code># Check current rate\ncurl http://localhost:8000/api/stream/status | jq '.events_per_second'\n\n# Check configuration\ncurl http://localhost:8000/api/stream/config | jq '.realtime.emit_interval_ms, .realtime.burst'\n</code></pre> <p>Solutions:</p> <ol> <li> <p>Increase burst size: <code>bash    curl -X PUT http://localhost:8000/api/stream/config \\      -H \"Content-Type: application/json\" \\      -d '{\"burst\": 200}'</code></p> </li> <li> <p>Decrease emit interval: <code>bash    curl -X PUT http://localhost:8000/api/stream/config \\      -H \"Content-Type: application/json\" \\      -d '{\"emit_interval_ms\": 250}'</code></p> </li> <li> <p>Check system resources:    ```bash    # CPU usage    top -p $(pgrep -f retail_datagen)</p> </li> </ol> <p># Memory usage    ps aux | grep retail_datagen    ```</p>"},{"location":"STREAMING_OPERATIONS/#issue-5-events-not-appearing-in-azure","title":"Issue 5: Events Not Appearing in Azure","text":"<p>Symptoms: - <code>events_sent_successfully</code> shows high counts - Azure Event Hub shows no incoming messages - No errors reported</p> <p>Diagnosis:</p> <pre><code># Verify Event Hub name\ncurl http://localhost:8000/api/stream/config | jq '.stream.hub'\n\n# Check recent events\ncurl http://localhost:8000/api/stream/events/recent?limit=5\n</code></pre> <p>Solutions:</p> <ol> <li>Verify Event Hub name matches:</li> <li>Check <code>stream.hub</code> in config</li> <li>Verify Event Hub exists in Azure Portal</li> <li> <p>Check EntityPath in connection string</p> </li> <li> <p>Check Azure Event Hub metrics:</p> </li> <li>Navigate to Azure Portal \u2192 Event Hub \u2192 Metrics</li> <li>Look at \"Incoming Messages\" (should match events_sent)</li> <li> <p>Check \"Throttled Requests\" (should be 0)</p> </li> <li> <p>Verify connection string: <code>bash    # Connection string should include EntityPath or hub name in config    echo $AZURE_EVENTHUB_CONNECTION_STRING | grep EntityPath</code></p> </li> </ol>"},{"location":"STREAMING_OPERATIONS/#circuit-breaker","title":"Circuit Breaker","text":""},{"location":"STREAMING_OPERATIONS/#how-it-works","title":"How It Works","text":"<p>The circuit breaker prevents cascading failures by stopping send attempts when error rate is too high.</p> <p>States: - Closed: Normal operation, all events sent - Open: Too many failures, reject all sends immediately - Half-Open: Testing if service recovered, allow limited sends</p> <p>Configuration:</p> <pre><code>{\n  \"realtime\": {\n    \"circuit_breaker_enabled\": true,\n    \"failure_threshold\": 5,\n    \"timeout_seconds\": 60,\n    \"half_open_max_calls\": 3\n  }\n}\n</code></pre> <p>Parameters: - <code>failure_threshold</code>: Consecutive failures before opening (default: 5) - <code>timeout_seconds</code>: Time to wait before trying half-open (default: 60) - <code>half_open_max_calls</code>: Test calls in half-open state (default: 3)</p>"},{"location":"STREAMING_OPERATIONS/#monitoring-circuit-breaker","title":"Monitoring Circuit Breaker","text":"<pre><code># Check trips\ncurl http://localhost:8000/api/stream/statistics | jq '.circuit_breaker_trips'\n\n# Current state (check failure pattern)\ncurl http://localhost:8000/api/stream/statistics | jq '.error_counts'\n</code></pre>"},{"location":"STREAMING_OPERATIONS/#manual-reset","title":"Manual Reset","text":"<p>Stop and restart streaming to reset circuit breaker:</p> <pre><code># Stop streaming\ncurl -X POST http://localhost:8000/api/stream/stop\n\n# Fix underlying issues\n\n# Restart streaming\ncurl -X POST http://localhost:8000/api/stream/start \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"emit_interval_ms\": 1000, \"burst\": 50}'\n</code></pre>"},{"location":"STREAMING_OPERATIONS/#dead-letter-queue","title":"Dead Letter Queue","text":""},{"location":"STREAMING_OPERATIONS/#overview","title":"Overview","text":"<p>Failed events are stored in a dead letter queue (DLQ) for analysis and retry.</p> <p>Maximum size: 10,000 events (configurable) Retention: In-memory only, cleared on restart</p>"},{"location":"STREAMING_OPERATIONS/#view-dlq","title":"View DLQ","text":"<pre><code>curl http://localhost:8000/api/stream/dlq\n</code></pre> <p>Response:</p> <pre><code>{\n  \"events\": [\n    {\n      \"event\": { /* event envelope */ },\n      \"error\": \"Connection timeout\",\n      \"timestamp\": \"2024-01-15T11:30:00Z\",\n      \"retry_count\": 3\n    }\n  ],\n  \"count\": 15\n}\n</code></pre>"},{"location":"STREAMING_OPERATIONS/#analyze-dlq","title":"Analyze DLQ","text":"<pre><code># Count events by error type\ncurl http://localhost:8000/api/stream/dlq | jq '.events | group_by(.error) | map({error: .[0].error, count: length})'\n</code></pre>"},{"location":"STREAMING_OPERATIONS/#clear-dlq","title":"Clear DLQ","text":"<pre><code>curl -X DELETE http://localhost:8000/api/stream/dlq\n</code></pre>"},{"location":"STREAMING_OPERATIONS/#retry-failed-events","title":"Retry Failed Events","text":"<p>Manual retry (future feature):</p> <pre><code># Coming soon\ncurl -X POST http://localhost:8000/api/stream/dlq/retry\n</code></pre> <p>Current workaround: Stop and restart streaming, events will be regenerated.</p>"},{"location":"STREAMING_OPERATIONS/#performance-tuning","title":"Performance Tuning","text":""},{"location":"STREAMING_OPERATIONS/#configuration-profiles","title":"Configuration Profiles","text":""},{"location":"STREAMING_OPERATIONS/#low-throughput-development","title":"Low Throughput (Development)","text":"<pre><code>{\n  \"realtime\": {\n    \"emit_interval_ms\": 2000,\n    \"burst\": 50,\n    \"max_batch_size\": 128\n  }\n}\n</code></pre> <p>Throughput: ~25 events/sec</p>"},{"location":"STREAMING_OPERATIONS/#medium-throughput-default","title":"Medium Throughput (Default)","text":"<pre><code>{\n  \"realtime\": {\n    \"emit_interval_ms\": 500,\n    \"burst\": 100,\n    \"max_batch_size\": 256\n  }\n}\n</code></pre> <p>Throughput: ~200 events/sec</p>"},{"location":"STREAMING_OPERATIONS/#high-throughput-production","title":"High Throughput (Production)","text":"<pre><code>{\n  \"realtime\": {\n    \"emit_interval_ms\": 100,\n    \"burst\": 500,\n    \"max_batch_size\": 1000\n  }\n}\n</code></pre> <p>Throughput: ~5000 events/sec</p> <p>Warning: High throughput may hit Event Hub throttling limits. Monitor Azure metrics.</p>"},{"location":"STREAMING_OPERATIONS/#azure-event-hub-limits","title":"Azure Event Hub Limits","text":"<p>Standard Tier: - Ingress: 1 MB/sec or 1000 events/sec - Egress: 2 MB/sec - Throughput Units: 1-20 (auto-inflate available)</p> <p>Premium Tier: - Ingress: Higher throughput - Dedicated capacity - Better latency</p> <p>Calculate event size:</p> <pre><code># Average event size\ncurl http://localhost:8000/api/stream/statistics | jq '(.bytes_sent / .events_sent_successfully) / 1024'\n</code></pre>"},{"location":"STREAMING_OPERATIONS/#batch-optimization","title":"Batch Optimization","text":"<p>Rule of thumb: - Small events (&lt;1KB): <code>max_batch_size: 500-1000</code> - Medium events (1-10KB): <code>max_batch_size: 100-500</code> - Large events (&gt;10KB): <code>max_batch_size: 50-100</code></p> <p>Test batch performance:</p> <pre><code># Monitor batches sent\nwatch -n 1 'curl -s http://localhost:8000/api/stream/statistics | jq \".batches_sent, .events_sent_successfully\"'\n</code></pre>"},{"location":"STREAMING_OPERATIONS/#production-deployment","title":"Production Deployment","text":""},{"location":"STREAMING_OPERATIONS/#recommended-configuration","title":"Recommended Configuration","text":"<pre><code>{\n  \"realtime\": {\n    \"emit_interval_ms\": 1000,\n    \"burst\": 100,\n    \"max_batch_size\": 256,\n    \"batch_timeout_ms\": 1000,\n    \"retry_attempts\": 3,\n    \"backoff_multiplier\": 2.0,\n    \"circuit_breaker_enabled\": true,\n    \"monitoring_interval\": 30,\n    \"max_buffer_size\": 10000,\n    \"enable_dead_letter_queue\": true\n  }\n}\n</code></pre>"},{"location":"STREAMING_OPERATIONS/#environment-variables","title":"Environment Variables","text":"<pre><code># Required\nexport AZURE_EVENTHUB_CONNECTION_STRING=\"Endpoint=sb://...\"\n\n# Optional\nexport LOG_LEVEL=\"INFO\"\nexport ALLOWED_ORIGINS=\"https://your-domain.com\"\nexport MAX_WORKERS=\"4\"\n</code></pre>"},{"location":"STREAMING_OPERATIONS/#docker-deployment","title":"Docker Deployment","text":"<pre><code>FROM python:3.11-slim\n\nWORKDIR /app\nCOPY . /app\n\nRUN pip install --no-cache-dir -e .\n\nEXPOSE 8000\n\nCMD [\"python\", \"-m\", \"uvicorn\", \"src.retail_datagen.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n</code></pre> <p>Run container:</p> <pre><code>docker build -t retail-datagen .\n\ndocker run -d \\\n  --name retail-datagen \\\n  -p 8000:8000 \\\n  -e AZURE_EVENTHUB_CONNECTION_STRING=\"$AZURE_EVENTHUB_CONNECTION_STRING\" \\\n  retail-datagen\n</code></pre>"},{"location":"STREAMING_OPERATIONS/#kubernetes-deployment","title":"Kubernetes Deployment","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: retail-datagen\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: retail-datagen\n  template:\n    metadata:\n      labels:\n        app: retail-datagen\n    spec:\n      containers:\n      - name: retail-datagen\n        image: retail-datagen:latest\n        ports:\n        - containerPort: 8000\n        env:\n        - name: AZURE_EVENTHUB_CONNECTION_STRING\n          valueFrom:\n            secretKeyRef:\n              name: azure-credentials\n              key: connection-string\n        resources:\n          requests:\n            memory: \"512Mi\"\n            cpu: \"500m\"\n          limits:\n            memory: \"2Gi\"\n            cpu: \"2000m\"\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8000\n          initialDelaySeconds: 30\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /api/stream/health\n            port: 8000\n          initialDelaySeconds: 10\n          periodSeconds: 5\n</code></pre>"},{"location":"STREAMING_OPERATIONS/#scaling-considerations","title":"Scaling Considerations","text":"<p>Single Instance: - Simpler deployment - State managed in-memory - Suitable for most use cases</p> <p>Multiple Instances: - Not currently supported (stateful application) - Future: Shared state via Redis/Database - Event Hub partitioning required</p>"},{"location":"STREAMING_OPERATIONS/#best-practices","title":"Best Practices","text":""},{"location":"STREAMING_OPERATIONS/#operations","title":"Operations","text":"<ol> <li>Start Small, Scale Up</li> <li>Begin with <code>burst: 50</code>, <code>emit_interval_ms: 2000</code></li> <li>Monitor success rate and Azure metrics</li> <li> <p>Gradually increase throughput</p> </li> <li> <p>Monitor Continuously</p> </li> <li>Set up alerts for key metrics</li> <li>Check DLQ regularly for patterns</li> <li> <p>Monitor Azure Event Hub metrics</p> </li> <li> <p>Enable Circuit Breaker</p> </li> <li>Prevents cascading failures</li> <li>Allows automatic recovery</li> <li> <p>Protects Azure Event Hub from overload</p> </li> <li> <p>Use Dead Letter Queue</p> </li> <li>Analyze failed events for patterns</li> <li>Identify systemic issues</li> <li> <p>Improve event generation logic</p> </li> <li> <p>Test Connection Regularly</p> </li> <li>Run <code>/stream/test</code> endpoint periodically</li> <li>Monitor response times</li> <li>Detect configuration issues early</li> </ol>"},{"location":"STREAMING_OPERATIONS/#security","title":"Security","text":"<ol> <li>Credential Management</li> <li>Use environment variables (never hardcode)</li> <li>Rotate keys quarterly</li> <li> <p>Use Azure Key Vault for production</p> </li> <li> <p>Network Security</p> </li> <li>Enable TLS 1.2+ (default)</li> <li>Use private endpoints if available</li> <li> <p>Restrict firewall rules to necessary ports</p> </li> <li> <p>Access Control</p> </li> <li>Use least privilege access policies</li> <li>Separate read/write permissions</li> <li>Audit access logs regularly</li> </ol>"},{"location":"STREAMING_OPERATIONS/#maintenance","title":"Maintenance","text":"<ol> <li>Regular Updates</li> <li>Keep Azure SDK updated</li> <li>Monitor for security patches</li> <li> <p>Test updates in non-production first</p> </li> <li> <p>Log Management</p> </li> <li>Rotate logs regularly</li> <li>Set appropriate log levels (INFO for prod)</li> <li> <p>Ship logs to centralized logging system</p> </li> <li> <p>Backup State</p> </li> <li>Export generation state periodically</li> <li>Store configuration in version control</li> <li>Document custom configurations</li> </ol>"},{"location":"STREAMING_OPERATIONS/#alerting-examples","title":"Alerting Examples","text":""},{"location":"STREAMING_OPERATIONS/#prometheus-rules","title":"Prometheus Rules","text":"<pre><code>groups:\n  - name: retail_datagen_streaming\n    rules:\n      - alert: StreamingHighFailureRate\n        expr: (streaming_events_failed / streaming_events_generated) &gt; 0.05\n        for: 5m\n        annotations:\n          summary: \"High streaming failure rate\"\n          description: \"Failure rate is {{ $value }}%\"\n\n      - alert: StreamingCircuitBreakerOpen\n        expr: streaming_circuit_breaker_trips &gt; 3\n        for: 10m\n        annotations:\n          summary: \"Circuit breaker tripped multiple times\"\n\n      - alert: StreamingLowThroughput\n        expr: streaming_events_per_second &lt; 10\n        for: 10m\n        annotations:\n          summary: \"Streaming throughput is low\"\n          description: \"Only {{ $value }} events/sec\"\n</code></pre>"},{"location":"STREAMING_OPERATIONS/#bash-monitoring-script","title":"Bash Monitoring Script","text":"<pre><code>#!/bin/bash\n\n# Monitor streaming health\nwhile true; do\n  STATUS=$(curl -s http://localhost:8000/api/stream/health | jq -r '.status')\n  FAILURE_RATE=$(curl -s http://localhost:8000/api/stream/statistics | jq '(.events_failed / .events_generated) * 100')\n\n  if [ \"$STATUS\" != \"healthy\" ]; then\n    echo \"ALERT: Streaming health is $STATUS\"\n  fi\n\n  if (( $(echo \"$FAILURE_RATE &gt; 5\" | bc -l) )); then\n    echo \"ALERT: Failure rate is ${FAILURE_RATE}%\"\n  fi\n\n  sleep 60\ndone\n</code></pre>"},{"location":"STREAMING_OPERATIONS/#support-debugging","title":"Support &amp; Debugging","text":""},{"location":"STREAMING_OPERATIONS/#enable-debug-logging","title":"Enable Debug Logging","text":"<pre><code>export LOG_LEVEL=\"DEBUG\"\npython -m retail_datagen.main\n</code></pre>"},{"location":"STREAMING_OPERATIONS/#view-logs","title":"View Logs","text":"<pre><code># Follow application logs\ntail -f retail_datagen.log\n\n# Search for errors\ngrep -i error retail_datagen.log\n\n# Search for specific event type\ngrep \"receipt_created\" retail_datagen.log\n</code></pre>"},{"location":"STREAMING_OPERATIONS/#generate-diagnostic-report","title":"Generate Diagnostic Report","text":"<pre><code>#!/bin/bash\necho \"=== Streaming Diagnostic Report ===\" &gt; diagnostic.txt\necho \"Generated: $(date)\" &gt;&gt; diagnostic.txt\necho \"\" &gt;&gt; diagnostic.txt\n\necho \"=== Status ===\" &gt;&gt; diagnostic.txt\ncurl -s http://localhost:8000/api/stream/status &gt;&gt; diagnostic.txt\necho \"\" &gt;&gt; diagnostic.txt\n\necho \"=== Statistics ===\" &gt;&gt; diagnostic.txt\ncurl -s http://localhost:8000/api/stream/statistics &gt;&gt; diagnostic.txt\necho \"\" &gt;&gt; diagnostic.txt\n\necho \"=== Health ===\" &gt;&gt; diagnostic.txt\ncurl -s http://localhost:8000/api/stream/health &gt;&gt; diagnostic.txt\necho \"\" &gt;&gt; diagnostic.txt\n\necho \"=== DLQ ===\" &gt;&gt; diagnostic.txt\ncurl -s http://localhost:8000/api/stream/dlq &gt;&gt; diagnostic.txt\n\necho \"Diagnostic report saved to diagnostic.txt\"\n</code></pre>"},{"location":"STREAMING_OPERATIONS/#next-steps","title":"Next Steps","text":"<ul> <li>Setup: See STREAMING_SETUP.md for initial configuration</li> <li>API Reference: See STREAMING_API.md for endpoint documentation</li> <li>Security: See CREDENTIALS.md for credential management</li> <li>Streaming Outbox</li> </ul> <p>The outbox holds pending events for the realtime drain. It should only contain the daily slice generated by the outbox streaming path \u2014 not the entire dataset.</p> <ul> <li><code>GET /api/stream/outbox/status</code> \u2014 counts by status and oldest pending timestamp</li> <li><code>POST /api/stream/outbox/drain</code> \u2014 drains pending items with pacing</li> <li><code>DELETE /api/stream/outbox/clear</code> \u2014 fast reset (drop/recreate)</li> </ul> <p>Historical generation does not populate the outbox; only <code>/api/stream/start</code> (outbox mode) adds new pending items when it generates the next day.</p>"},{"location":"STREAMING_SETUP/","title":"Streaming Setup Guide","text":"<p>Complete guide for setting up real-time event streaming to Azure Event Hub or Microsoft Fabric Real-Time Intelligence.</p>"},{"location":"STREAMING_SETUP/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11+ (strict requirement)</li> <li>Azure Event Hub or Microsoft Fabric RTI workspace</li> <li>Connection string with send permissions</li> <li>Historical data must be generated first (streaming requires existing base data)</li> </ul>"},{"location":"STREAMING_SETUP/#installation","title":"Installation","text":""},{"location":"STREAMING_SETUP/#1-install-azure-event-hub-sdk","title":"1. Install Azure Event Hub SDK","text":"<p>The streaming system requires the Azure Event Hubs SDK:</p> <pre><code>pip install azure-eventhub&gt;=5.11.0\n</code></pre> <p>This dependency is included in <code>requirements.txt</code> and automatically installed with:</p> <pre><code>pip install -e .\n</code></pre>"},{"location":"STREAMING_SETUP/#2-verify-installation","title":"2. Verify Installation","text":"<p>Check that retail-datagen is properly installed:</p> <pre><code>python -m retail_datagen.main --help\n</code></pre> <p>Start the FastAPI server:</p> <pre><code>python -m retail_datagen.main\n</code></pre> <p>Access the application at http://localhost:8000</p>"},{"location":"STREAMING_SETUP/#azure-event-hub-configuration","title":"Azure Event Hub Configuration","text":""},{"location":"STREAMING_SETUP/#option-a-environment-variable-recommended","title":"Option A: Environment Variable (Recommended)","text":"<p>Set the connection string as an environment variable for maximum security:</p> <pre><code>export AZURE_EVENTHUB_CONNECTION_STRING=\"Endpoint=sb://your-namespace.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=your-key;EntityPath=retail-events\"\n</code></pre> <p>Advantages: - No credentials in code or config files - Easy to rotate credentials - Works across different environments - Prevents accidental commits of secrets</p> <p>For persistent configuration, add to your shell profile:</p> <pre><code># Add to ~/.bashrc, ~/.zshrc, or equivalent\necho 'export AZURE_EVENTHUB_CONNECTION_STRING=\"Endpoint=sb://...\"' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre>"},{"location":"STREAMING_SETUP/#option-b-configuration-file","title":"Option B: Configuration File","text":"<p>Edit <code>config.json</code> in the project root:</p> <pre><code>{\n  \"realtime\": {\n    \"azure_connection_string\": \"Endpoint=sb://your-namespace.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=your-key;EntityPath=retail-events\",\n    \"emit_interval_ms\": 500,\n    \"burst\": 100\n  },\n  \"stream\": {\n    \"hub\": \"retail-events\"\n  }\n}\n</code></pre> <p>Warning: Never commit <code>config.json</code> with real credentials to version control. Add to <code>.gitignore</code>:</p> <pre><code>echo 'config.json' &gt;&gt; .gitignore\n</code></pre>"},{"location":"STREAMING_SETUP/#option-c-azure-key-vault-enterprise","title":"Option C: Azure Key Vault (Enterprise)","text":"<p>For production environments, use Azure Key Vault integration:</p> <pre><code>{\n  \"realtime\": {\n    \"use_keyvault\": true,\n    \"keyvault_url\": \"https://your-vault.vault.azure.net/\",\n    \"keyvault_secret_name\": \"eventhub-connection-string\"\n  }\n}\n</code></pre> <p>Requirements: - Azure Key Vault instance - Managed identity or service principal with secret read access - Azure SDK for Key Vault: <code>pip install azure-keyvault-secrets azure-identity</code></p>"},{"location":"STREAMING_SETUP/#microsoft-fabric-rti-setup","title":"Microsoft Fabric RTI Setup","text":"<p>Microsoft Fabric Real-Time Intelligence uses Event Hubs as its streaming backend.</p>"},{"location":"STREAMING_SETUP/#step-1-create-event-stream-in-fabric","title":"Step 1: Create Event Stream in Fabric","text":"<ol> <li>Navigate to your Fabric workspace</li> <li>Click New \u2192 Eventstream</li> <li>Name your event stream (e.g., \"retail-events\")</li> <li>Wait for provisioning to complete</li> </ol>"},{"location":"STREAMING_SETUP/#step-2-get-connection-string","title":"Step 2: Get Connection String","text":"<ol> <li>Open your Event Stream</li> <li>Navigate to the Keys or Settings section</li> <li>Copy the Connection string-primary key</li> <li>Format will be: <code>Endpoint=sb://eventstream-xxx.servicebus.windows.net/;SharedAccessKeyName=...</code></li> </ol>"},{"location":"STREAMING_SETUP/#step-3-configure-retail-datagen","title":"Step 3: Configure retail-datagen","text":"<p>Set the connection string using environment variable:</p> <pre><code>export AZURE_EVENTHUB_CONNECTION_STRING=\"&lt;your-fabric-eventstream-connection-string&gt;\"\n</code></pre> <p>Or add to <code>config.json</code>:</p> <pre><code>{\n  \"realtime\": {\n    \"azure_connection_string\": \"&lt;your-fabric-eventstream-connection-string&gt;\"\n  },\n  \"stream\": {\n    \"hub\": \"retail-events\"\n  }\n}\n</code></pre>"},{"location":"STREAMING_SETUP/#step-4-configure-event-stream-destination","title":"Step 4: Configure Event Stream Destination","text":"<p>In Fabric, configure where events should flow:</p> <ol> <li>Lakehouse: Direct ingestion to Delta tables</li> <li>KQL Database: Real-time analytics with Kusto Query Language</li> <li>Eventhouse: Advanced real-time intelligence scenarios</li> <li>Custom endpoint: Webhook, Function, Logic App</li> </ol>"},{"location":"STREAMING_SETUP/#connection-string-format","title":"Connection String Format","text":"<p>Azure Event Hub connection strings have this format:</p> <pre><code>Endpoint=sb://&lt;namespace&gt;.servicebus.windows.net/;\nSharedAccessKeyName=&lt;policy-name&gt;;\nSharedAccessKey=&lt;key&gt;;\nEntityPath=&lt;event-hub-name&gt;\n</code></pre> <p>Components: - Endpoint: Service Bus namespace URL - SharedAccessKeyName: Access policy name (usually \"RootManageSharedAccessKey\") - SharedAccessKey: Secret key for authentication - EntityPath: Event Hub name (optional, can be set in config.json)</p> <p>Example:</p> <pre><code>Endpoint=sb://retail-analytics.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=abc123xyz789==;EntityPath=retail-events\n</code></pre>"},{"location":"STREAMING_SETUP/#verification","title":"Verification","text":""},{"location":"STREAMING_SETUP/#test-connection","title":"Test Connection","text":"<p>Use the API to test your Azure Event Hub connection:</p> <pre><code>curl -X POST http://localhost:8000/api/stream/test\n</code></pre> <p>Expected success response:</p> <pre><code>{\n  \"success\": true,\n  \"message\": \"Connection test successful\",\n  \"response_time_ms\": 45.2\n}\n</code></pre> <p>Expected failure response:</p> <pre><code>{\n  \"success\": false,\n  \"message\": \"Connection test failed: Invalid connection string format\",\n  \"details\": {\n    \"exception_type\": \"ValueError\"\n  }\n}\n</code></pre>"},{"location":"STREAMING_SETUP/#verify-prerequisites","title":"Verify Prerequisites","text":"<p>Check that fact data exists (required for streaming):</p> <pre><code>curl http://localhost:8000/api/generators/state\n</code></pre> <p>Expected response:</p> <pre><code>{\n  \"has_fact_data\": true,\n  \"last_generated_timestamp\": \"2024-01-15T10:30:00\",\n  ...\n}\n</code></pre> <p>If <code>has_fact_data</code> is <code>false</code>, generate fact data first:</p> <pre><code>curl -X POST http://localhost:8000/api/generators/historical/start\n</code></pre>"},{"location":"STREAMING_SETUP/#test-streaming","title":"Test Streaming","text":"<p>Start a short streaming session (1 minute):</p> <pre><code>curl -X POST http://localhost:8000/api/stream/start \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"duration_minutes\": 1, \"emit_interval_ms\": 1000, \"burst\": 10}'\n</code></pre> <p>Monitor status:</p> <pre><code>curl http://localhost:8000/api/stream/status\n</code></pre> <p>Check statistics:</p> <pre><code>curl http://localhost:8000/api/stream/statistics\n</code></pre>"},{"location":"STREAMING_SETUP/#configuration-parameters","title":"Configuration Parameters","text":"<p>Key configuration options in <code>config.json</code>:</p> <pre><code>{\n  \"realtime\": {\n    \"emit_interval_ms\": 500,           // Time between event bursts (milliseconds)\n    \"burst\": 100,                       // Events per burst\n    \"max_batch_size\": 256,              // Max events per Azure batch\n    \"batch_timeout_ms\": 1000,           // Batch timeout\n    \"retry_attempts\": 3,                // Retry failed sends\n    \"backoff_multiplier\": 2.0,          // Exponential backoff multiplier\n    \"circuit_breaker_enabled\": true,    // Enable circuit breaker pattern\n    \"monitoring_interval\": 30,          // Monitoring interval (seconds)\n    \"max_buffer_size\": 10000,           // Max events in buffer\n    \"enable_dead_letter_queue\": true    // Enable DLQ for failed events\n  }\n}\n</code></pre> <p>Performance tuning: - Low throughput: <code>emit_interval_ms: 2000</code>, <code>burst: 50</code> - Medium throughput: <code>emit_interval_ms: 500</code>, <code>burst: 100</code> (default) - High throughput: <code>emit_interval_ms: 100</code>, <code>burst: 500</code></p> <p>Warning: High throughput may hit Event Hub throttling limits. Monitor failure rates.</p>"},{"location":"STREAMING_SETUP/#troubleshooting","title":"Troubleshooting","text":""},{"location":"STREAMING_SETUP/#connection-string-issues","title":"Connection String Issues","text":"<p>Problem: \"Invalid connection string format\" Solution: Ensure connection string includes all required components (Endpoint, SharedAccessKeyName, SharedAccessKey)</p> <p>Problem: \"Authentication failed\" Solution: Verify SharedAccessKey is correct and policy has Send permissions</p>"},{"location":"STREAMING_SETUP/#prerequisite-errors","title":"Prerequisite Errors","text":"<p>Problem: \"Fact data must be generated first\" Solution: Generate fact data before starting streaming:</p> <pre><code># Generate dimension data\ncurl -X POST http://localhost:8000/api/generators/master/start\n\n# Generate fact data\ncurl -X POST http://localhost:8000/api/generators/historical/start\n</code></pre>"},{"location":"STREAMING_SETUP/#network-issues","title":"Network Issues","text":"<p>Problem: Connection timeouts Solution: - Check firewall rules allow outbound connections to <code>*.servicebus.windows.net</code> - Verify DNS resolution: <code>nslookup &lt;namespace&gt;.servicebus.windows.net</code> - Test network connectivity: <code>telnet &lt;namespace&gt;.servicebus.windows.net 5671</code></p>"},{"location":"STREAMING_SETUP/#throttling","title":"Throttling","text":"<p>Problem: High failure rates, circuit breaker trips Solution: - Reduce <code>burst</code> size - Increase <code>emit_interval_ms</code> - Upgrade Event Hub tier (Standard \u2192 Premium) - Check Azure Event Hub metrics for throttling</p>"},{"location":"STREAMING_SETUP/#next-steps","title":"Next Steps","text":"<ul> <li>API Usage: See STREAMING_API.md for endpoint documentation</li> <li>Operations: See STREAMING_OPERATIONS.md for monitoring and troubleshooting</li> <li>Security: See CREDENTIALS.md for credential management best practices</li> <li>Web UI: Access http://localhost:8000 for browser-based control</li> </ul>"},{"location":"STREAMING_SETUP/#security-best-practices","title":"Security Best Practices","text":"<ol> <li>Never commit credentials to version control</li> <li>Use environment variables for connection strings in development</li> <li>Use Azure Key Vault for production environments</li> <li>Rotate keys regularly (quarterly recommended)</li> <li>Use least privilege access policies (Send-only for streaming)</li> <li>Enable TLS 1.2+ for all connections (default)</li> <li>Audit access logs in Azure Portal regularly</li> </ol>"},{"location":"STREAMING_SETUP/#support","title":"Support","text":"<p>For issues or questions: - Check logs: <code>tail -f retail_datagen.log</code> - Enable debug logging: Set <code>LOG_LEVEL=DEBUG</code> environment variable - Review STREAMING_OPERATIONS.md troubleshooting section - Check Azure Event Hub metrics in Azure Portal</p>"},{"location":"UPLOAD_DATA/","title":"Upload Data (Export + Azure Storage Upload)","text":"<p>Upload Parquet exports to Azure Blob Storage using the Storage account URI + key. Upload occurs immediately after export from the UI or API.</p>"},{"location":"UPLOAD_DATA/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python package (server-side):   <code>bash   pip install azure-storage-blob</code></li> <li>Storage credentials via env or config:</li> <li><code>AZURE_STORAGE_ACCOUNT_URI</code> (may include container/prefix)</li> <li><code>AZURE_STORAGE_ACCOUNT_KEY</code></li> <li>or <code>config.json</code> \u2192 <code>storage.account_uri</code>, <code>storage.account_key</code></li> </ul>"},{"location":"UPLOAD_DATA/#account-uri-formats","title":"Account URI Formats","text":"<p>Any of the following are accepted:</p> <ul> <li><code>https://account.blob.core.windows.net</code></li> <li><code>https://account.blob.core.windows.net/container</code></li> <li><code>https://account.blob.core.windows.net/container/prefix</code></li> </ul> <p>When the container is omitted, the default container <code>retail</code> is used.</p>"},{"location":"UPLOAD_DATA/#upload-paths","title":"Upload Paths","text":"<ul> <li>Master upload prefix: <code>datagen/export/master/&lt;timestamp&gt;</code></li> <li>Facts upload prefix: <code>datagen/export/facts/&lt;timestamp&gt;</code></li> </ul> <p>The final blob name is <code>&lt;prefix&gt;/&lt;local-filename&gt;.parquet</code>.</p>"},{"location":"UPLOAD_DATA/#ui-flow","title":"UI Flow","text":"<ol> <li>Generate data on the Local Data tab.</li> <li>Click \u201cUpload Dimensions\u201d or \u201cUpload Facts\u201d.</li> <li>The server exports Parquet files and uploads them to the configured Storage account.</li> <li>If Storage is not configured or the <code>azure-storage-blob</code> library is missing, the server will export locally and log a warning; the upload step is skipped.</li> </ol>"},{"location":"UPLOAD_DATA/#api","title":"API","text":"<ul> <li>Export master (uploads if configured):   <code>bash   curl -X POST http://localhost:8000/api/export/master \\     -H \"Content-Type: application/json\" \\     -d '{\"format\":\"parquet\"}'</code></li> <li>Export facts (uploads if configured):   <code>bash   curl -X POST http://localhost:8000/api/export/facts \\     -H \"Content-Type: application/json\" \\     -d '{\"format\":\"parquet\"}'</code></li> </ul> <p>The export status endpoint returns the task progress and (if uploaded) a summary under <code>uploaded</code>:</p> <pre><code>{\n  \"status\": \"completed\",\n  \"output_directory\": \"data/export\",\n  \"uploaded\": {\n    \"uploaded\": 42,\n    \"container\": \"retail\",\n    \"prefix\": \"datagen/export/facts/20250115-133000\"\n  }\n}\n</code></pre>"},{"location":"UPLOAD_DATA/#verifying-upload","title":"Verifying Upload","text":"<ul> <li> <p>List blobs with Azure CLI:   <code>bash   az storage blob list \\     --account-name &lt;account&gt; \\     --container-name &lt;container&gt; \\     --prefix datagen/export/facts/ \\     --auth-mode login -o table</code></p> </li> <li> <p>Or browse in the Azure Portal under the configured container.</p> </li> </ul>"},{"location":"UPLOAD_DATA/#security-considerations","title":"Security Considerations","text":"<ul> <li>Prefer Key Vault or environment variables for secrets.</li> <li>Use limited permissions for upload (write-only SAS or scoped RBAC if using managed identity; this sample uses account key for simplicity).</li> <li>Avoid committing keys to source control.</li> </ul>"},{"location":"VALIDATION/","title":"Validation","text":"<p>Validation Guide</p> <p>This guide captures a set of sanity checks to validate the synthetic omni\u2011channel dataset generated by the retail datagen. You can run the SQL in docs/validation_queries.sql against the DuckDB at data/retail.duckdb.</p> <ul> <li>Pricing invariants</li> <li>Cost &lt; SalePrice \u2264 MSRP</li> <li> <p>Cost/SalePrice between 0.50 and 0.85 for most products</p> </li> <li> <p>Tax checks</p> </li> <li>Store tax_rate in reasonable range (0\u201310.25%)</li> <li>Reduced\u2011rate items present in dim_products.taxability</li> <li> <p>Recompute sample receipt taxes: |recorded \u2212 computed| \u2264 $0.02 for &gt; 98%</p> </li> <li> <p>POS behavior</p> </li> <li>Basket size by store_format roughly: express ~2, hypermarket 12\u201316</li> <li> <p>Returns present (receipt_type='RETURN') and negative quantities in lines</p> </li> <li> <p>Inventory fidelity</p> </li> <li>fact_store_inventory_txn includes SALE, INBOUND_SHIPMENT, RETURN, ADJUSTMENT</li> <li> <p>fact_dc_inventory_txn includes INBOUND_SHIPMENT, OUTBOUND_SHIPMENT</p> </li> <li> <p>Online orders</p> </li> <li>Fulfillment mix near 60/30/10 (DC/Store/BOPIS)</li> <li>Lines carry PromoCode 10\u201330% of the time</li> <li> <p>Small cancellation rate present; cancelled orders have zero totals</p> </li> <li> <p>Marketing</p> </li> <li> <p>Device multipliers ~ 1.0x/1.2x/1.5x across channels</p> </li> <li> <p>Presence/Sensors</p> </li> <li>Foot traffic zones non\u2011uniform and vary by store_format</li> <li>BLE pings per visit vary by format; ~30% pings link to customers</li> </ul>"}]}